{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIS Water Random Forest 1.0.0\n",
    "Version: 06.30.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "#GPU\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from cuml.ensemble import RandomForestClassifier as cumlRF\n",
    "\n",
    "# Scikit learn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "#GDAL Stuff\n",
    "from osgeo import gdalconst\n",
    "from osgeo import gdal\n",
    "\n",
    "#sys.path.append('../')\n",
    "#import notebook_util as nu\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "LABEL_NAME = 'water'\n",
    "DATA_TYPE = cp.float32\n",
    "colsToDrop = ['Unnamed: 0', 'x_offset', 'y_offset']\n",
    "v_names = ['sur_refl_b01_1','sur_refl_b02_1','sur_refl_b03_1',\n",
    "           'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
    "           'sur_refl_b07_1','ndvi','ndwi1','ndwi2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fpath, colsToDrop, yCol='water', testSize=0.2, randomState=42, \n",
    "              dataType=np.float32, cpu=True, splitXY=False, trainTestSplit=False,\n",
    "             applyLog=False):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by models\n",
    "    :param fpath: Path to the data to be ingested.\n",
    "    :param dataType: Data type to convert ingested data to.\n",
    "    :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "    :param testSize: Ration to\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(fpath).astype(dataType) if cpu else cudf.read_csv(fpath).astype(dataType)\n",
    "    df = df.drop(columns=colsToDrop)\n",
    "    cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    if applyLog:\n",
    "        for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "            print('Applying log1p func to {}'.format(col))\n",
    "            cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "        cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    df = None\n",
    "    if not splitXY:\n",
    "        return cleanedDF\n",
    "    X = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    y = cleanedDF[yCol].astype(dataType)\n",
    "    if trainTestSplit:\n",
    "        return train_test_split(X, y, test_size=TEST_RATIO)\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "- Read in to cuDF Dataframe\n",
    "- Drop unnecessary columns\n",
    "- Split into Xs and Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/path/to/projects/modis_water/goodDistData/combined_td/MOD09_WATER_TR_DATA_1m#0.csv'\n",
    "os.path.exists(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data for use of visualizations \n",
    "(skip this if you just want to train model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = load_data(fpath=data_path, colsToDrop=colsToDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T.to_csv('outputInfo.csv')\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample so we can speed up expensive visualizations\n",
    "sampledDf = df.sample(frac=0.2)\n",
    "sampledDf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.pairplot(sampledDf, kind='reg')\n",
    "plt.savefig('modisWaterTrainingData.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same as above but with water highlighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.pairplot(sampledDf, hue='water', kind='reg')\n",
    "plt.savefig('modisWaterTrainingEDA_Correlation_WaterHighlight.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(16, 20), bins=50)\n",
    "plt.savefig('histDF.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation with dataset - target value\n",
    "corr = df.corr()['water']\n",
    "corr.to_csv('correlation.csv')\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full correlation table\n",
    "df.corr().style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at outliers and horizontal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier check\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "for i, c in enumerate(df.drop('water', axis=1).select_dtypes(include='number').columns):\n",
    "    plt.subplot(10,2,i*2+1)\n",
    "    sns.boxplot(df[c], color='blue')\n",
    "    plt.title('Distribution plot for field:' + c)\n",
    "    plt.xlabel('')\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "\n",
    "    \n",
    "    plt.subplot(10,2,i*2+2)\n",
    "    sns.boxplot(df[c].apply('log1p'), color='red')\n",
    "    plt.title('Log1p distribution plot for field:' + c)\n",
    "    plt.xlabel('')\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.savefig('outlier_distribution_modis_water.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 14))\n",
    "\n",
    "for i, c in enumerate(df.select_dtypes(include='number').columns):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    sns.distplot(df[c])\n",
    "    plt.title('Distribution plot for field:' + c)\n",
    "    plt.xlabel('')\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.savefig('output_dist_modis_water.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "sampledDf = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model\n",
    "\n",
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'n_estimators': 900,\n",
    "                   #'max_samples': 1.0,\n",
    "                   'max_depth': 100,\n",
    "                   'n_bins': 128,\n",
    "                   'random_state':  42,\n",
    "                   #'n_jobs': -1\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cumlRF(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_data(fpath=data_path, \n",
    "                  colsToDrop=colsToDrop,\n",
    "                  dataType=DATA_TYPE,\n",
    "                  cpu=False,\n",
    "                  splitXY=True,\n",
    "                  #imbalance=True,\n",
    "                  #land=True,\n",
    "                  trainTestSplit=False,\n",
    "                  applyLog=False)\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "kf.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = None\n",
    "scores = []\n",
    "for trainIdx, testIdx in kf.split(X):\n",
    "    print(\"Train {}, Test {}\".format(trainIdx, testIdx))\n",
    "    X_train, X_test = X.iloc[trainIdx], X.iloc[testIdx]\n",
    "    y_train, y_test = y.iloc[trainIdx], y.iloc[testIdx]\n",
    "    print('Fitting model')\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print('Getting score')\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    if score>=0.8:\n",
    "        bestModel = classifier\n",
    "        break\n",
    "    print('Predicting for test set')\n",
    "    test_predictions = classifier.predict(X_test)\n",
    "    print(classification_report(y_test.to_array(), test_predictions.to_array()))\n",
    "    print('Score: {}'.format(score))\n",
    "    scores.append(score)\n",
    "    del test_predictions, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreAvg = np.asarray(scores).mean()\n",
    "print(scoreAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data(fpath=data_path, \n",
    "                                             colsToDrop=colsToDrop,\n",
    "                                             dataType=DATA_TYPE,\n",
    "                                             cpu=False,\n",
    "                                             splitXY=True,\n",
    "                                             trainTestSplit=True,\n",
    "                                             applyLog=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = classifier.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(score, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = classifier.predict(X_train)\n",
    "test_predictions = classifier.predict(X_test)\n",
    "prediction_probs = classifier.predict_proba(X_test)\n",
    "prediction_probs = prediction_probs[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 14))\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.distplot(test_predictions.to_array())\n",
    "plt.title('Distribution plot for test predictions')\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.distplot(y_test.to_array())\n",
    "plt.title('Distribution of truth values')\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.distplot(prediction_probs.to_array())\n",
    "plt.title('Distribution of the probability of predicted values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.astype(cp.int32)\n",
    "y_test_int = y_test.astype(cp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_train.to_array(), train_predictions.to_array()))\n",
    "print('Test Performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test.to_array(), test_predictions.to_array()))\n",
    "cm = confusion_matrix(y_test_int, test_predictions)\n",
    "recall = (cm[0][0] / (cm[0][0] + cm[0][1]))\n",
    "print('Test Recall')\n",
    "print('-------------------------------------------------------')\n",
    "print(recall)\n",
    "print('Confusion Matrix')\n",
    "print('-------------------------------------------------------')\n",
    "print(cm)\n",
    "auc_score = roc_auc_score(y_test_int, prediction_probs)\n",
    "print('Roc_auc score')\n",
    "print('-------------------------------------------------------')\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test, test_predictions, train_predictions, prediction_probs, y_test_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sav_path = '../models/mw_rf_{}_{}_{}_{}.sav'.format(score, \n",
    "                                                          hyperparameters['n_estimators'],\n",
    "                                                          hyperparameters['max_depth'],\n",
    "                                                          hyperparameters['n_bins'])\n",
    "joblib.dump(bestModel, model_sav_path, compress=3)\n",
    "classifier = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Raster testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = 124\n",
    "YEAR = 2006\n",
    "PATH = '/path/to/projects/repos/data/modis-water-random-forest/test_data/h09v05/{}'.format(YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_list = [fn for fn in glob.glob(os.path.join(PATH, f'*A{YEAR}{DAY}*.tif'))\n",
    "            if 'sur_refl' in fn]\n",
    "vars_list.sort()\n",
    "vars_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dimensions of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrt_opts = gdal.BuildVRTOptions(separate=True)\n",
    "dd = gdal.BuildVRT('tmp.vrt', vars_list, options=vrt_opts)\n",
    "nrows, ncols = dd.RasterYSize, dd.RasterXSize\n",
    "dd = None\n",
    "nrows, ncols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data \n",
    "We don't need to slice because we have more than enough GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readRasterToArray(vars_list, dictForm=False):\n",
    "    vrt_options = gdal.BuildVRTOptions(separate=True)\n",
    "    dd = gdal.BuildVRT('tmp.vrt', vars_list, options=vrt_options)\n",
    "    nrows, ncols = dd.RasterYSize, dd.RasterXSize\n",
    "    newshp = (ncols*nrows, dd.RasterCount+3)\n",
    "    img = np.empty(newshp, dtype=np.int16)\n",
    "    if dictForm:\n",
    "        dictRet = {}\n",
    "    for b in range(len(vars_list)):\n",
    "        if dictForm:\n",
    "            dictRet[b+1] = dd.GetRasterBand(b+1).ReadAsArray().astype(np.int16).ravel()\n",
    "        img[:, b] = dd.GetRasterBand(b+1).ReadAsArray().astype(np.int16).ravel()\n",
    "    dd = None\n",
    "    if dictForm:\n",
    "        dictRet[len(vars_list)+1] = ((img[:, 1] - img[:, 0]) / (img[:, 1] + img[:, 0])) * 10000\n",
    "        dictRet[len(vars_list)+2] = ((img[:, 1] - img[:, 5]) / (img[:, 1] + img[:, 5])) * 10000\n",
    "        dictRet[len(vars_list)+3] = ((img[:, 1] - img[:, 6]) / (img[:, 1] + img[:, 6])) * 10000 \n",
    "    img[:, len(vars_list)] = ((img[:, 1] - img[:, 0]) / (img[:, 1] + img[:, 0])) * 10000\n",
    "    img[:, len(vars_list)+1] = ((img[:, 1] - img[:, 5]) / (img[:, 1] + img[:, 5])) * 10000\n",
    "    img[:, len(vars_list)+2] = ((img[:, 1] - img[:, 6]) / (img[:, 1] + img[:, 6])) * 10000\n",
    "    if dictForm:\n",
    "        return dictRet, img\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictIm, im = readRasterToArray(vars_list, dictForm = True)\n",
    "print('Raster as ndarray')\n",
    "print(im)\n",
    "print('{} GB size'.format((im.size * im.itemsize) / 1000000000))\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../models/mw_rf_0.682_900_100_128.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRaster(img_chunk):\n",
    "    \"\"\"\n",
    "    Function given a raster in the form of a nxn matrix, will\n",
    "    convert the matrix to a GPU-bound data frame then perform \n",
    "    predictions given the loaded model.\n",
    "    \n",
    "    Return the prediction matrix, the prediction probabilities\n",
    "    for each and the dataframe converted to host.\n",
    "    \"\"\"\n",
    "    print('Converting host array to GPU-based dataframe')\n",
    "    df = cudf.DataFrame(cp.asarray(img_chunk), columns=v_names)\n",
    "    print('Making predictions from raster')\n",
    "    predictions = model.predict(df)\n",
    "    predictionsProbs = model.predict_proba(df)\n",
    "    print('Converting GPU-bound predictions to host')\n",
    "    predictionsPandas = predictions.to_pandas()\n",
    "    predictionsProbaPandas = predictionsProbs.to_pandas()\n",
    "    predictions = None\n",
    "    predictionsProbs = None\n",
    "    return predictionsPandas, predictionsProbaPandas, df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedRaster, predictedProbaRaster, df = predictRaster(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input test raster: description and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df.hist(column='sur_refl_b05_1', bins=30, grid=False, figsize=(8, 10), color='#86bf91')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the predicted probability for each pixel in the raster (no bad-data vals masked yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedProbaRaster.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape the unravelled matrix back to the 4800x4800 raster shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = (4800, 4800)\n",
    "matrix = np.asarray(predictedRaster)\n",
    "reshp = matrix.reshape(shp)\n",
    "reshp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the QA Mask and the Water Mask for the h09v05 tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qaMask = '/path/to/projects/repos/data/modis-water-random-forest/qa_masks'\n",
    "waterMask = '/path/to/projects/repos/data/modis-water-random-forest/water_masks'\n",
    "qa_list = [fn for fn in glob.glob(os.path.join(qaMask, f'*A{YEAR}{DAY}.h09v05*.tif'))]\n",
    "water_list = [fn for fn in glob.glob(os.path.join(waterMask, '*h09v05*.tif'))]\n",
    "qa_mask = qa_list[0]\n",
    "water_mask = water_list[0]\n",
    "print(water_mask)\n",
    "ds = gdal.Open(qa_mask, gdal.GA_ReadOnly)\n",
    "waterMask = gdal.Open(water_mask, gdal.GA_ReadOnly)\n",
    "qaMaskMatrix = ds.GetRasterBand(1).ReadAsArray()\n",
    "waterMaskMatrix = waterMask.GetRasterBand(1).ReadAsArray()\n",
    "ds = None\n",
    "waterMask = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask out results if QA Mask says pixel is \"bad\"\n",
    "Mask out water mask if QA Mask says pixel is \"bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedResult = np.where(qaMaskMatrix == 0, reshp, -9999)\n",
    "waterMasked = np.where(qaMaskMatrix == 0, waterMaskMatrix, -9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterMaskRavel = waterMasked.ravel()\n",
    "print(waterMaskRavel.shape)\n",
    "imWater = (waterMaskRavel == 1)\n",
    "imWater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating stats for predicted and truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qaDict = {}\n",
    "stackedArr = None\n",
    "for i, k in enumerate(dictIm.keys()):\n",
    "    qaDict[k] = np.extract(imWater, dictIm[k])\n",
    "    if i==0:\n",
    "        stackedArr = qaDict[k]\n",
    "    else:\n",
    "        stackedArr = np.vstack([stackedArr, qaDict[k]])\n",
    "stackedArr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count num of occurences for each class with the masked predicted result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countNoData = np.count_nonzero(maskedResult == -9999)\n",
    "countLand = np.count_nonzero(maskedResult == 0)\n",
    "countWater = np.count_nonzero(maskedResult == 1)\n",
    "print('Predicted\\n Nodata occurences: {}\\n Land occurance: {}\\n Water occurances: {}'.format(countNoData, countLand, countWater))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count num of occurences for each class with the water mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countNoDataT = np.count_nonzero(waterMasked == -9999)\n",
    "countLandT = np.count_nonzero(waterMasked == 0)\n",
    "countWaterT = np.count_nonzero(waterMasked == 1)\n",
    "print('Truth Vals\\n Nodata occurences: {}\\n Land occurance: {}\\n Water occurances: {}'.format(countNoDataT, countLandT, countWaterT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of model given water-only test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedRaster, predictedProbaRaster, df = predictRaster(stackedArr.T)\n",
    "print(predictedRaster.value_counts())\n",
    "predictedProbaRaster.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output predicted raster to GeoTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = gdal.Open(vars_list[0], gdal.GA_ReadOnly)\n",
    "geo = ds.GetGeoTransform()\n",
    "proj = ds.GetProjection()\n",
    "ncols = ds.RasterXSize\n",
    "nrows = ds.RasterYSize\n",
    "print('Transform')\n",
    "print(geo)\n",
    "print('Projection')\n",
    "print(proj)\n",
    "print('Width')\n",
    "print(ncols)\n",
    "print('Height')\n",
    "print(nrows)\n",
    "ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outPath = '../predictions/{}_{}_h09v05_predicted.tif'.format(YEAR, DAY)\n",
    "waterMaskForDay = '../predictions/waterMask_h09v05_qa.tif'.format(YEAR, DAY)\n",
    "print(outPath)\n",
    "print(waterMaskForDay)\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "outDs = driver.Create(outPath, ncols, nrows, 1, gdal.GDT_Float32, options=['COMPRESS=LZW'])\n",
    "outDs.SetGeoTransform(geo)\n",
    "outDs.SetProjection(proj)\n",
    "outBand = outDs.GetRasterBand(1)\n",
    "outBand.WriteArray(maskedResult)\n",
    "outBand.SetNoDataValue(-9999)\n",
    "outDs.FlushCache()\n",
    "outDs = None\n",
    "outBand = None\n",
    "driver = None\n",
    "\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "outDs = driver.Create(waterMaskForDay, ncols, nrows, 1, gdal.GDT_Int16, options=['COMPRESS=LZW'])\n",
    "outDs.SetGeoTransform(geo)\n",
    "outDs.SetProjection(proj)\n",
    "outBand = outDs.GetRasterBand(1)\n",
    "outBand.WriteArray(waterMasked)\n",
    "outBand.SetNoDataValue(-9999)\n",
    "outDs.FlushCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "outputPlt = plt.matshow(np.where(maskedResult == -9999, np.NaN, maskedResult), fignum=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truth Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "truthPlt = plt.matshow(np.where(waterMasked==-9999, np.NaN, waterMasked), fignum=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilab-kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
