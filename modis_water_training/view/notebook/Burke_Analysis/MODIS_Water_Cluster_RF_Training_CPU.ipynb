{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b714c30-b71c-43c6-9fe3-9b012a7bfdfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  MODIS Water Cluster Training\n",
    "\n",
    "Version: 0.1.0\n",
    "\n",
    "Date modified: 05.01.2023\n",
    "\n",
    "Modified by: Amanda Burke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f43eed03-46c0-41a4-b716-4e543a00f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import joblib\n",
    "import optuna\n",
    "import pickle\n",
    "import time\n",
    "import glob\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0c8f7-a553-43aa-a7a9-720557034e6f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef09a8be-17ed-40a8-958e-ed66b83929bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = False\n",
    "MODEL = 'rf'\n",
    "TEST_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "LABEL_NAME = 'water'\n",
    "DATA_TYPE = np.int16\n",
    "FRAC_LAND=0.5\n",
    "num_datapoints = 100000000\n",
    "\n",
    "v_names = [\n",
    "    'sur_refl_b01_1','sur_refl_b02_1','sur_refl_b03_1',\n",
    "    'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
    "    'sur_refl_b07_1','ndvi','ndwi1','ndwi2'\n",
    "    ]\n",
    "\n",
    "common_params = {\n",
    "    \"n_init\": \"auto\"\n",
    "}\n",
    "input_vars = ['sur_refl_b01_1','sur_refl_b02_1','sur_refl_b07_1']\n",
    "droped_vars = [v for v in v_names if v not in input_vars]\n",
    "\n",
    "#RF Training\n",
    "search_space={\n",
    "    \"n_estimators\": [75, 100, 125, 150, 175, 200, 250, 300, 400, 500],\n",
    "    \"max_depth\" : [5, 10, 30, 50, 80, 90, 100, 110],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5],\n",
    "    \"min_samples_split\" : [2, 4, 8, 10],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"max_features\" : ['auto', 'sqrt', 'log2'] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b186d-7086-4346-8f59-be1048f778d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62b27b38-d384-4fba-bdc6-f1970e7f6bd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729b926-4895-4835-9225-0d3863f8f40f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287cd372-f48f-4cdf-90b7-f8a8fc9d66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_clusters(X_w,X_l,cluster_output_w,cluster_output_l, n_cluster,\n",
    "                      kme_w=None,kme_l=None):\n",
    "    fig = plt.figure(figsize = (25, 10))\n",
    "\n",
    "    plt.suptitle(f'Kmeans Clustering {DATA_VERSION} Data, {n_cluster} Clusters')\n",
    "\n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.set_title(f'Land and Water Datapoints')\n",
    "    ax1.scatter(X_w.values[:,0], X_w.values[:,1],label='Water')\n",
    "    ax1.scatter(X_l.values[:,0], X_l.values[:,1],label='Land')\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax1.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    ax1.set_xlabel(X_w.columns[0])\n",
    "    ax1.set_ylabel(X_w.columns[1])\n",
    "    ax1.legend(loc='lower right',fontsize=\"20\")\n",
    "\n",
    "    ax2 = plt.subplot(132)\n",
    "    ax2.set_title(f'Water Datapoints Clustered: {len(X_water)} Examples')\n",
    "    ax2.scatter(X_w.values[:,0], X_w.values[:,1],c=cluster_output_w,cmap='tab10')\n",
    "    if kme_w is not None:\n",
    "        ax2.scatter(kme_w.cluster_centers_[:,0],kme_w.cluster_centers_[:,1],\n",
    "            label='Center Point',c='k',s=150)\n",
    "        ax2.legend(loc='lower right',fontsize=\"20\")\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax2.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    ax2.set_xlabel(X_w.columns[0])\n",
    "    ax2.set_ylabel(X_w.columns[1])\n",
    "    \n",
    "\n",
    "    ax3 = plt.subplot(133)\n",
    " \n",
    "    ax3.set_title(f'Land Datapoints Clustered: {len(X_land)} Examples')\n",
    "    ax3.scatter(X_l.values[:,0], X_l.values[:,1],c=cluster_output_l,cmap='tab10')\n",
    "    if kme_l is not None:\n",
    "        ax3.scatter(kme_l.cluster_centers_[:,0],kme_l.cluster_centers_[:,1],\n",
    "                    label='Center Point',c='k',s=150)\n",
    "        ax3.legend(loc='lower right',fontsize=\"20\")\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax3.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    ax3.set_xlabel(X_l.columns[0])\n",
    "    ax3.set_ylabel(X_l.columns[1])\n",
    "   \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a675b-fb62-484d-8a3d-9b8fed870873",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd27567-2a51-4e94-8d0a-43504a90bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fpath, colsToDrop, \n",
    "              yCol='water', testSize=0.2, randomState=42,\n",
    "              dataType=np.float32, cpu=True, splitXY=False, trainTestSplit=False,\n",
    "              applyLog=False, imbalance=False, frac=0.1, land=False, multi=False, \n",
    "              multisample=1000000, ndvi_change=False):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by models\n",
    "    :param fpath: Path to the data to be ingested.\n",
    "    :param dataType: Data type to convert ingested data to.\n",
    "    :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "    :param testSize: Ration to\n",
    "    \"\"\"\n",
    "    if multi:\n",
    "        all_dfs = [pd.read_csv(path_) for\n",
    "                   path_ in fpath]\n",
    "        df = pd.concat(all_dfs).sample(n=multisample, random_state=randomState)\n",
    "        print('DF length: {}'.format(len(df.index)))\n",
    "    else:   \n",
    "        df = pd.read_parquet(fpath) if '.parquet' in fpath else pd.read_csv(fpath)\n",
    "    df = df[df['sur_refl_b01_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b07_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b06_1'] + df['sur_refl_b02_1'] != 0]\n",
    "\n",
    "    df = df.drop(columns=colsToDrop)\n",
    "    cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0).astype(dataType)\n",
    "    if applyLog:\n",
    "        for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "            print('Applying log1p func to {}'.format(col))\n",
    "            cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "        cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    df = None\n",
    "    if imbalance:\n",
    "        if land:\n",
    "            print('Imbalancing data, sampling {} from water'.format(frac))\n",
    "        else:\n",
    "            print(f'Imbalancing data, sampling {frac} from land, {1-frac} from water')\n",
    "        groupedDF = cleanedDF.groupby('water')\n",
    "        dfs = [groupedDF.get_group(y) for y in groupedDF.groups]\n",
    "        sampledDF = dfs[1].sample(frac=frac)if land else dfs[0].sample(frac=frac)\n",
    "        concatDF = sampledDF.append(dfs[0]) if land else sampledDF.append(dfs[1])\n",
    "        concatDF = concatDF.sample(frac=1)\n",
    "        concatDF = concatDF.reset_index()\n",
    "        cleanedDF = concatDF.drop(columns=['index'])\n",
    "    if not splitXY:\n",
    "        return cleanedDF\n",
    "    cleanedX = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    cleanedy = cleanedDF[yCol].astype(dataType)\n",
    "    \n",
    "    ############\n",
    "    #Added calculation of NDVI instead of the file point\n",
    "    ############\n",
    "    if ndvi_change is True:\n",
    "        top_math_ndvi = (cleanedX['sur_refl_b02_1'].values - cleanedX['sur_refl_b01_1'].values)\n",
    "        bot_math_ndvi = (cleanedX['sur_refl_b02_1'].values + cleanedX['sur_refl_b01_1'].values)\n",
    "        calculated_ndvi = top_math_ndvi/bot_math_ndvi\n",
    "        calculated_ndvi[calculated_ndvi > 1.0] = 1.0\n",
    "        calculated_ndvi[calculated_ndvi < -1.0] = -1.0\n",
    "        scaled_ndvi = (10000*calculated_ndvi).astype(int)\n",
    "        cleanedX['ndvi'] = scaled_ndvi\n",
    "        \n",
    "    if trainTestSplit:\n",
    "        return train_test_split(cleanedX, cleanedy, test_size=TEST_RATIO)\n",
    "    else:\n",
    "        return cleanedX, cleanedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24bef151-652f-4cad-b1ca-5c4e64344c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(tile, data_version, offsets_indexes, \n",
    "                     ndvi_calc=True, colsToDrop=droped_vars):\n",
    "    \n",
    "    training_data_basepath = f'/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/{data_version}'\n",
    "    glob_string = os.path.join(training_data_basepath,'MOD*{}*.parquet.gzip'.format(tile))\n",
    "    data_paths = sorted([fv for fv in glob.glob(glob_string)])\n",
    " \n",
    "    data_path = data_paths[0]\n",
    "    print(data_path)\n",
    "\n",
    "    colsToDropTraining = colsToDrop.copy()\n",
    "    colsToDropTraining.extend(offsets_indexes)\n",
    "    \n",
    "    X, X_test, y, y_test = load_data(\n",
    "        fpath=data_path,\n",
    "        colsToDrop=colsToDropTraining,\n",
    "        dataType=DATA_TYPE,\n",
    "        cpu=True,\n",
    "        splitXY=True,\n",
    "        trainTestSplit=True,\n",
    "        ndvi_change=ndvi_calc)\n",
    "\n",
    "    print('Input Variables', X.columns)\n",
    "    print(f'data shape: {X.shape}, {y.shape}')\n",
    "    \n",
    "    #Getting the indices that are associated with land (0) and water (1)\n",
    "    water_indx = np.where(y>0.5)[0]\n",
    "    land_indx = np.where(y<0.5)[0]\n",
    "    # print(y.iloc[water_indx])\n",
    "    # print('Min water value:',np.nanmin(y.iloc[water_indx]),', Min land value:',np.nanmin(y.iloc[land_indx]))\n",
    "    print()\n",
    "\n",
    "    return X, y, water_indx, land_indx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e435e0-8089-4c0f-8ab0-ef140c5eb414",
   "metadata": {},
   "source": [
    "### Kmeans Clustering and Matching Size dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e0854-39fc-409d-82ce-9d340243778b",
   "metadata": {},
   "source": [
    "Based on the cluster analysis above on 5.03.23, 15 clusters appears to have the most data and exclude outliers so will use that number for selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d66a293-e0e7-419f-a6c2-e558102de4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(cluster_type, InX, InY, water_i, land_i, \n",
    "                      kwargs=common_params, plotting=False, CLUSTER_NUM=15, \n",
    "                      PERCENT_RANDOM_PULL=0.15, match=True):\n",
    "\n",
    "    InY_w = InY.iloc[water_i].reset_index(drop=True)\n",
    "    InY_l = InY.iloc[land_i].reset_index(drop=True)\n",
    "    InX_w = InX.iloc[water_i].reset_index(drop=True)\n",
    "    InX_l = InX.iloc[land_i].reset_index(drop=True)\n",
    "    \n",
    "    kme_land_model = MiniBatchKMeans(n_clusters=CLUSTER_NUM, **kwargs).fit(InX_l)\n",
    "    kme_land = kme_land_model.predict(InX_l)\n",
    "\n",
    "    kme_water_model = MiniBatchKMeans(n_clusters=CLUSTER_NUM, **kwargs).fit(InX_w)\n",
    "    kme_water = kme_water_model.predict(InX_w)\n",
    "    \n",
    "    if plotting:\n",
    "        plotting_clusters(\n",
    "                    InX_w, InX_l,\n",
    "                    kme_water,kme_land,\n",
    "                    CLUSTER_NUM,kme_water_model,kme_land_model)\n",
    "    if 'Even' in cluster_type: \n",
    "        eb_count_water  = np.inf\n",
    "        eb_count_land = np.inf\n",
    "        for c in np.arange(CLUSTER_NUM):\n",
    "            water_num = len(np.where(kme_water == c)[0])\n",
    "            if water_num < eb_count_water: eb_count_water = water_num\n",
    "            land_num = len(np.where(kme_land == c)[0])\n",
    "            if land_num < eb_count_land: eb_count_land = land_num\n",
    "        if eb_count_land < eb_count_water: COUNT = eb_count_land\n",
    "        else: COUNT = eb_count_water\n",
    "    \n",
    "    w_l_cluster_indx = []\n",
    "    for label in [kme_water,kme_land]:\n",
    "        cluster_indx = []\n",
    "        for c in np.arange(CLUSTER_NUM):\n",
    "            indx = np.where(label == c)[0]  \n",
    "            if 'Even' in cluster_type: selection_count = COUNT\n",
    "            else: selection_count = int(PERCENT_RANDOM_PULL*len(indx))\n",
    "            rand_indx = np.random.choice(indx,selection_count,replace=False)\n",
    "            cluster_indx.extend(list(rand_indx))\n",
    "        w_l_cluster_indx.append(cluster_indx)\n",
    "    \n",
    "    clusterY = pd.concat(\n",
    "        [InY_w.iloc[w_l_cluster_indx[0]],InY_l.iloc[w_l_cluster_indx[1]]]\n",
    "         ).reset_index(drop=True).sample(frac=1)\n",
    "    clusterX = pd.concat(\n",
    "        [InX_w.iloc[w_l_cluster_indx[0]],InX_l.iloc[w_l_cluster_indx[1]]]\n",
    "         ).reset_index(drop=True).iloc[clusterY.index]\n",
    "    if match is False:\n",
    "        print(\"Using clustered data\")\n",
    "        return clusterX, clusterY\n",
    "    else:\n",
    "        print(\"Using Randomly Matched Data\")\n",
    "        matchY_w = InY_w.sample(n=len(w_l_cluster_indx[0]),replace=False)\n",
    "        matchY_l = InY_l.sample(n=len(w_l_cluster_indx[1]),replace=False)\n",
    "    \n",
    "        matchY = pd.concat([matchY_w,matchY_l]).reset_index(drop=True).sample(frac=1)  \n",
    "        matchX = pd.concat(\n",
    "            [InX_w.iloc[matchY_w.index], InX_l.iloc[matchY_l.index]]\n",
    "            ).reset_index(drop=True).iloc[matchY.index]\n",
    "        return matchX, matchY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223ed7a-dd6a-4f04-ba2c-711551e1a4af",
   "metadata": {},
   "source": [
    "### Random Forest functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3244e03-63f5-45f2-b28d-dfcd6b7bc8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rf_objective(trial, rfaX, rfaY):\n",
    "    list_trees = [75, 100, 125, 150, 175, 200, 250, 300, 400, 500]\n",
    "    max_depth = [5, 10, 30, 50, 80, 90, 100, 110]\n",
    "    min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "    min_samples_split = [2, 4, 8, 10]\n",
    "    bootstrap = [True, False]\n",
    "    max_features = ['auto', 'sqrt', 'log2']\n",
    "    \n",
    "    param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
    "        'max_depth':trial.suggest_categorical('max_depth', max_depth), \n",
    "        'min_samples_split':trial.suggest_categorical('min_samples_split', min_samples_split), \n",
    "        'min_samples_leaf':trial.suggest_categorical('min_samples_leaf', min_samples_leaf), \n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', bootstrap),\n",
    "        'criterion':'gini', \n",
    "        'max_features':trial.suggest_categorical('max_features', max_features), \n",
    "        'max_leaf_nodes':None, \n",
    "        'min_impurity_decrease':0.0, \n",
    "        'oob_score':False, \n",
    "        'n_jobs':-1, \n",
    "        'verbose':0, \n",
    "        'warm_start':False, \n",
    "        'class_weight':None, \n",
    "        'ccp_alpha':0.0, \n",
    "        'max_samples':None\n",
    "                      }\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    cv_scores = np.empty(5)\n",
    "    \n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(rfaX,rfaY)):\n",
    "        X_train, X_val = rfaX.iloc[train_idx], rfaX.iloc[val_idx]\n",
    "        y_train, y_val = rfaY.iloc[train_idx],  rfaY.iloc[val_idx]\n",
    "\n",
    "        model = skRF(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores[idx] = f1_score(y_val, preds)\n",
    "        if cv_scores[idx] == 0.0:\n",
    "            print('Pruning because of 0.0 score.')\n",
    "            return 0.0\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca239ea1-6081-466a-9458-c158eb7f2393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def running_rfa(num_trials, rfaX, rfaY):\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    study = optuna.create_study(\n",
    "        study_name='RF Tuning Grid Search', direction='maximize',\n",
    "        sampler=optuna.samplers.GridSampler(search_space))\n",
    "    study.optimize(\n",
    "        lambda trial: rf_objective(trial, rfaX, rfaY), \n",
    "        n_trials=num_trials, timeout=30*600)\n",
    "    trials = study.best_trials            \n",
    "    max_trial_score = max([trial.values[0] for trial in trials])\n",
    "    max_trial_params = [trial.params for trial in trials \n",
    "                        if trial.values[0] == max_trial_score][0]\n",
    "    max_trial_params['n_jobs'] = -1\n",
    "    return max_trial_score, max_trial_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4baa2cf-000f-4119-8f05-26a9384eb67a",
   "metadata": {},
   "source": [
    "### Running the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bb0fe47-657c-4bdd-b41d-cb8e70068281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/v2.0.1/MOD09_GLOBAL_5469777_2_0_1.parquet.gzip\n",
      "Input Variables Index(['sur_refl_b01_1', 'sur_refl_b02_1', 'sur_refl_b07_1', 'ndvi'], dtype='object')\n",
      "data shape: (4375821, 4), (4375821,)\n",
      "\n",
      "CPU times: user 3.63 s, sys: 940 ms, total: 4.57 s\n",
      "Wall time: 4.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ############################\n",
    "# # VERSION 4.2.1 (targeted 500k points)\n",
    "# v421_X, v421_y, v421_water_i, v421_land_i  = pre_process_data('Golden','v4.2.1',['x_offset','y_offset','year','julian_day','tileID'])\n",
    "# #############################\n",
    "\n",
    "##############################\n",
    "# VERSION 2.0.1 (5 million points)\n",
    "v201_X, v201_y, v201_water_i, v201_land_i = pre_process_data('GLOBAL','v2.0.1',['x_offset','y_offset','year','julian_day'])\n",
    "##############################\n",
    "\n",
    "# ##############################\n",
    "# VERSION 0.0.0 (2billion data points)\n",
    "# v000_X, v000_y = read_in_file('cleaned','AGU',[])\n",
    "# ###############################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fccb8-3634-4481-9282-796c6c63ff1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7850ead-84e0-449f-8b3f-97bc45ec18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10\n",
    "num_trials = 25\n",
    "cluster_name = ['EBmatch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "322d8541-74f4-4d5b-b279-38bb0a297a7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3247026218.py, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 43\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'\\nMax score for {cluster_type}: {best_score},'+/\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "best_trial_data = {}\n",
    "\n",
    "for cluster_type in cluster_name:\n",
    "    start_time = time.time()\n",
    "    print(f'\\n{cluster_type}')\n",
    "    trial_scores, trial_data_size, rfa_trials = np.array([]), np.array([]),np.array([])\n",
    "    rfa_preds, rfa_labels = np.array([]), np.array([])\n",
    "    for i in np.arange(num_iterations):\n",
    "        print(f'Iteration: {i}')\n",
    "        if 'EB' in cluster_type:\n",
    "            if 'match' in cluster_type: \n",
    "                rfa_pred, rfa_label = kmeans_clustering(\n",
    "                    'Even Balance', v201_X, v201_y, v201_water_i, v201_land_i, match=True)\n",
    "            else: \n",
    "                rfa_pred, rfa_label = kmeans_clustering(\n",
    "                    'Even Balance', v201_X, v201_y, v201_water_i, v201_land_i, match=False)\n",
    "        if 'P' in cluster_type:\n",
    "            if 'match' in cluster_type: \n",
    "                rfa_pred, rfa_label = kmeans_clustering(\n",
    "                    'Percent', v201_X, v201_y, v201_water_i, v201_land_i, match=True)\n",
    "            else: \n",
    "                rfa_pred, rfa_pred = kmeans_clustering(\n",
    "                    'Percent', v201_X, v201_y, v201_water_i, v201_land_i, match=False)       \n",
    "        \n",
    "        score, param = running_rfa(num_trials, rfa_pred, rfa_label)\n",
    "        tuned_classifier = skRF(**param)\n",
    "        tuned_classifier.fit(rfa_pred , rfa_label)\n",
    "       \n",
    "        # Append info to the lists\n",
    "        rfa_preds = np.append(rfa_preds, rfa_pred)\n",
    "        rfa_labels = np.append(rfa_labels, rfa_label)\n",
    "        rfa_trials = np.append(rfa_trials, tuned_classifier)\n",
    "        trial_scores = np.append(trial_scores, score)\n",
    "        del tuned_classifier, rfa_pred, rfa_pred\n",
    "    \n",
    "    #Get max score of iterations\n",
    "    best_score_indx = np.argmax(trial_scores)\n",
    "    best_score = int(np.round(trial_scores[max_score_indx],3)*100)\n",
    "    best_rfa = rfa_trials[max_score_indx]       \n",
    "    best_trial_data[cluster_type] = (rfa_preds[max_score_indx], rfa_labels[max_score_indx]) \n",
    "    \n",
    "    #Print out info \n",
    "    print(f'\\nMax score for {cluster_type}: {best_score},'+/ \n",
    "           f'{len(rfa_preds[best_score_indx])} Samples')\n",
    "    rfa_filename = f'rfa_models/MODIS_RFA_v201_{cluster_type}_MaxScore{best_score}_SfcRef127ndvi.pkl'\n",
    "    print(f'Saving random forest to: {rfa_filename}')\n",
    "    \n",
    "    #Output rfa file\n",
    "    pickle.dump(best_rfa, open(rfa_filename, 'wb'))\n",
    " \n",
    "    #Print out time length \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Execution time: {time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))}\\n')\n",
    "    print(best_rfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14903308-fb43-460a-99b1-693b8cdf4fa4",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e8879-a05e-4a1a-87e3-061ac0d5f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_trial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed094c0f-363c-46db-89e0-944575ecfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2,figsize=(20, 10))\n",
    "# var=0\n",
    "# for col in range(2):\n",
    "#     ax[col, 0].set_ylabel('Frequency') \n",
    "#     for row in range(2):\n",
    "#         variable=P_cluster_X.columns[var]\n",
    "#         if 'ndvi' in variable: var_bins = bin_boundaries\n",
    "#         else: var_bins=None\n",
    "#         ax[row, col].hist(\n",
    "#             [   \n",
    "#                 v201_X[variable].values,\n",
    "#                 P_cluster_X[variable].values,\n",
    "#                 # P_match_X[variable].values,\n",
    "#                 EB_cluster_X[variable].values,\n",
    "#                 # EB_match_X[variable].values,\n",
    "#             ],\n",
    "#             label=[\n",
    "#                 #Change these \n",
    "#                 'v2.0.1',\n",
    "#                 'Percent Cluster',\n",
    "#                 # 'Percent Match',\n",
    "#                 'EB Cluster'\n",
    "#                 # 'EB Match'\n",
    "#             ],\n",
    "#             bins=var_bins,\n",
    "#         color=['orange',\n",
    "#                'brown',\n",
    "#                # 'steelblue',\n",
    "#                'lightgreen'\n",
    "#                # 'pink'\n",
    "#               ]) #, log=True) \n",
    "#         ax[row, col].set_xlabel(f'{variable}')\n",
    "#         var+=1\n",
    "#     ax[0,0].legend(loc='upper right',fontsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133868b4-66bb-4f85-bcb2-641a79f06e2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75088f-e9a1-4f6a-b34e-96b60a4ba9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EB_cluster_X, EB_cluster_y, EB_match_X, EB_match_y = kmeans_clustering(\n",
    "#     'Even Balance', v201_X, v201_y, v201_water_i, v201_land_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb9fb1-e6c0-447d-9821-57e33e004038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_cluster_X, P_cluster_y, P_match_X, P_match_y = kmeans_clustering(\n",
    "#     'Percent', v201_X, v201_y, v201_water_i, v201_land_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76526a20-7aac-4466-94ea-2b3621e79511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin_boundaries =  [*range(-10000,0,1000)] + [*range(0,10001,1000)]\n",
    "# plt.figure(figsize=(10,5))\n",
    "# # plt.hist(v201_X['ndvi'].values, label='Total Values',rwidth=0.5,bins=bin_boundaries)\n",
    "# plt.hist(P_cluster_X['ndvi'].values, label='Percent Cluster',\n",
    "#          bins=bin_boundaries,color='red',histtype ='bar')\n",
    "# plt.hist(EB_cluster_X['ndvi'].values, label='Even Balanced Cluster',\n",
    "#          bins=bin_boundaries,color='black',histtype ='bar')\n",
    "\n",
    "# plt.ylabel('Frequency',fontsize=12)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae927b8-cd3b-4e20-9689-23dff97ad1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0276abf7-ae38-4e96-b250-3e25238de329",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Recalculating NDVI manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d231ff-be4f-4bf0-b9de-e0fbace04f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_ndvi = np.where(X['ndvi'].values < 0.0)[0]\n",
    "# percent_neg_ndvi = len(neg_ndvi)/len(X['ndvi'].values)\n",
    "# how_many_water = np.where(y.iloc[neg_ndvi] > 0.5)[0]\n",
    "# how_many_land = np.where(y.iloc[neg_ndvi] < 0.5)[0]\n",
    "# print(len(how_many_water))\n",
    "# print(len(how_many_land))\n",
    "# print(len(neg_ndvi))\n",
    "\n",
    "# print(percent_neg_ndvi)\n",
    "# print(X.iloc[neg_ndvi,:].head())\n",
    "# print(y.iloc[neg_ndvi].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ad173-8495-4809-91c9-7757636daba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bin_boundaries =  [*range(-10000,0,1000)] + [*range(0,10001,1000)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219a2ca-012b-4fea-804d-2bdac8cec747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "# trials = study.best_trials\n",
    "# trial_score = max([trial.values[0]\n",
    "#                    for trial in trials])\n",
    "# best_trial_params = [trial.params for trial in trials if trial.values[0] == trial_score][0]\n",
    "# print(best_trial_params)\n",
    "# print(trial_score)\n",
    "# score_print = np.round(trial_score,4)\n",
    "# print(score_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb27e0f-3ab7-41f8-bda7-2c0e7564578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = best_trial_params\n",
    "# hyperparameters['n_jobs'] = -1\n",
    "# print('Using these params:')\n",
    "# print(hyperparameters)\n",
    "# tuned_classifier = skRF(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3220fba-351e-4bc5-9e24-f2af5dcf901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickled_model = pickle.load(open('rfa_models/MODIS_RFA_v201_EBCluster_sfcref127ndvi_4.pkl', 'rb'))\n",
    "# print(pickled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e05495-91b9-4ca8-9a14-26e0fa8ac422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EB_rand_X_rfa: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'bootstrap': True, 'max_features': 'log2'} 0.9785175070775922\n",
    "#Per_rand_X_rfa: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3, 'bootstrap': True, 'max_features': 'auto', 'n_jobs': -1} 0.9773275135496542\n",
    "#EB_cluster_X_rfa: {'n_estimators': 200, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'bootstrap': True, 'max_features': 'sqrt'} 0.9668007117784662\n",
    "#Per_cluster_X_rfa: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': True, 'max_features': 'auto', 'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee12a19-8cf8-472d-ba4d-e269e7356272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EB1: 0.9121361508267432\n",
    "# EB2: 0.9152120215067565\n",
    "# EB3: 0.9153888116216589\n",
    "# EB4: 0.9334065797136774\n",
    "# EB5: 0.9330483639924072\n",
    "# EB6: 0.9325007563612594\n",
    "# EB7: 13875 12950 0.9330562509477165\n",
    "# EB8: 14220 13272 0.9119937102685194 \n",
    "# EB9: 13875 12950 0.9318627771973583\n",
    "# EB10: 14220 13272 0.9128319097402475\n",
    "\n",
    "# %1: 359648 295422 0.9778067788170863\n",
    "# %2: 359649 295421 0.977828848863204\n",
    "# %3: 359649 295421 0.977814397217147\n",
    "# %4: 359648 295421 0.9777926266177195\n",
    "# %5: 359650 295422 0.9778923365411023\n",
    "# %6: 359843 295233 0.9779668774041262\n",
    "# %7: 359841 295230 0.977761799842581\n",
    "# %8: 359840 296518 0.977231470922011\n",
    "# %9: 359835 295223 0.977650365098458\n",
    "# %10: 359837 295222 0.9778535497660246\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (TensorFlow)",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
