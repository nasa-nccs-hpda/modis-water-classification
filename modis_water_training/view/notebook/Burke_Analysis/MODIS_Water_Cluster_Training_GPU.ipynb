{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b714c30-b71c-43c6-9fe3-9b012a7bfdfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  MODIS Water Cluster Training\n",
    "\n",
    "Version: 0.1.0\n",
    "\n",
    "Date modified: 05.01.2023\n",
    "\n",
    "Modified by: Amanda Burke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef8ad40-b2c6-4ccc-9a4b-c595bcce20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import math \n",
    "import pandas as pd\n",
    "from pathlib import Path   \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "# plt.style.use('fivethirtyeight')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, matthews_corrcoef\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold\n",
    "#from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# #GDAL Stuff\n",
    "# from osgeo import gdalconst\n",
    "# from osgeo import gdal\n",
    "# from pprint import pprint\n",
    "\n",
    "# # GPU-based frameworks\n",
    "\n",
    "# import cudf\n",
    "# import cupy as cp\n",
    "# from cuml.ensemble import RandomForestClassifier as cuRFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411a1108-f8dd-4339-a6b1-91697b19b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_pickle('MODIS_RFA_v201_NoCluster_sfcref127ndvi.pkl')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169c7a95-24a1-4ceb-9036-27369d259e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef09a8be-17ed-40a8-958e-ed66b83929bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'rf'\n",
    "TEST_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "LABEL_NAME = 'water'\n",
    "if GPU is False:\n",
    "    DATA_TYPE = np.int16\n",
    "else: \n",
    "    DATA_TYPE = cp.float32\n",
    "FRAC_LAND=0.5\n",
    "num_datapoints = 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb0fe47-657c-4bdd-b41d-cb8e70068281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/v2.0.1/MOD09_GLOBAL_5469777_2_0_1.parquet.gzip']\n",
      "/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/v2.0.1/MOD09_GLOBAL_5469777_2_0_1.parquet.gzip\n"
     ]
    }
   ],
   "source": [
    "# #############################\n",
    "# # VERSION 4.2.1 (targeted 500k points)\n",
    "# TILE_IN = 'Golden'#v4.2.1\n",
    "# DATA_VERSION='v4.2.1'\n",
    "# offsets_indexes = ['x_offset', 'y_offset', 'year', 'julian_day','tileID']\n",
    "# #############################\n",
    "\n",
    "##############################\n",
    "#VERSION 2.0.1 (5 million points)\n",
    "TILE_IN = 'GLOBAL'#v2.0.1\n",
    "DATA_VERSION='v2.0.1'\n",
    "offsets_indexes = ['x_offset', 'y_offset', 'year', 'julian_day']\n",
    "##############################\n",
    "\n",
    "# #############################\n",
    "# #VERSION 0.0.0 (2billion data points)\n",
    "# TILE_IN = 'cleaned'#v0.0.0\n",
    "# DATA_VERSION='AGU'\n",
    "# offsets_indexes = []#'x_offset', 'y_offset', 'year', 'julian_day']\n",
    "# ##############################\n",
    "\n",
    "training_data_basepath = f'/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/{DATA_VERSION}'\n",
    "glob_string = os.path.join(training_data_basepath,'MOD*{}*.parquet.gzip'.format(TILE_IN))\n",
    "data_paths = sorted([fv for fv in glob.glob(glob_string)])\n",
    "\n",
    "#Only want the one with 4.2.0 because the other file doesnt work. \n",
    "print(data_paths)\n",
    "data_path = data_paths[0]\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fd27567-2a51-4e94-8d0a-43504a90bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpu_data(fpath, colsToDrop, yCol='water', testSize=0.2, randomState=42, \n",
    "            dataType=np.float32, cpu=True, splitXY=False, trainTestSplit=False,\n",
    "            applyLog=False, imbalance=False, frac=0.1, land=False, multi=False, \n",
    "            multisample=1000000):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by models\n",
    "    :param fpath: Path to the data to be ingested.\n",
    "    :param dataType: Data type to convert ingested data to.\n",
    "    :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "    :param testSize: Ration to\n",
    "    \"\"\"\n",
    "    if multi:\n",
    "        all_dfs = [pd.read_csv(path_) for path_ in fpath]\n",
    "        df = pd.concat(all_dfs).sample(n=multisample, random_state=randomState)\n",
    "        print('DF length: {}'.format(len(df.index)))\n",
    "    else:   \n",
    "        df = pd.read_parquet(fpath) if '.parquet' in fpath else pd.read_csv(fpath)\n",
    "    df = df[df['sur_refl_b01_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b07_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b06_1'] + df['sur_refl_b02_1'] != 0]\n",
    "\n",
    "    df = df.drop(columns=colsToDrop)\n",
    "    cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0).astype(dataType)\n",
    "    if applyLog:\n",
    "        for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "            print('Applying log1p func to {}'.format(col))\n",
    "            cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "        cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    df = None\n",
    "    if imbalance:\n",
    "        if land:\n",
    "            print('Imbalancing data, sampling {} from water'.format(frac))\n",
    "        else:\n",
    "            print(f'Imbalancing data, sampling {frac} from land, {1-frac} from water')\n",
    "        groupedDF = cleanedDF.groupby('water')\n",
    "        dfs = [groupedDF.get_group(y) for y in groupedDF.groups]\n",
    "        sampledDF = dfs[1].sample(frac=frac)if land else dfs[0].sample(frac=frac)\n",
    "        concatDF = sampledDF.append(dfs[0]) if land else sampledDF.append(dfs[1])\n",
    "        concatDF = concatDF.sample(frac=1)\n",
    "        concatDF = concatDF.reset_index()\n",
    "        cleanedDF = concatDF.drop(columns=['index'])\n",
    "    if not splitXY:\n",
    "        return cleanedDF\n",
    "    X = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    y = cleanedDF[yCol].astype(dataType)\n",
    "    if trainTestSplit:\n",
    "        return train_test_split(X, y, test_size=TEST_RATIO)\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea32a90-09e3-4d33-8a91-c62cecaa548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_gpu_data(fpath, colsToDrop, yCol='water', testSize=0.2, randomState=42, \n",
    "#             dataType=cp.float32, cpu=False, splitXY=True, trainTestSplit=True,\n",
    "#             applyLog=False, imbalance=False, frac=0.1, land=False, multi=False, \n",
    "#             multisample=1000000):\n",
    "#     \"\"\"\n",
    "#     Simple helper function for loading data to be used by models\n",
    "#     :param fpath: Path to the data to be ingested.\n",
    "#     :param dataType: Data type to convert ingested data to.\n",
    "#     :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "#     :param testSize: Ration to\n",
    "#     \"\"\"\n",
    "#     if multi:\n",
    "#         all_dfs = [pd.read_csv(path_) for path_ in fpath]\n",
    "#         df = pd.concat(all_dfs).sample(n=multisample, random_state=randomState)\n",
    "#         print('DF length: {}'.format(len(df.index)))\n",
    "#     else:   \n",
    "#         df = pd.read_parquet(fpath) if '.parquet' in fpath else pd.read_csv(fpath)\n",
    "#     df = df[df['sur_refl_b01_1'] + df['sur_refl_b02_1'] != 0]\n",
    "#     df = df[df['sur_refl_b07_1'] + df['sur_refl_b02_1'] != 0]\n",
    "#     df = df[df['sur_refl_b06_1'] + df['sur_refl_b02_1'] != 0]\n",
    "#     df = df.drop(columns=colsToDrop)\n",
    "#     cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0).astype(dataType)\n",
    "#     cleanedDF = cudf.from_pandas(cleanedDF) if not cpu else cleanedDF\n",
    "#     if applyLog:\n",
    "#         for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "#             print('Applying log1p func to {}'.format(col))\n",
    "#             cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "#         cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "#     df = None\n",
    "#     if imbalance:\n",
    "#         if land:\n",
    "#             print('Imbalancing data, sampling {} from water'.format(frac))\n",
    "#         else:\n",
    "#             print('Imbalancing data, sampling {} from land'.format(frac))\n",
    "#         groupedDF = cleanedDF.groupby('water')\n",
    "#         dfs = [groupedDF.get_group(y) for y in groupedDF.groups]\n",
    "#         sampledDF = dfs[1].sample(frac=frac)if land else dfs[0].sample(frac=frac)\n",
    "#         concatDF = sampledDF.append(dfs[0]) if land else sampledDF.append(dfs[1])\n",
    "#         concatDF = concatDF.sample(frac=1)\n",
    "#         concatDF = concatDF.reset_index()\n",
    "#         cleanedDF = concatDF.drop(columns=['index'])\n",
    "#     if not splitXY:\n",
    "#         return cleanedDF\n",
    "#     X = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "#     y = cleanedDF[yCol].astype(dataType)\n",
    "#     cleanedX = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "#     cleanedy = cleanedDF[yCol].astype(dataType)\n",
    "#     if trainTestSplit:\n",
    "#         return train_test_split(cleanedX, cleanedy, test_size=TEST_RATIO)\n",
    "#     else:\n",
    "#         return cleanedX, cleanedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdee2440-7931-4da3-80e7-f79aefcb15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToDrop = [\n",
    "    # 'sur_refl_b01_1',\n",
    "    # 'sur_refl_b02_1',\n",
    "    'sur_refl_b03_1',\n",
    "    'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
    "    # 'sur_refl_b07_1',\n",
    "    # 'ndvi',\n",
    "    'ndwi1','ndwi2'\n",
    "        ]\n",
    "\n",
    "colsToDropTraining = colsToDrop.copy()\n",
    "colsToDropTraining.extend(offsets_indexes)\n",
    "v_names = ['sur_refl_b01_1','sur_refl_b02_1','sur_refl_b03_1',\n",
    "           'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
    "           'sur_refl_b07_1','ndvi','ndwi1','ndwi2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133868b4-66bb-4f85-bcb2-641a79f06e2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8a3852-14ee-4615-bc7c-871046ca19e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sur_refl_b03_1',\n",
       " 'sur_refl_b04_1',\n",
       " 'sur_refl_b05_1',\n",
       " 'sur_refl_b06_1',\n",
       " 'ndwi1',\n",
       " 'ndwi2']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colsToDrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb281755-23fe-4789-ba8b-584105111691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (4375821, 4), (4375821,)\n",
      "CPU times: user 3.65 s, sys: 1.04 s, total: 4.69 s\n",
      "Wall time: 4.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_data_params = {'fpath':data_path,'colsToDrop':colsToDropTraining,'splitXY':True,\n",
    "                    'imbalance':False,'trainTestSplit':True}\n",
    "\n",
    "# print(load_data_params)\n",
    "\n",
    "if GPU is False: \n",
    "    X, X_test, y, y_test = load_cpu_data(**load_data_params)\n",
    "else: \n",
    "    X, X_test, y, y_test = load_gpu_data(**load_data_params)\n",
    "        \n",
    "# X = X.iloc[:num_datapoints,:] \n",
    "# y = y.iloc[:num_datapoints] \n",
    "\n",
    "# X_test = X_test.iloc[:num_datapoints,:] \n",
    "# y_test = y_test.iloc[:num_datapoints] \n",
    "\n",
    "print(f'data shape: {X.shape}, {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f34f70-3e05-4c0b-9a0c-3ce093cfca33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a444a79c-1f48-4093-8a74-63636ca44092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sur_refl_b01_1</th>\n",
       "      <th>sur_refl_b02_1</th>\n",
       "      <th>sur_refl_b07_1</th>\n",
       "      <th>ndvi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4423372</th>\n",
       "      <td>58.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-10350.876953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037063</th>\n",
       "      <td>2196.0</td>\n",
       "      <td>2455.0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>556.869507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888872</th>\n",
       "      <td>240.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2961.876953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284286</th>\n",
       "      <td>816.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>1258.0</td>\n",
       "      <td>4401.372070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018719</th>\n",
       "      <td>44.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>-18387.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512927</th>\n",
       "      <td>420.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>6533.223145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403713</th>\n",
       "      <td>553.0</td>\n",
       "      <td>2213.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>6001.446289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415244</th>\n",
       "      <td>419.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>5573.164062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582120</th>\n",
       "      <td>54.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-21764.705078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4864755</th>\n",
       "      <td>803.0</td>\n",
       "      <td>3085.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>5869.341797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4375821 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sur_refl_b01_1  sur_refl_b02_1  sur_refl_b07_1          ndvi\n",
       "4423372            58.0            -1.0             9.0 -10350.876953\n",
       "4037063          2196.0          2455.0          2345.0    556.869507\n",
       "1888872           240.0           442.0            87.0   2961.876953\n",
       "4284286           816.0          2099.0          1258.0   4401.372070\n",
       "1018719            44.0           -13.0            94.0 -18387.097656\n",
       "...                 ...             ...             ...           ...\n",
       "5512927           420.0          2003.0           713.0   6533.223145\n",
       "3403713           553.0          2213.0           684.0   6001.446289\n",
       "3415244           419.0          1474.0           810.0   5573.164062\n",
       "3582120            54.0           -20.0            37.0 -21764.705078\n",
       "4864755           803.0          3085.0           824.0   5869.341797\n",
       "\n",
       "[4375821 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeedbf70-0110-4ee4-81ec-afcce883ac05",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5788ef49-6c9f-4827-825b-8a29a1fbe208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (1976866, 4), (2398955, 4)\n"
     ]
    }
   ],
   "source": [
    "#Getting the indices that are associated with land (0) and water (1)\n",
    "y_water_ind = np.where(y>0.5)[0]\n",
    "y_land_ind = np.where(y<0.5)[0]\n",
    "\n",
    "#Subset the X AND y data to later/ subset with the clusters and then combine for RFA\n",
    "X_water = X.iloc[y_water_ind,:]\n",
    "y_water = y.iloc[y_water_ind]\n",
    "\n",
    "X_land = X.iloc[y_land_ind,:]\n",
    "y_land = y.iloc[y_land_ind]\n",
    "print(f'data shape: {X_water.shape}, {X_land.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b38dfe2-a25e-4656-a5e8-444addd34398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sur_refl_b01_1\n",
      "sur_refl_b02_1\n",
      "sur_refl_b07_1\n",
      "ndvi\n"
     ]
    }
   ],
   "source": [
    "_ = [print(column) for column in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82998bd2-524f-439d-bbd8-200287d0faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_VERSION='v4.2.1'\n",
    "# training_data_basepath = f'/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/{DATA_VERSION}'\n",
    "\n",
    "# #VERSION 4.2.1\n",
    "# TILE_IN = 'Golden'#v4.2.1\n",
    "# offsets_indexes = ['x_offset', 'y_offset', 'year', 'julian_day','tileID']\n",
    "\n",
    "# glob_string = os.path.join(training_data_basepath,'MOD*{}*.parquet.gzip'.format(TILE_IN))\n",
    "# data_paths = sorted([fv for fv in glob.glob(glob_string)])\n",
    "\n",
    "# #Only want the one with 4.2.0 because the other file doesnt work. \n",
    "# print(data_paths)\n",
    "# data_path = data_paths[0]\n",
    "# print(data_path)\n",
    "# colsToDropTraining = colsToDrop.copy()\n",
    "# colsToDropTraining.extend(offsets_indexes)\n",
    "\n",
    "\n",
    "# X_target, X_test_target, y_target, y_test_target = load_data(fpath=data_path,\n",
    "#                                 colsToDrop=colsToDropTraining,\n",
    "#                                 dataType=DATA_TYPE,\n",
    "#                                 cpu=True,\n",
    "#                                 splitXY=True,\n",
    "#                                 trainTestSplit=True\n",
    "#                                 )\n",
    "\n",
    "# X_target = X_target.iloc[:num_datapoints,:] \n",
    "# y_target = y_target.iloc[:num_datapoints] \n",
    "\n",
    "# X_test_target = X_test_target.iloc[:num_datapoints,:] \n",
    "# y_test_target = y_test_target.iloc[:num_datapoints] \n",
    "\n",
    "# print(f'\\n\\ntarget subset data shape: {X_target.shape}, {y_target.shape}')\n",
    "\n",
    "# #Getting the indices that are associated with land (0) and water (1)\n",
    "# #Subset the X AND y data to later subset with the clusters and then combine for RFA\n",
    "# X_water_target = X_target.iloc[np.where(y_target>0.5)[0],:]\n",
    "# X_land_target = X_target.iloc[np.where(y_target<0.5)[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3a1ce-bb9e-4789-bbd1-bcfe2c913785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89fdd11d-a3b3-4733-b95f-f5cb8bd80fc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clustering Data for Input to Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e0854-39fc-409d-82ce-9d340243778b",
   "metadata": {},
   "source": [
    "Based on the cluster analysis above on 5.03.23, 15 clusters appears to have the most data and exclude outliers so will use that number for selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "860899fd-59ae-420d-ac0b-a1ad8940f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_NUM=15\n",
    "\n",
    "common_params = {\n",
    "    \"n_init\": \"auto\",\n",
    "    # \"random_state\": 42,\n",
    "    \"init\":\"random\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14fadaa2-f0c0-43d0-8048-de4c7ef01329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 2.66 s, total: 2min 17s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kme_land_random =  KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_land)\n",
    "kmeans_output_land_random = kme_land_random.predict(X_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08b9ac07-2215-4e65-ab83-e67411dec00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 1.36 s, total: 1min 9s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kme_water_random = KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_water)\n",
    "kmeans_output_water_random = kme_water_random.predict(X_water)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf9549-0236-4f29-a8a3-c1a2d0ab60e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Even Balanced Random pulled datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42a34ff7-b94d-472b-8e8b-633272252473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 49\n",
      "4 4 49\n"
     ]
    }
   ],
   "source": [
    "COUNT_EVEN_BALANCE_LAND = np.inf\n",
    "COUNT_EVEN_BALANCE_WATER = np.inf\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    land_num = len(np.where(kmeans_output_land_random == cluster)[0])\n",
    "    water_num = len(np.where(kmeans_output_water_random == cluster)[0])\n",
    "    if land_num < COUNT_EVEN_BALANCE_LAND: COUNT_EVEN_BALANCE_LAND = land_num\n",
    "    if water_num < COUNT_EVEN_BALANCE_WATER: COUNT_EVEN_BALANCE_WATER = water_num\n",
    "    \n",
    "print(COUNT_EVEN_BALANCE_LAND, COUNT_EVEN_BALANCE_WATER)\n",
    "if COUNT_EVEN_BALANCE_LAND < COUNT_EVEN_BALANCE_WATER:\n",
    "    COUNT = COUNT_EVEN_BALANCE_LAND\n",
    "else: \n",
    "    COUNT = COUNT_EVEN_BALANCE_WATER\n",
    "print(COUNT,COUNT_EVEN_BALANCE_LAND,COUNT_EVEN_BALANCE_WATER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "660e6139-cb3b-4595-9469-215a1252db02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0\n",
      "cluster 1\n",
      "cluster 2\n",
      "cluster 3\n",
      "cluster 4\n",
      "cluster 5\n",
      "cluster 6\n",
      "cluster 7\n",
      "cluster 8\n",
      "cluster 9\n",
      "cluster 10\n",
      "cluster 11\n",
      "cluster 12\n",
      "cluster 13\n",
      "cluster 14\n",
      "(60,) (60,)\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "random_ind_land = np.array([])\n",
    "random_ind_water = []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water = np.append(random_ind_water, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT,replace=False)\n",
    "    random_ind_land = np.append(random_ind_land, random_pts_land)\n",
    "    \n",
    "random_ind_water = random_ind_water.astype('int')\n",
    "random_ind_land = random_ind_land.astype('int')\n",
    "\n",
    "print(np.shape(random_ind_water),np.shape(random_ind_land))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61637e1f-2741-4bf4-9745-c6a2e521d16a",
   "metadata": {},
   "source": [
    "# THE DATES TO PULL IN VIIRS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e230982-aa17-48ae-ac01-963766ac0309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (4375821, 8), (4375821,)\n",
      "CPU times: user 6.03 s, sys: 2.29 s, total: 8.33 s\n",
      "Wall time: 7.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This set of parameters has the date/lat lon encoded \n",
    "\n",
    "load_data_params = {'fpath':data_path,'colsToDrop':colsToDrop,'splitXY':True,\n",
    "                    'imbalance':False,'trainTestSplit':True}\n",
    "\n",
    "# print(load_data_params)\n",
    "\n",
    "if GPU is False: \n",
    "    X_meta, X_meta, y_meta, y_meta = load_cpu_data(**load_data_params)\n",
    "else: \n",
    "    X_meta, X_meta, y_meta, y_meta = load_gpu_data(**load_data_params)\n",
    "\n",
    "print(f'data shape: {X_w_date.shape}, {y_w_date.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a4667a3-ada8-4ba2-a6eb-7135d0c01e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1439478,  438068,  730604, 1503219, 1509976, 1770749, 1190977,\n",
       "       1599469,  594781, 1102015, 1817470, 1745113, 1197818, 1212199,\n",
       "         23772,  390059,   14795, 1209277,  314210,  694903,  752054,\n",
       "        537682, 1712979,  516959, 1319815,   22178, 1673176, 1786381,\n",
       "        774458,  248623,  617242,  624232, 1865703,  442469,  107038,\n",
       "        914474,  954533,  939537, 1264737, 1333356,  353275,  721534,\n",
       "        249302,   59454,  715028,    4168,  533153, 1138907, 1705743,\n",
       "       1546762,  397961, 1519468,  688548,  781819,  209172, 1624426,\n",
       "        665362, 1582558,  181003,  627999, 1076402, 1611394, 1517693,\n",
       "        797320, 1572290, 1946907, 1866284, 1623656, 2301389,  759022,\n",
       "       1828056,   74701,  636832, 1463362, 1107487,  238254, 1868573,\n",
       "        813388, 2199747,  452622,  402285,  626479,  519152, 1365355,\n",
       "        884207,  313800,  436181, 1565850,  745461, 2380084,  541789,\n",
       "        265226, 2322677, 1461569, 1764940, 1804591, 1393325, 1145260,\n",
       "        773825, 1898864, 1533168,  971302, 1726816, 1460694,  854640,\n",
       "         69424,  655508,  746645, 2354570,  924332, 2263917, 1487178,\n",
       "        955428, 1539645, 1455779, 2217914, 1381312, 2194301,  558286,\n",
       "        872365])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([random_ind_water,random_ind_land])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50fbcb51-f38b-4d00-9063-9f8d847d28fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m total_cluster_inds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([random_ind_water,random_ind_land])\n\u001b[0;32m----> 2\u001b[0m cluster_meta_data \u001b[38;5;241m=\u001b[39m \u001b[43mX_meta\u001b[49m\u001b[38;5;241m.\u001b[39miloc[total_cluster_inds,\u001b[38;5;241m4\u001b[39m:]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(cluster_meta_data[cluster_meta_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2011.0\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_meta' is not defined"
     ]
    }
   ],
   "source": [
    "total_cluster_inds = np.concatenate([random_ind_water,random_ind_land])\n",
    "cluster_meta_data = X_meta.iloc[total_cluster_inds,4:]\n",
    "print(cluster_meta_data[cluster_meta_data['year' > 2011.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3cc0f-29ea-4a3d-baf2-d29f81a45357",
   "metadata": {
    "tags": []
   },
   "source": [
    "# THE OTHER STUFF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a4cca-556f-4e75-bc92-6361608f42c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Percentage Random pulled datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6a8c5-ad0e-4e6c-89b7-7e75526f654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the clusters: kmeans_output_land and kmeans_output_water\n",
    "# Data: X_water, X_land, y_water, y_land\n",
    "\n",
    "PERCENT_RANDOM_PULL = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa603ad-b373-4797-b1b2-cd966ef1c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "random_ind_land = np.array([])\n",
    "random_ind_water = []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    # cluster_ind_water = np.where(bgm_water == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_WATER = int(PERCENT_RANDOM_PULL*len(cluster_ind_water))\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT_RANDOM_PULL_WATER,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water = np.append(random_ind_water, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    # cluster_ind_land = np.where(bgm_land == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_LAND = int(PERCENT_RANDOM_PULL*len(cluster_ind_land))\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT_RANDOM_PULL_LAND,replace=False)\n",
    "    random_ind_land = np.append(random_ind_land, random_pts_land)\n",
    "    # print(f'Pulling {COUNT_RANDOM_PULL_WATER} Water pts and {COUNT_RANDOM_PULL_LAND} Land pts')\n",
    "    # print()\n",
    "random_ind_water = random_ind_water.astype('int')\n",
    "random_ind_land = random_ind_land.astype('int')\n",
    "\n",
    "print(len(random_ind_water),len(random_ind_land))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad8c21-d046-49b7-8bca-e4fb6cdf145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2,figsize=(20, 10))\n",
    "# var=0\n",
    "# for col in range(2):\n",
    "#     ax[col, 0].set_ylabel('Frequency') \n",
    "#     for row in range(2):\n",
    "#         variable=X_cpu.columns[var]\n",
    "#         if 'ndvi' in variable: \n",
    "#             continue\n",
    "#             var_bins = bin_boundaries\n",
    "#             log_values = False\n",
    "#         else: \n",
    "#             var_bins = None\n",
    "#             log_values = True\n",
    "#         ax[row, col].hist(\n",
    "#             [   \n",
    "#             X_cpu[variable][not_same_point.index].values\n",
    "#             ],\n",
    "#             label=[\n",
    "#             \"data\"\n",
    "#             ],\n",
    "#             bins=var_bins,\n",
    "#         color=['brown'], log=log_values) \n",
    "#         ax[row, col].set_xlabel(f'{variable}')\n",
    "#         var+=1\n",
    "#     ax[0,0].legend(loc='upper right',fontsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855d30f-505c-45cb-b02b-f94e5d38da4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d307387-dc6d-49ce-be7d-af4346607953",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Total random dataset used for training random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccec67-bee6-4314-b013-ca09089b09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_land_random = X_land.iloc[random_ind_land]\n",
    "y_cluster_land_random = y_land.iloc[random_ind_land]\n",
    "X_cluster_water_random = X_water.iloc[random_ind_water]\n",
    "y_cluster_water_random = y_water.iloc[random_ind_water]\n",
    "\n",
    "X_cluster_random = pd.concat([X_cluster_land_random,X_cluster_water_random])\n",
    "y_cluster_random = pd.concat([y_cluster_land_random,y_cluster_water_random])\n",
    "\n",
    "#Combine the data so that we can shuffle the indices and keep the data together that should be\n",
    "All_data_random = pd.concat([X_cluster_random,y_cluster_random],axis=1).sample(frac=1)\n",
    "\n",
    "X_cluster_rfa_random = All_data_random[X_cluster_random.columns]\n",
    "y_cluster_rfa_random = All_data_random['water']\n",
    "\n",
    "print(X_cluster_rfa_random)\n",
    "print(y_cluster_rfa_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27677834-c156-4527-9f1d-1e53b33a7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ind_land = np.random.choice(\n",
    "    np.arange(len(X_land)),len(random_ind_land),replace=False)\n",
    "print(random_ind_land)\n",
    "print(match_ind_land)\n",
    "\n",
    "match_ind_water = np.random.choice(\n",
    "    np.arange(len(X_water)),len(random_ind_water),replace=False)\n",
    "print(len(random_ind_water))\n",
    "print(len(match_ind_water))\n",
    "\n",
    "# X_match_land_random = X_land.iloc[match_ind_land]\n",
    "# y_match_land_random = y_land.iloc[match_ind_land]\n",
    "# X_match_water_random = X_water.iloc[match_ind_water]\n",
    "# y_match_water_random = y_water.iloc[match_ind_water]\n",
    "\n",
    "X_match_land_random = X_land.iloc[random_ind_land]\n",
    "y_match_land_random = y_land.iloc[random_ind_land]\n",
    "X_match_water_random = X_water.iloc[random_ind_water]\n",
    "y_match_water_random = y_water.iloc[random_ind_water]\n",
    "\n",
    "X_match_random = pd.concat([X_match_land_random,X_match_water_random])\n",
    "y_match_random = pd.concat([y_match_land_random,y_match_water_random])\n",
    "\n",
    "#Combine the data so that we can shuffle the indices and keep the data together that should be\n",
    "All_data_match_random = pd.concat([X_match_random,y_match_random],axis=1).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_match_rfa_random = All_data_match_random[X_match_random.columns]\n",
    "y_match_rfa_random = All_data_match_random['water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba98450-3b2d-46b7-8445-94e67036f79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(All_data_random)\n",
    "print(X_match_rfa_random)\n",
    "print(y_match_rfa_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce60e95-e471-4c4a-a292-7d3e4152cca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8be6ccf-6e47-4297-bb0b-92277c4fc231",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plotting paramater space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4907add-7b1c-4060-90c6-f971c49cc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kme_land_random =  KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_land)\n",
    "kmeans_output_land_random = kme_land_random.predict(X_land)\n",
    "kme_water_random = KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_water)\n",
    "kmeans_output_water_random = kme_water_random.predict(X_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76286d-7e58-444e-97ef-27cd5fa83dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "random_ind_land_eb = np.array([])\n",
    "random_ind_water_eb = []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water_eb = np.append(random_ind_water_eb, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT,replace=False)\n",
    "    random_ind_land_eb = np.append(random_ind_land_eb, random_pts_land)\n",
    "    \n",
    "random_ind_water_eb = random_ind_water_eb.astype('int')\n",
    "random_ind_land_eb = random_ind_land_eb.astype('int')\n",
    "\n",
    "print(random_ind_water_eb,random_ind_land_eb)\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "match_ind_land_eb = np.random.choice(np.arange(len(X_land)),len(random_ind_land_eb),replace=False)\n",
    "match_ind_water_eb = np.random.choice(np.arange(len(X_water)),len(random_ind_water_eb),replace=False)\n",
    "\n",
    "X_match_land_eb = X_land.iloc[match_ind_land_eb]\n",
    "X_match_water_eb = X_water.iloc[match_ind_water_eb]\n",
    "X_match_eb = pd.concat([X_match_land_eb,X_match_water_eb])\n",
    "\n",
    "X_cluster_land_eb = X_land.iloc[random_ind_land_eb]\n",
    "X_cluster_water_eb = X_water.iloc[random_ind_water_eb]\n",
    "X_cluster_eb = pd.concat([X_cluster_land_eb,X_cluster_water_eb])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac0359-2a9c-44c9-b68b-dff80958e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#############\n",
    "np.random.seed(42)\n",
    "random_ind_land_p = np.array([])\n",
    "random_ind_water_p= []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    # cluster_ind_water = np.where(bgm_water == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_WATER = int(PERCENT_RANDOM_PULL*len(cluster_ind_water))\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT_RANDOM_PULL_WATER,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water_p = np.append(random_ind_water_p, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    # cluster_ind_land = np.where(bgm_land == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_LAND = int(PERCENT_RANDOM_PULL*len(cluster_ind_land))\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT_RANDOM_PULL_LAND,replace=False)\n",
    "    random_ind_land_p = np.append(random_ind_land_p, random_pts_land)\n",
    "    print(f'Pulling {COUNT_RANDOM_PULL_WATER} Water pts and {COUNT_RANDOM_PULL_LAND} Land pts')\n",
    "    print()\n",
    "random_ind_water_p = random_ind_water_p.astype('int')\n",
    "random_ind_land_p = random_ind_land_p.astype('int')\n",
    "\n",
    "print(random_ind_water_p,random_ind_land_p)\n",
    "\n",
    "#############\n",
    "\n",
    "match_ind_land_p = np.random.choice(np.arange(len(X_land)),len(random_ind_land_p),replace=False)\n",
    "match_ind_water_p = np.random.choice(np.arange(len(X_water)),len(random_ind_water_p),replace=False)\n",
    "\n",
    "X_match_land_p = X_land.iloc[match_ind_land_p]\n",
    "X_match_water_p = X_water.iloc[match_ind_water_p]\n",
    "X_match_p = pd.concat([X_match_land_p,X_match_water_p])\n",
    "\n",
    "X_cluster_land_p = X_land.iloc[random_ind_land_p]\n",
    "X_cluster_water_p = X_water.iloc[random_ind_water_p]\n",
    "X_cluster_p = pd.concat([X_cluster_land_p,X_cluster_water_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da7981-4061-4f85-8c3b-5aef1a65fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2,figsize=(20, 10))\n",
    "var=0\n",
    "for col in range(2):\n",
    "    ax[col, 0].set_ylabel('Frequency') \n",
    "    for row in range(2):\n",
    "        variable=X_land.columns[var]\n",
    "        if 'ndvi' in variable: \n",
    "            # var_bins = bin_boundaries\n",
    "            log_values = False\n",
    "        else: \n",
    "            # var_bins = None\n",
    "            log_values = True\n",
    "        ax[row, col].hist(\n",
    "            [  \n",
    "            # X_cluster_eb[variable].values,\n",
    "            # X_match_eb[variable].values,\n",
    "            X_cluster_p[variable].values,\n",
    "            X_match_p[variable].values,\n",
    "            ],\n",
    "            label=[\n",
    "            # f\"EB Cluster {len(X_cluster_eb)}\",\n",
    "            # \"EB Match\",\n",
    "            f\"P Cluster {len(X_match_p)}\",\n",
    "            f\"P Match\"\n",
    "            ],\n",
    "            #bins=var_bins,\n",
    "        #color=['darkgreen','lightgreen','darkblue','lightblue'], log=log_values) \n",
    "        color=['plum','darkorchid'], log=log_values) \n",
    "        ax[row, col].set_xlabel(f'{variable}')\n",
    "        var+=1\n",
    "    ax[0,0].legend(loc='upper right',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b82dde-f9a2-40c5-a21a-c76837a96d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(1, 1,figsize=(10, 5))\n",
    "variable = X_land.columns[0]\n",
    "\n",
    "plt.hist(\n",
    "    [X_cluster_p[variable].values,\n",
    "     X_match_p[variable].values,\n",
    "    ],\n",
    "    label=[\n",
    "        f\"P Cluster {len(X_match_p)}\",\n",
    "        f\"P Match\"\n",
    "        ],\n",
    "    color=['plum','darkorchid'], log=True) \n",
    "\n",
    "plt.ylabel('Frequency') \n",
    "plt.xlabel(f'{variable}')\n",
    "plt.legend(loc='upper right',fontsize=20)   \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed9581-542c-433e-a139-1a45a83d9612",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3244e03-63f5-45f2-b28d-dfcd6b7bc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_rf_objective(trial):\n",
    "    list_trees = [75, 100, 125, 150, 175, 200, 250, 300, 400, 500]\n",
    "    max_depth = [5, 10, 30, 50, 80, 90, 100, 110]\n",
    "    min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "    min_samples_split = [2, 4, 8, 10]\n",
    "    bootstrap = [True, False]\n",
    "    max_features = ['auto', 'sqrt', 'log2']\n",
    "    \n",
    "    param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
    "       'max_depth':trial.suggest_categorical('max_depth', max_depth), \n",
    "       'min_samples_split':trial.suggest_categorical('min_samples_split', min_samples_split), \n",
    "       'min_samples_leaf':trial.suggest_categorical('min_samples_leaf', min_samples_leaf), \n",
    "       'bootstrap': trial.suggest_categorical('bootstrap', bootstrap),\n",
    "       'criterion':'gini', \n",
    "       #'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 1e-8, 1.0, log=True), \n",
    "       'max_features':trial.suggest_categorical('max_features', max_features), \n",
    "       'max_leaf_nodes':None, \n",
    "       'min_impurity_decrease':0.0, \n",
    "       'oob_score':False, \n",
    "       'n_jobs':-1, \n",
    "       # 'random_state':42, \n",
    "       'verbose':0, \n",
    "       'warm_start':False, \n",
    "       'class_weight':None, \n",
    "       'ccp_alpha':0.0, \n",
    "       'max_samples':None\n",
    "        }\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    #######################\n",
    "    # HERE IS WHERE TO CHANGE THE X,Y DATASET USED FOR TRAINING\n",
    "    #######################\n",
    "   \n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(X,y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # for idx, (train_idx, val_idx) in enumerate(cv.split(X_cluster_rfa_random,  y_cluster_rfa_random)):    \n",
    "    #     X_train, X_val = X_cluster_rfa_random.iloc[train_idx], X_cluster_rfa_random.iloc[val_idx]\n",
    "    #     y_train, y_val = y_cluster_rfa_random.iloc[train_idx],  y_cluster_rfa_random.iloc[val_idx]\n",
    "\n",
    "    # for idx, (train_idx, val_idx) in enumerate(cv.split(X_match_rfa_random,  y_match_rfa_random)):    \n",
    "    #     X_train, X_val = X_match_rfa_random.iloc[train_idx], X_match_rfa_random.iloc[val_idx]\n",
    "    #     y_train, y_val = y_match_rfa_random.iloc[train_idx],  y_match_rfa_random.iloc[val_idx]     \n",
    "\n",
    "        model = skRF(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores[idx] = f1_score(y_val, preds)\n",
    "        if cv_scores[idx] == 0.0:\n",
    "            print('Pruning because of 0.0 score.')\n",
    "            return 0.0\n",
    "        print('Fold {}: {}'.format(idx, cv_scores[idx]))\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "search_space={\n",
    "    \"n_estimators\": [75, 100, 125, 150, 175, 200, 250, 300, 400, 500],\n",
    "    \"max_depth\" : [5,10, 30, 50, 80, 90, 100, 110],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5],\n",
    "    \"min_samples_split\" : [2, 4, 8, 10],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"max_features\" : ['auto', 'sqrt', 'log2'],\n",
    "    \n",
    "}\n",
    "TREES_AND_DEPTH_ONLY = False\n",
    "GRID_SEARCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b08f3e-44b5-48f8-acb8-33d538cae39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_rf_objective(trial):\n",
    "    list_trees = [75, 100, 125, 150, 175, 200, 250, 300, 400, 500]\n",
    "    max_depth = [5, 10, 30, 50, 80, 90, 100, 110]\n",
    "    min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "    min_samples_split = [2, 4, 8, 10]\n",
    "    bootstrap = [True, False]\n",
    "    max_features = ['auto', 'sqrt', 'log2']\n",
    "    \n",
    "    param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
    "        'max_depth':trial.suggest_categorical('max_depth', max_depth), \n",
    "        'min_samples_split':trial.suggest_categorical('min_samples_split', min_samples_split), \n",
    "        'min_samples_leaf':trial.suggest_categorical('min_samples_leaf', min_samples_leaf), \n",
    "        'max_features':trial.suggest_categorical('max_features', max_features), \n",
    "            }\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    #######################\n",
    "    # HERE IS WHERE TO CHANGE THE X,Y DATASET USED FOR TRAINING\n",
    "    #######################\n",
    "   \n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(X.to_pandas(),y.to_pandas())):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = cuRFC(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores[idx] = f1_score(y_val.to_numpy(), preds.to_numpy())\n",
    "        del model, preds\n",
    "        if cv_scores[idx] == 0.0:\n",
    "            print('Pruning because of 0.0 score.')\n",
    "            return 0.0\n",
    "        print('Fold {}: {}'.format(idx, cv_scores[idx]))\n",
    "    return np.mean(cv_scores)\n",
    "    \n",
    "search_space={\n",
    "    \"n_estimators\": [75, 100, 125, 150, 175, 200, 250, 300, 400, 500],\n",
    "    \"max_depth\" : [5,10, 30, 50, 80, 90, 100, 110],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5],\n",
    "    \"min_samples_split\" : [2, 4, 8, 10],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"max_features\" : ['auto', 'sqrt', 'log2'],\n",
    "    \n",
    "}\n",
    "TREES_AND_DEPTH_ONLY = False\n",
    "GRID_SEARCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca239ea1-6081-466a-9458-c158eb7f2393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "if GRID_SEARCH:\n",
    "    study = optuna.create_study(study_name='RF Tuning Grid Search', \n",
    "                                direction='maximize',\n",
    "                                sampler=optuna.samplers.GridSampler(search_space))\n",
    "    \n",
    "else:\n",
    "    study = optuna.create_study(study_name='RF Tuning',\n",
    "                                direction='maximize')\n",
    "#Objective is under the functions area\n",
    "\n",
    "#####################################################################\n",
    "#CHANGE HERE FOR DIFFERENT MODELING TYPE\n",
    "#rf_objective or xgb_objective\n",
    "#####################################################################\n",
    "if GPU is False:\n",
    "    study.optimize(cpu_rf_objective, n_trials=25, timeout=30*600)\n",
    "else: \n",
    "    study.optimize(gpu_rf_objective, n_trials=25, timeout=30*600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef706118-c253-40b8-b067-3adba3bdffd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training and output best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602bb0b-7735-4127-a350-a554dcb8a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = study.best_trials            \n",
    "max_trial_score = max([trial.values[0] for trial in trials])\n",
    "max_trial_params = [trial.params for trial in trials \n",
    "                        if trial.values[0] == max_trial_score][0]\n",
    "max_trial_params['n_jobs'] = -1\n",
    "score_print = int(np.round(max_trial_score,4)*1000)\n",
    "print(max_trial_score)\n",
    "print(score_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb27e0f-3ab7-41f8-bda7-2c0e7564578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = max_trial_params\n",
    "hyperparameters['n_jobs'] = -1\n",
    "print('Using these params:')\n",
    "print(hyperparameters)\n",
    "tuned_classifier = skRF(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dea7c9-7927-4f2c-9b11-8bfa0dd082ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "tuned_classifier.fit(X,y) #_match_rfa_random , y_match_rfa_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29964f62-43bb-453c-9b65-a7526af71bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = f'rfa_models/MODIS_RFA_Targeted_v000_MaxScore{score_print}_sfcref127ndvi.pkl'\n",
    "print(filename)\n",
    "pickle.dump(tuned_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3220fba-351e-4bc5-9e24-f2af5dcf901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickled_model = pickle.load(open('rfa_models/MODIS_RFA_v201_EBCluster_sfcref127ndvi_4.pkl', 'rb'))\n",
    "# print(pickled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee12a19-8cf8-472d-ba4d-e269e7356272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (TensorFlow)",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
