{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b714c30-b71c-43c6-9fe3-9b012a7bfdfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  MODIS Water Cluster Training\n",
    "\n",
    "Version: 0.1.0\n",
    "\n",
    "Date modified: 05.01.2023\n",
    "\n",
    "Modified by: Amanda Burke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef8ad40-b2c6-4ccc-9a4b-c595bcce20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path   \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, matthews_corrcoef\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold\n",
    "#from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# #GDAL Stuff\n",
    "# from osgeo import gdalconst\n",
    "# from osgeo import gdal\n",
    "# from pprint import pprint\n",
    "\n",
    "# GPU-based frameworks\n",
    "\n",
    "# import cudf\n",
    "# import cupy as cp\n",
    "# from cuml.ensemble import RandomForestClassifier as cuRFC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b8fa3-9e2b-4d31-8606-b1162a041128",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef09a8be-17ed-40a8-958e-ed66b83929bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = False\n",
    "MODEL = 'rf'\n",
    "TEST_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "LABEL_NAME = 'water'\n",
    "DATA_TYPE = np.int16\n",
    "FRAC_LAND=0.5\n",
    "num_datapoints = 10000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f10435-8cba-40c0-9b5b-80f16a347a1f",
   "metadata": {},
   "source": [
    "\"Unhighlight\" different versions for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb0fe47-657c-4bdd-b41d-cb8e70068281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/v2.0.1/MOD09_GLOBAL_5469777_2_0_1.parquet.gzip']\n",
      "/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/v2.0.1/MOD09_GLOBAL_5469777_2_0_1.parquet.gzip\n"
     ]
    }
   ],
   "source": [
    "# #############################\n",
    "# # VERSION 4.2.1 (targeted 500k points)\n",
    "# TILE_IN = 'Golden'#v4.2.1\n",
    "# DATA_VERSION='v4.2.1'\n",
    "# offsets_indexes = ['x_offset', 'y_offset', 'year', 'julian_day','tileID']\n",
    "# #############################\n",
    "\n",
    "##############################\n",
    "#VERSION 2.0.1 (5 million points)\n",
    "TILE_IN = 'GLOBAL'#v2.0.1\n",
    "DATA_VERSION='v2.0.1'\n",
    "offsets_indexes = ['x_offset', 'y_offset', 'year', 'julian_day']\n",
    "##############################\n",
    "\n",
    "# #############################\n",
    "# #VERSION 0.0.0 (2billion data points)\n",
    "# TILE_IN = 'cleaned'#v2.0.1\n",
    "# DATA_VERSION='AGU'\n",
    "# offsets_indexes = []#'x_offset', 'y_offset', 'year', 'julian_day']\n",
    "# ##############################\n",
    "\n",
    "training_data_basepath = f'/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/{DATA_VERSION}'\n",
    "glob_string = os.path.join(training_data_basepath,'MOD*{}*.parquet.gzip'.format(TILE_IN))\n",
    "data_paths = sorted([fv for fv in glob.glob(glob_string)])\n",
    "\n",
    "print(data_paths)\n",
    "data_path = data_paths[0]\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd27567-2a51-4e94-8d0a-43504a90bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpu_data(fpath, colsToDrop, yCol='water', testSize=0.2, randomState=42, \n",
    "            dataType=np.float32, cpu=True, splitXY=False, trainTestSplit=False,\n",
    "            applyLog=False, imbalance=False, frac=0.1, land=False, multi=False, \n",
    "            multisample=1000000):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by models\n",
    "    :param fpath: Path to the data to be ingested.\n",
    "    :param dataType: Data type to convert ingested data to.\n",
    "    :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "    :param testSize: Ration to\n",
    "    \"\"\"\n",
    "    if multi:\n",
    "        all_dfs = [pd.read_csv(path_) for path_ in fpath]\n",
    "        df = pd.concat(all_dfs).sample(n=multisample, random_state=randomState)\n",
    "        print('DF length: {}'.format(len(df.index)))\n",
    "    else:   \n",
    "        df = pd.read_parquet(fpath) if '.parquet' in fpath else pd.read_csv(fpath)\n",
    "    df = df[df['sur_refl_b01_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b07_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b06_1'] + df['sur_refl_b02_1'] != 0]\n",
    "\n",
    "    df = df.drop(columns=colsToDrop)\n",
    "    cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0).astype(dataType)\n",
    "    if applyLog:\n",
    "        for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "            print('Applying log1p func to {}'.format(col))\n",
    "            cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "        cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    df = None\n",
    "    if imbalance:\n",
    "        if land:\n",
    "            print('Imbalancing data, sampling {} from water'.format(frac))\n",
    "        else:\n",
    "            print(f'Imbalancing data, sampling {frac} from land, {1-frac} from water')\n",
    "        groupedDF = cleanedDF.groupby('water')\n",
    "        dfs = [groupedDF.get_group(y) for y in groupedDF.groups]\n",
    "        sampledDF = dfs[1].sample(frac=frac)if land else dfs[0].sample(frac=frac)\n",
    "        concatDF = sampledDF.append(dfs[0]) if land else sampledDF.append(dfs[1])\n",
    "        concatDF = concatDF.sample(frac=1)\n",
    "        concatDF = concatDF.reset_index()\n",
    "        cleanedDF = concatDF.drop(columns=['index'])\n",
    "    if not splitXY:\n",
    "        return cleanedDF\n",
    "    X = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    y = cleanedDF[yCol].astype(dataType)\n",
    "    if trainTestSplit:\n",
    "        return train_test_split(X, y, test_size=TEST_RATIO)\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20d193-7b83-41c9-9aa4-02feb1fa7a66",
   "metadata": {},
   "source": [
    "Change the input features below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdee2440-7931-4da3-80e7-f79aefcb15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToDrop = [\n",
    "            # 'sur_refl_b01_1','sur_refl_b02_1',\n",
    "            'sur_refl_b03_1','sur_refl_b04_1',\n",
    "            'sur_refl_b05_1','sur_refl_b06_1',\n",
    "            # 'sur_refl_b07_1', 'ndvi',\n",
    "            'ndwi1','ndwi2'\n",
    "            ]\n",
    "\n",
    "colsToDropTraining = colsToDrop.copy()\n",
    "colsToDropTraining.extend(offsets_indexes)\n",
    "v_names = ['sur_refl_b01_1','sur_refl_b02_1',\n",
    "           'sur_refl_b03_1','sur_refl_b04_1',\n",
    "           'sur_refl_b05_1','sur_refl_b06_1',\n",
    "           'sur_refl_b07_1','ndvi',\n",
    "           'ndwi1','ndwi2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8a3852-14ee-4615-bc7c-871046ca19e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sur_refl_b03_1',\n",
       " 'sur_refl_b04_1',\n",
       " 'sur_refl_b05_1',\n",
       " 'sur_refl_b06_1',\n",
       " 'ndwi1',\n",
       " 'ndwi2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colsToDrop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133868b4-66bb-4f85-bcb2-641a79f06e2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb281755-23fe-4789-ba8b-584105111691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (4375821, 4), (4375821,)\n",
      "CPU times: user 4.09 s, sys: 986 ms, total: 5.08 s\n",
      "Wall time: 4.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, X_test, y, y_test = load_cpu_data(fpath=data_path,\n",
    "                                             colsToDrop=colsToDropTraining,\n",
    "                                             dataType=DATA_TYPE,\n",
    "                                             splitXY=True,\n",
    "                                             imbalance=False,\n",
    "                                             trainTestSplit=True)\n",
    "X = X.iloc[:num_datapoints,:] \n",
    "y = y.iloc[:num_datapoints] \n",
    "\n",
    "X_test = X_test.iloc[:num_datapoints,:] \n",
    "y_test = y_test.iloc[:num_datapoints] \n",
    "\n",
    "print(f'data shape: {X.shape}, {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5788ef49-6c9f-4827-825b-8a29a1fbe208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976893 2398928\n"
     ]
    }
   ],
   "source": [
    "#Getting the indices that are associated with land (0) and water (1)\n",
    "y_water_ind = np.where(y>0.5)[0]\n",
    "y_land_ind = np.where(y<0.5)[0]\n",
    "\n",
    "#Subset the X AND y data to later/ subset with the clusters and then combine for RFA\n",
    "X_water = X.iloc[y_water_ind,:]\n",
    "y_water = y.iloc[y_water_ind]\n",
    "\n",
    "X_land = X.iloc[y_land_ind,:]\n",
    "y_land = y.iloc[y_land_ind]\n",
    "print(len(X_water),len(X_land))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b38dfe2-a25e-4656-a5e8-444addd34398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sur_refl_b01_1\n",
      "sur_refl_b02_1\n",
      "sur_refl_b07_1\n",
      "ndvi\n"
     ]
    }
   ],
   "source": [
    "_ = [print(column) for column in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdd11d-a3b3-4733-b95f-f5cb8bd80fc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e0854-39fc-409d-82ce-9d340243778b",
   "metadata": {},
   "source": [
    "Based on the cluster analysis above on 5.03.23, 15 clusters appears to have the most data and exclude outliers so will use that number for selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f8d4ca4-dca4-47e5-a497-a3f2db68a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_land_fit_file = 'kmeans_land_fit.pkl'\n",
    "kmean_water_fit_file = 'kmeans_water_fit.pkl'\n",
    "# if len(glob.glob(kmean_land_fit_file)) == 1:\n",
    "#     print(f\"Opening {kmean_land_fit_file}\")\n",
    "#     kme_land_random = pickle.load(open(kmean_land_fit_file, 'rb'))\n",
    "# if len(glob.glob(kmean_water_fit_file)) == 1:\n",
    "#     print(f\"Opening {kmean_water_fit_file}\")\n",
    "#     kme_water_random = pickle.load(open(kmean_water_fit_file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "860899fd-59ae-420d-ac0b-a1ad8940f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_NUM=15\n",
    "\n",
    "common_params = {\n",
    "    \"n_init\": \"auto\",\n",
    "    \"random_state\": 42,\n",
    "    \"init\":\"random\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14fadaa2-f0c0-43d0-8048-de4c7ef01329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.1 s, sys: 1.35 s, total: 59.4 s\n",
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kme_water_random = KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_water)\n",
    "kmeans_output_water_random = kme_water_random.predict(X_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08b9ac07-2215-4e65-ab83-e67411dec00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 18s, sys: 2.6 s, total: 2min 21s\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kme_land_random = KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_land)\n",
    "kmeans_output_land_random = kme_land_random.predict(X_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3449a52c-9d1e-4bdd-9a62-d5424943d3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(kme_land_random, open(\"kmeans_land_fit.pkl\", \"wb\"))\n",
    "pickle.dump(kme_water_random, open(\"kmeans_water_fit.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf9549-0236-4f29-a8a3-c1a2d0ab60e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evenly balanced cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42a34ff7-b94d-472b-8e8b-633272252473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919 33589\n",
      "919 919 33589\n"
     ]
    }
   ],
   "source": [
    "COUNT_EVEN_BALANCE_LAND = np.inf\n",
    "COUNT_EVEN_BALANCE_WATER = np.inf\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    land_num = len(np.where(kmeans_output_land_random == cluster)[0])\n",
    "    water_num = len(np.where(kmeans_output_water_random == cluster)[0])\n",
    "    if land_num < COUNT_EVEN_BALANCE_LAND: COUNT_EVEN_BALANCE_LAND = land_num\n",
    "    if water_num < COUNT_EVEN_BALANCE_WATER: COUNT_EVEN_BALANCE_WATER = water_num\n",
    "    \n",
    "print(COUNT_EVEN_BALANCE_LAND, COUNT_EVEN_BALANCE_WATER)\n",
    "if COUNT_EVEN_BALANCE_LAND < COUNT_EVEN_BALANCE_WATER:\n",
    "    COUNT = COUNT_EVEN_BALANCE_LAND\n",
    "else: \n",
    "    COUNT = COUNT_EVEN_BALANCE_WATER\n",
    "print(COUNT,COUNT_EVEN_BALANCE_LAND,COUNT_EVEN_BALANCE_WATER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "660e6139-cb3b-4595-9469-215a1252db02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0\n",
      "cluster 1\n",
      "cluster 2\n",
      "cluster 3\n",
      "cluster 4\n",
      "cluster 5\n",
      "cluster 6\n",
      "cluster 7\n",
      "cluster 8\n",
      "cluster 9\n",
      "cluster 10\n",
      "cluster 11\n",
      "cluster 12\n",
      "cluster 13\n",
      "cluster 14\n",
      "13785 13785\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cluster_sample_land = np.array([])\n",
    "cluster_sample_water = np.array([])\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    sample_water = np.random.choice(cluster_water,COUNT,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[sample_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        cluster_sample_water = np.append(cluster_sample_water, sample_water)\n",
    "    else: \n",
    "        print(f'contains outliers')\n",
    "        continue\n",
    "    \n",
    "    cluster_land= np.where(kmeans_output_land_random == cluster)[0]\n",
    "    sample_land = np.random.choice(cluster_land,COUNT,replace=False)\n",
    "    cluster_sample_land = np.append(cluster_sample_land, sample_land)\n",
    "    \n",
    "cluster_sample_water = cluster_sample_water.astype('int')\n",
    "cluster_sample_land = cluster_sample_land.astype('int')\n",
    "\n",
    "print(len(cluster_sample_water),len(cluster_sample_land))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efc837-8cc4-404c-b18b-e8647db50af7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Combining even balance cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3be16f9-0734-47ce-a8d2-7cb3e1c22cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sur_refl_b01_1  sur_refl_b02_1  sur_refl_b07_1   ndvi  water\n",
      "1860342             477            2980             958   7240      0\n",
      "2227721             162            2774             352   8896      0\n",
      "325991               21               6              65  -5555      1\n",
      "2253569             -32               2              12 -11333      1\n",
      "5381081              23              -5              19 -15555      1\n",
      "...                 ...             ...             ...    ...    ...\n",
      "1996160              29             -37              63  16964      1\n",
      "2942419            -100              93             329 -13570      0\n",
      "901337              491            1740            1129   5598      0\n",
      "3174851             318             112             178  -4790      1\n",
      "94498                -5               3              11  25536      1\n",
      "\n",
      "[27570 rows x 5 columns]\n",
      "         sur_refl_b01_1  sur_refl_b02_1  sur_refl_b07_1   ndvi\n",
      "1860342             477            2980             958   7240\n",
      "2227721             162            2774             352   8896\n",
      "325991               21               6              65  -5555\n",
      "2253569             -32               2              12 -11333\n",
      "5381081              23              -5              19 -15555\n",
      "...                 ...             ...             ...    ...\n",
      "1996160              29             -37              63  16964\n",
      "2942419            -100              93             329 -13570\n",
      "901337              491            1740            1129   5598\n",
      "3174851             318             112             178  -4790\n",
      "94498                -5               3              11  25536\n",
      "\n",
      "[27570 rows x 4 columns]\n",
      "1860342    0\n",
      "2227721    0\n",
      "325991     1\n",
      "2253569    1\n",
      "5381081    1\n",
      "          ..\n",
      "1996160    1\n",
      "2942419    0\n",
      "901337     0\n",
      "3174851    1\n",
      "94498      1\n",
      "Name: water, Length: 27570, dtype: int16\n"
     ]
    }
   ],
   "source": [
    "X_seperate_cluster = pd.concat([\n",
    "    X_land.iloc[cluster_sample_land],X_water.iloc[cluster_sample_water]\n",
    "    ])\n",
    "    \n",
    "y_seperate_cluster = pd.concat([\n",
    "    y_land.iloc[cluster_sample_land],y_water.iloc[cluster_sample_water]\n",
    "    ])\n",
    "\n",
    "#Combine the data so that we can shuffle the indices and keep the data together that should be\n",
    "all_cluster = pd.concat([X_seperate_cluster,y_seperate_cluster],axis=1).sample(frac=1)\n",
    "X_cluster = all_cluster[X_seperate_cluster.columns]\n",
    "y_cluster = all_cluster['water']\n",
    "\n",
    "print(all_cluster)\n",
    "print(X_cluster)\n",
    "print(y_cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a4cca-556f-4e75-bc92-6361608f42c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Proportional cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6a8c5-ad0e-4e6c-89b7-7e75526f654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the clusters: kmeans_output_land and kmeans_output_water\n",
    "# Data: X_water, X_land, y_water, y_land\n",
    "\n",
    "PERCENT_RANDOM_PULL = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee2dae0-b83d-470b-ae1d-daffa1c42816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "random_ind_land = np.array([])\n",
    "random_ind_water = []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    # cluster_ind_water = np.where(bgm_water == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_WATER = int(PERCENT_RANDOM_PULL*len(cluster_ind_water))\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT_RANDOM_PULL_WATER,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water = np.append(random_ind_water, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    # cluster_ind_land = np.where(bgm_land == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_LAND = int(PERCENT_RANDOM_PULL*len(cluster_ind_land))\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT_RANDOM_PULL_LAND,replace=False)\n",
    "    random_ind_land = np.append(random_ind_land, random_pts_land)\n",
    "    print(f'Pulling {COUNT_RANDOM_PULL_WATER} Water pts and {COUNT_RANDOM_PULL_LAND} Land pts')\n",
    "    print()\n",
    "random_ind_water = random_ind_water.astype('int')\n",
    "random_ind_land = random_ind_land.astype('int')\n",
    "\n",
    "print(random_ind_water,random_ind_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855d30f-505c-45cb-b02b-f94e5d38da4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d307387-dc6d-49ce-be7d-af4346607953",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating random sample, same size as clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27677834-c156-4527-9f1d-1e53b33a7803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sur_refl_b01_1  sur_refl_b02_1  sur_refl_b07_1   ndvi  water\n",
      "0                 176            3652             498   9080      0\n",
      "1                1043            3682            1292   5585      0\n",
      "2                 497            2324            1346   6476      0\n",
      "3                  47               2              30  -9183      1\n",
      "4                 111            1862             229   8874      0\n",
      "...               ...             ...             ...    ...    ...\n",
      "27565             358            1683             835   6491      0\n",
      "27566             971            2881            1883   4958      0\n",
      "27567              35              -3              12 -11875      1\n",
      "27568            1130            2442            1474   3673      0\n",
      "27569            2513            1731             830  -1842      0\n",
      "\n",
      "[27570 rows x 5 columns]\n",
      "       sur_refl_b01_1  sur_refl_b02_1  sur_refl_b07_1   ndvi\n",
      "0                 176            3652             498   9080\n",
      "1                1043            3682            1292   5585\n",
      "2                 497            2324            1346   6476\n",
      "3                  47               2              30  -9183\n",
      "4                 111            1862             229   8874\n",
      "...               ...             ...             ...    ...\n",
      "27565             358            1683             835   6491\n",
      "27566             971            2881            1883   4958\n",
      "27567              35              -3              12 -11875\n",
      "27568            1130            2442            1474   3673\n",
      "27569            2513            1731             830  -1842\n",
      "\n",
      "[27570 rows x 4 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        1\n",
      "4        0\n",
      "        ..\n",
      "27565    0\n",
      "27566    0\n",
      "27567    1\n",
      "27568    0\n",
      "27569    0\n",
      "Name: water, Length: 27570, dtype: int16\n"
     ]
    }
   ],
   "source": [
    "match_sample_land = np.random.choice( np.arange(len(X_land)),len(cluster_sample_land),replace=False)\n",
    "match_sample_water = np.random.choice( np.arange(len(X_water)),len(cluster_sample_water),replace=False)\n",
    "\n",
    "X_seperate_match= pd.concat([\n",
    "    X_land.iloc[match_sample_land],X_water.iloc[match_sample_water]\n",
    "        ])\n",
    "y_seperate_match = pd.concat([\n",
    "    y_land.iloc[match_sample_land],y_water.iloc[match_sample_water]\n",
    "        ])\n",
    "\n",
    "all_match = pd.concat([X_seperate_match,y_seperate_match],axis=1).sample(frac=1).reset_index(drop=True)\n",
    "X_match= all_match[X_seperate_match.columns]\n",
    "y_match = all_match['water']\n",
    "\n",
    "print(all_match)\n",
    "print(X_match)\n",
    "print(y_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be6ccf-6e47-4297-bb0b-92277c4fc231",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plotting paramater space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da7981-4061-4f85-8c3b-5aef1a65fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2,figsize=(20, 10))\n",
    "# var=0\n",
    "# for col in range(2):\n",
    "#     ax[col, 0].set_ylabel('Frequency') \n",
    "#     for row in range(2):\n",
    "#         variable=X_land.columns[var]\n",
    "#         if 'ndvi' in variable: \n",
    "#             # var_bins = bin_boundaries\n",
    "#             log_values = False\n",
    "#         else: \n",
    "#             # var_bins = None\n",
    "#             log_values = True\n",
    "#         ax[row, col].hist(\n",
    "#             [  \n",
    "#             X_cluster_eb[variable].values,\n",
    "#             X_match_eb[variable].values,\n",
    "#             X_cluster_p[variable].values,\n",
    "#             X_match_p[variable].values,\n",
    "#             ],\n",
    "#             label=[\n",
    "#             f\"EB Cluster {len(X_cluster_eb)}\",\n",
    "#             \"EB Match\",\n",
    "#             f\"P Cluster {len(X_match_p)}\",\n",
    "#             f\"P Match\"\n",
    "#             ],\n",
    "#             #bins=var_bins,\n",
    "#         color=['darkgreen','lightgreen','darkblue','lightblue'], log=log_values) \n",
    "#         ax[row, col].set_xlabel(f'{variable}')\n",
    "#         var+=1\n",
    "#     ax[0,0].legend(loc='upper right',fontsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed9581-542c-433e-a139-1a45a83d9612",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3244e03-63f5-45f2-b28d-dfcd6b7bc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_rf_objective(trial):\n",
    "    list_trees = [75, 100, 125, 150, 175, 200, 250, 300, 400, 500]\n",
    "    max_depth = [5, 10, 30, 50, 80, 90, 100, 110]\n",
    "    min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "    min_samples_split = [2, 4, 8, 10]\n",
    "    bootstrap = [True, False]\n",
    "    max_features = ['auto', 'sqrt', 'log2']\n",
    " \n",
    "    param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
    "                       'max_depth':trial.suggest_categorical('max_depth', max_depth), \n",
    "                       'min_samples_split':trial.suggest_categorical('min_samples_split', min_samples_split), \n",
    "                       'min_samples_leaf':trial.suggest_categorical('min_samples_leaf', min_samples_leaf), \n",
    "                       'bootstrap': trial.suggest_categorical('bootstrap', bootstrap),\n",
    "                       'criterion':'gini', \n",
    "                       #'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 1e-8, 1.0, log=True), \n",
    "                       'max_features':trial.suggest_categorical('max_features', max_features), \n",
    "                       'max_leaf_nodes':None, \n",
    "                       'min_impurity_decrease':0.0, \n",
    "                       'oob_score':False, \n",
    "                       'n_jobs':-1, \n",
    "                       # 'random_state':42, \n",
    "                       'verbose':0, \n",
    "                       'warm_start':False, \n",
    "                       'class_weight':None, \n",
    "                       'ccp_alpha':0.0, \n",
    "                       'max_samples':None\n",
    "                      }\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    #####################################################################\n",
    "    # HERE IS WHERE TO CHANGE THE X,Y DATASET USED FOR TRAINING\n",
    "    #####################################################################\n",
    "   \n",
    "    cv_scores = np.empty(5)\n",
    "    \n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(X_match,  y_match)):    \n",
    "        X_train, X_val = X_match.iloc[train_idx], X_match.iloc[val_idx]\n",
    "        y_train, y_val = y_match.iloc[train_idx],  y_match.iloc[val_idx]   \n",
    "        \n",
    "    # for idx, (train_idx, val_idx) in enumerate(cv.split(X_cluster,  y_cluster)):    \n",
    "    #     X_train, X_val = X_cluster.iloc[train_idx], X_cluster.iloc[val_idx]\n",
    "    #     y_train, y_val = y_cluster.iloc[train_idx],  y_cluster.iloc[val_idx]     \n",
    "   \n",
    "\n",
    "    #####################################################################\n",
    "\n",
    "        model = skRF(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores[idx] = f1_score(y_val, preds)\n",
    "        if cv_scores[idx] == 0.0:\n",
    "            print('Pruning because of 0.0 score.')\n",
    "            return 0.0\n",
    "        print('Fold {}: {}'.format(idx, cv_scores[idx]))\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "search_space={\n",
    "    \"n_estimators\": [75, 100, 125, 150, 175, 200, 250, 300, 400, 500],\n",
    "    \"max_depth\" : [5,10, 30, 50, 80, 90, 100, 110],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5],\n",
    "    \"min_samples_split\" : [2, 4, 8, 10],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"max_features\" : ['auto', 'sqrt', 'log2'],\n",
    "    \n",
    "}\n",
    "TREES_AND_DEPTH_ONLY = False\n",
    "GRID_SEARCH = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0070240-5655-486d-9011-b038ebee4403",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5bac7-b2b6-4860-aaf3-8bd597480347",
   "metadata": {},
   "source": [
    "Change modeling type below e.g.,\n",
    "\n",
    "study.optimize(cpu_***rf***_objective, n_trials=25, timeout=30*600)\n",
    "\n",
    "vs\n",
    "\n",
    "study.optimize(cpu_***xgb***_objective, n_trials=25, timeout=30*600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca239ea1-6081-466a-9458-c158eb7f2393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:12:30,300]\u001b[0m A new study created in memory with name: RF Tuning Grid Search\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 0.9782766111513396\n",
      "Fold 1: 0.9779225479551213\n",
      "Fold 2: 0.9772768587529541\n",
      "Fold 3: 0.9798730734360834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:12:34,460]\u001b[0m Trial 0 finished with value: 0.9784730020507061 and parameters: {'n_estimators': 75, 'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 5, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9784730020507061.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9790159189580318\n",
      "Fold 0: 0.9780916168748868\n",
      "Fold 1: 0.9775849602313811\n",
      "Fold 2: 0.9761861479730959\n",
      "Fold 3: 0.9795029929258118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:12:43,021]\u001b[0m Trial 1 finished with value: 0.977970124255528 and parameters: {'n_estimators': 150, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 2, 'bootstrap': False, 'max_features': 'auto'}. Best is trial 0 with value: 0.9784730020507061.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9784849032724642\n",
      "Fold 0: 0.9782687432089823\n",
      "Fold 1: 0.9781153915717128\n",
      "Fold 2: 0.9770909090909091\n",
      "Fold 3: 0.9802213754309563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:12:58,857]\u001b[0m Trial 2 finished with value: 0.9786133338062232 and parameters: {'n_estimators': 400, 'max_depth': 100, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': True, 'max_features': 'auto'}. Best is trial 2 with value: 0.9786133338062232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9793702497285559\n",
      "Fold 0: 0.9782766111513396\n",
      "Fold 1: 0.9783001808318265\n",
      "Fold 2: 0.976203451407811\n",
      "Fold 3: 0.9793253536452666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:13:04,389]\u001b[0m Trial 3 finished with value: 0.9780457804088758 and parameters: {'n_estimators': 100, 'max_depth': 80, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': False, 'max_features': 'log2'}. Best is trial 2 with value: 0.9786133338062232.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9781233050081359\n",
      "Fold 0: 0.9786231884057972\n",
      "Fold 1: 0.9786463988418385\n",
      "Fold 2: 0.977632296781233\n",
      "Fold 3: 0.9805842859735076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:13:11,487]\u001b[0m Trial 4 finished with value: 0.9790805884423062 and parameters: {'n_estimators': 175, 'max_depth': 90, 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': True, 'max_features': 'auto'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.979916772209155\n",
      "Fold 0: 0.9791704401376562\n",
      "Fold 1: 0.9779385171790236\n",
      "Fold 2: 0.9774709302325582\n",
      "Fold 3: 0.9804063860667634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:13:14,609]\u001b[0m Trial 5 finished with value: 0.9788713046689115 and parameters: {'n_estimators': 75, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': True, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9793702497285559\n",
      "Fold 0: 0.9780836804926645\n",
      "Fold 1: 0.9775606225117626\n",
      "Fold 2: 0.9765411893071468\n",
      "Fold 3: 0.9806054014863151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:13:25,518]\u001b[0m Trial 6 finished with value: 0.9782890036510394 and parameters: {'n_estimators': 200, 'max_depth': 80, 'min_samples_split': 8, 'min_samples_leaf': 3, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9786541244573084\n",
      "Fold 0: 0.9787928221859707\n",
      "Fold 1: 0.9784381228483421\n",
      "Fold 2: 0.9765411893071468\n",
      "Fold 3: 0.9794955543458538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:13:30,200]\u001b[0m Trial 7 finished with value: 0.9781220894866017 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'bootstrap': False, 'max_features': 'auto'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9773427587456952\n",
      "Fold 0: 0.9782766111513396\n",
      "Fold 1: 0.9781233050081359\n",
      "Fold 2: 0.9774381368267832\n",
      "Fold 3: 0.9802213754309563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:13:46,162]\u001b[0m Trial 8 finished with value: 0.9787258252965328 and parameters: {'n_estimators': 400, 'max_depth': 110, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True, 'max_features': 'log2'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9795696980654494\n",
      "Fold 0: 0.9784537389100127\n",
      "Fold 1: 0.9786463988418385\n",
      "Fold 2: 0.9774463441251364\n",
      "Fold 3: 0.9807622504537206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:14:01,947]\u001b[0m Trial 9 finished with value: 0.9789712487285852 and parameters: {'n_estimators': 400, 'max_depth': 80, 'min_samples_split': 10, 'min_samples_leaf': 2, 'bootstrap': True, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9795475113122173\n",
      "Fold 0: 0.9789778905400508\n",
      "Fold 1: 0.9784459337076616\n",
      "Fold 2: 0.9768964889939967\n",
      "Fold 3: 0.9802285506983495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:14:08,746]\u001b[0m Trial 10 finished with value: 0.9788148280516464 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9795252763181735\n",
      "Fold 0: 0.9784693323683734\n",
      "Fold 1: 0.9783080260303688\n",
      "Fold 2: 0.9778020378457061\n",
      "Fold 3: 0.9798657718120805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:14:16,676]\u001b[0m Trial 11 finished with value: 0.9786613913348828 and parameters: {'n_estimators': 200, 'max_depth': 90, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9788617886178861\n",
      "Fold 0: 0.9786309308221659\n",
      "Fold 1: 0.9773837524877873\n",
      "Fold 2: 0.9767272727272727\n",
      "Fold 3: 0.9796733212341198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-02-06 15:14:24,747]\u001b[0m Trial 12 finished with value: 0.9781784795815976 and parameters: {'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': False, 'max_features': 'auto'}. Best is trial 4 with value: 0.9790805884423062.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9784771206366432\n",
      "Fold 0: 0.9784537389100127\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "if GRID_SEARCH:\n",
    "    study = optuna.create_study(study_name='RF Tuning Grid Search', \n",
    "                                direction='maximize',\n",
    "                                sampler=optuna.samplers.GridSampler(search_space))\n",
    "    \n",
    "else:\n",
    "    study = optuna.create_study(study_name='RF Tuning',\n",
    "                                direction='maximize')\n",
    "\n",
    "study.optimize(cpu_rf_objective, n_trials=25, timeout=30*600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602bb0b-7735-4127-a350-a554dcb8a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = study.best_trials            \n",
    "max_trial_score = max([trial.values[0] for trial in trials])\n",
    "max_trial_params = [trial.params for trial in trials \n",
    "                        if trial.values[0] == max_trial_score][0]\n",
    "max_trial_params['n_jobs'] = -1\n",
    "score_print = int(np.round(max_trial_score,4)*1000)\n",
    "print(score_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb27e0f-3ab7-41f8-bda7-2c0e7564578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = max_trial_params\n",
    "hyperparameters['n_jobs'] = -1\n",
    "print('Using these params:')\n",
    "print(hyperparameters)\n",
    "tuned_classifier = skRF(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e4648-5ff9-4a05-96b2-3febe9f188ff",
   "metadata": {},
   "source": [
    "Change the data in the .fit() function below e.g. \n",
    "\n",
    "tuned_classifier.fit(***X_cluster, y_cluster***)\n",
    "\n",
    "vs\n",
    "\n",
    "tuned_classifier.fit(***X_match, y_match***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dea7c9-7927-4f2c-9b11-8bfa0dd082ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "tuned_classifier.fit(X_cluster, y_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14365c59-6e81-46b2-9f35-12a413b4f2cd",
   "metadata": {},
   "source": [
    "Change the filename below e.g., \n",
    "\n",
    "out_file = f'rfa_models/MODIS_RFA_v201_***EBcluster***_MaxScore{score_print}_sfcref127ndvi.pkl'\n",
    "\n",
    "vs\n",
    "\n",
    "out_file = f'rfa_models/MODIS_RFA_v201_***EBmatch***_MaxScore{score_print}_sfcref127ndvi.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29964f62-43bb-453c-9b65-a7526af71bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = f'rfa_models/MODIS_RFA_v201_EBcluster_MaxScore{score_print}_sfcref127ndvi.pkl'\n",
    "print(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99d9eb-de88-41ed-af92-a6063206fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tuned_classifier, open(out_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3220fba-351e-4bc5-9e24-f2af5dcf901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickled_model = pickle.load(open(out_file, 'rb'))\n",
    "# print(pickled_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (TensorFlow)",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
