{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b714c30-b71c-43c6-9fe3-9b012a7bfdfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  MODIS Water Cluster Training\n",
    "\n",
    "Version: 0.1.0\n",
    "\n",
    "Date modified: 05.01.2023\n",
    "\n",
    "Modified by: Amanda Burke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef8ad40-b2c6-4ccc-9a4b-c595bcce20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import math \n",
    "import pandas as pd\n",
    "from pathlib import Path   \n",
    "from sklearn.cluster import KMeans\n",
    "# from sklearn.cluster import Birch\n",
    "# from sklearn.cluster import SpectralClustering\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# plt.style.use('fivethirtyeight')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# import optuna\n",
    "# from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "# from sklearn.model_selection import train_test_split \n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, precision_score, f1_score\n",
    "# from sklearn.metrics import classification_report, roc_curve, auc, matthews_corrcoef\n",
    "# from sklearn.model_selection import RandomizedSearchCV, KFold, StratifiedKFold\n",
    "# #from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "169c7a95-24a1-4ceb-9036-27369d259e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef09a8be-17ed-40a8-958e-ed66b83929bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'rf'\n",
    "TEST_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "LABEL_NAME = 'water'\n",
    "if GPU is False:\n",
    "    DATA_TYPE = np.int16\n",
    "else: \n",
    "    DATA_TYPE = cp.float32\n",
    "FRAC_LAND=0.5\n",
    "num_datapoints = 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bb0fe47-657c-4bdd-b41d-cb8e70068281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/v2.0.1/MOD09_GLOBAL_5469777_2_0_1.parquet.gzip']\n",
      "/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/v2.0.1/MOD09_GLOBAL_5469777_2_0_1.parquet.gzip\n"
     ]
    }
   ],
   "source": [
    "# #############################\n",
    "# # VERSION 4.2.1 (targeted 500k points)\n",
    "# TILE_IN = 'Golden'#v4.2.1\n",
    "# DATA_VERSION='v4.2.1'\n",
    "# offsets_indexes = ['x_offset', 'y_offset', 'year', 'julian_day','tileID']\n",
    "# #############################\n",
    "\n",
    "##############################\n",
    "#VERSION 2.0.1 (5 million points)\n",
    "TILE_IN = 'GLOBAL'#v2.0.1\n",
    "DATA_VERSION='v2.0.1'\n",
    "offsets_indexes = ['x_offset', 'y_offset', 'year', 'julian_day']\n",
    "##############################\n",
    "\n",
    "# #############################\n",
    "# #VERSION 0.0.0 (2billion data points)\n",
    "# TILE_IN = 'cleaned'#v0.0.0\n",
    "# DATA_VERSION='AGU'\n",
    "# offsets_indexes = []#'x_offset', 'y_offset', 'year', 'julian_day']\n",
    "# ##############################\n",
    "\n",
    "training_data_basepath = f'/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/{DATA_VERSION}'\n",
    "glob_string = os.path.join(training_data_basepath,'MOD*{}*.parquet.gzip'.format(TILE_IN))\n",
    "data_paths = sorted([fv for fv in glob.glob(glob_string)])\n",
    "\n",
    "#Only want the one with 4.2.0 because the other file doesnt work. \n",
    "print(data_paths)\n",
    "data_path = data_paths[0]\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd27567-2a51-4e94-8d0a-43504a90bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpu_data(fpath, colsToDrop, yCol='water', testSize=0.2, randomState=42, \n",
    "            dataType=np.float32, cpu=True, splitXY=False, trainTestSplit=False,\n",
    "            applyLog=False, imbalance=False, frac=0.1, land=False, multi=False, \n",
    "            multisample=1000000):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by models\n",
    "    :param fpath: Path to the data to be ingested.\n",
    "    :param dataType: Data type to convert ingested data to.\n",
    "    :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "    :param testSize: Ration to\n",
    "    \"\"\"\n",
    "    if multi:\n",
    "        all_dfs = [pd.read_csv(path_) for path_ in fpath]\n",
    "        df = pd.concat(all_dfs).sample(n=multisample, random_state=randomState)\n",
    "        print('DF length: {}'.format(len(df.index)))\n",
    "    else:   \n",
    "        df = pd.read_parquet(fpath) if '.parquet' in fpath else pd.read_csv(fpath)\n",
    "    df = df[df['sur_refl_b01_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b07_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b06_1'] + df['sur_refl_b02_1'] != 0]\n",
    "\n",
    "    df = df.drop(columns=colsToDrop)\n",
    "    cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0).astype(dataType)\n",
    "    if applyLog:\n",
    "        for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "            print('Applying log1p func to {}'.format(col))\n",
    "            cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "        cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    df = None\n",
    "    if imbalance:\n",
    "        if land:\n",
    "            print('Imbalancing data, sampling {} from water'.format(frac))\n",
    "        else:\n",
    "            print(f'Imbalancing data, sampling {frac} from land, {1-frac} from water')\n",
    "        groupedDF = cleanedDF.groupby('water')\n",
    "        dfs = [groupedDF.get_group(y) for y in groupedDF.groups]\n",
    "        sampledDF = dfs[1].sample(frac=frac)if land else dfs[0].sample(frac=frac)\n",
    "        concatDF = sampledDF.append(dfs[0]) if land else sampledDF.append(dfs[1])\n",
    "        concatDF = concatDF.sample(frac=1)\n",
    "        concatDF = concatDF.reset_index()\n",
    "        cleanedDF = concatDF.drop(columns=['index'])\n",
    "    if not splitXY:\n",
    "        return cleanedDF\n",
    "    X = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    y = cleanedDF[yCol].astype(dataType)\n",
    "    if trainTestSplit:\n",
    "        return train_test_split(X, y, test_size=TEST_RATIO)\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdee2440-7931-4da3-80e7-f79aefcb15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToDrop = [\n",
    "    # 'sur_refl_b01_1',\n",
    "    # 'sur_refl_b02_1',\n",
    "    'sur_refl_b03_1',\n",
    "    'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
    "    # 'sur_refl_b07_1',\n",
    "    # 'ndvi',\n",
    "    'ndwi1','ndwi2'\n",
    "        ]\n",
    "\n",
    "colsToDropTraining = colsToDrop.copy()\n",
    "colsToDropTraining.extend(offsets_indexes)\n",
    "v_names = ['sur_refl_b01_1','sur_refl_b02_1','sur_refl_b03_1',\n",
    "           'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
    "           'sur_refl_b07_1','ndvi','ndwi1','ndwi2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133868b4-66bb-4f85-bcb2-641a79f06e2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8a3852-14ee-4615-bc7c-871046ca19e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sur_refl_b03_1',\n",
       " 'sur_refl_b04_1',\n",
       " 'sur_refl_b05_1',\n",
       " 'sur_refl_b06_1',\n",
       " 'ndwi1',\n",
       " 'ndwi2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colsToDrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb281755-23fe-4789-ba8b-584105111691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (4375821, 4), (4375821,)\n",
      "CPU times: user 3.84 s, sys: 993 ms, total: 4.83 s\n",
      "Wall time: 4.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_data_params = {'fpath':data_path,'colsToDrop':colsToDropTraining,'splitXY':True,\n",
    "                    'imbalance':False,'trainTestSplit':True}\n",
    "\n",
    "X, X_test, y, y_test = load_cpu_data(**load_data_params)\n",
    "\n",
    "print(f'data shape: {X.shape}, {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeedbf70-0110-4ee4-81ec-afcce883ac05",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5788ef49-6c9f-4827-825b-8a29a1fbe208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (1978081, 4), (2397740, 4)\n"
     ]
    }
   ],
   "source": [
    "#Getting the indices that are associated with land (0) and water (1)\n",
    "y_water_ind = np.where(y>0.5)[0]\n",
    "y_land_ind = np.where(y<0.5)[0]\n",
    "\n",
    "#Subset the X AND y data to later/ subset with the clusters and then combine for RFA\n",
    "X_water = X.iloc[y_water_ind,:]\n",
    "y_water = y.iloc[y_water_ind]\n",
    "\n",
    "X_land = X.iloc[y_land_ind,:]\n",
    "y_land = y.iloc[y_land_ind]\n",
    "print(f'data shape: {X_water.shape}, {X_land.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b38dfe2-a25e-4656-a5e8-444addd34398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sur_refl_b01_1\n",
      "sur_refl_b02_1\n",
      "sur_refl_b07_1\n",
      "ndvi\n"
     ]
    }
   ],
   "source": [
    "_ = [print(column) for column in X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdd11d-a3b3-4733-b95f-f5cb8bd80fc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clustering Data for Input to Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e0854-39fc-409d-82ce-9d340243778b",
   "metadata": {},
   "source": [
    "Based on the cluster analysis above on 5.03.23, 15 clusters appears to have the most data and exclude outliers so will use that number for selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "860899fd-59ae-420d-ac0b-a1ad8940f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_NUM=15\n",
    "\n",
    "common_params = {\n",
    "    \"n_init\": \"auto\",\n",
    "    # \"random_state\": 42,\n",
    "    \"init\":\"random\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14fadaa2-f0c0-43d0-8048-de4c7ef01329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 3.06 s, total: 2min 29s\n",
      "Wall time: 38.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kme_land_random =  KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_land)\n",
    "kmeans_output_land_random = kme_land_random.predict(X_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08b9ac07-2215-4e65-ab83-e67411dec00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 1.52 s, total: 1min 7s\n",
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kme_water_random = KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_water)\n",
    "kmeans_output_water_random = kme_water_random.predict(X_water)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbf9549-0236-4f29-a8a3-c1a2d0ab60e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Even Balanced Random pulled datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42a34ff7-b94d-472b-8e8b-633272252473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50\n",
      "2 2 50\n"
     ]
    }
   ],
   "source": [
    "COUNT_EVEN_BALANCE_LAND = np.inf\n",
    "COUNT_EVEN_BALANCE_WATER = np.inf\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    land_num = len(np.where(kmeans_output_land_random == cluster)[0])\n",
    "    water_num = len(np.where(kmeans_output_water_random == cluster)[0])\n",
    "    if land_num < COUNT_EVEN_BALANCE_LAND: COUNT_EVEN_BALANCE_LAND = land_num\n",
    "    if water_num < COUNT_EVEN_BALANCE_WATER: COUNT_EVEN_BALANCE_WATER = water_num\n",
    "    \n",
    "print(COUNT_EVEN_BALANCE_LAND, COUNT_EVEN_BALANCE_WATER)\n",
    "if COUNT_EVEN_BALANCE_LAND < COUNT_EVEN_BALANCE_WATER:\n",
    "    COUNT = COUNT_EVEN_BALANCE_LAND\n",
    "else: \n",
    "    COUNT = COUNT_EVEN_BALANCE_WATER\n",
    "print(COUNT,COUNT_EVEN_BALANCE_LAND,COUNT_EVEN_BALANCE_WATER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "660e6139-cb3b-4595-9469-215a1252db02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0\n",
      "cluster 1\n",
      "cluster 2\n",
      "cluster 3\n",
      "cluster 4\n",
      "cluster 5\n",
      "cluster 6\n",
      "cluster 7\n",
      "cluster 8\n",
      "cluster 9\n",
      "cluster 10\n",
      "cluster 11\n",
      "cluster 12\n",
      "cluster 13\n",
      "cluster 14\n",
      "(30,) (30,)\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(42)\n",
    "random_ind_land = np.array([])\n",
    "random_ind_water = []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water = np.append(random_ind_water, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT,replace=False)\n",
    "    random_ind_land = np.append(random_ind_land, random_pts_land)\n",
    "    \n",
    "random_ind_water = random_ind_water.astype('int')\n",
    "random_ind_land = random_ind_land.astype('int')\n",
    "\n",
    "print(np.shape(random_ind_water),np.shape(random_ind_land))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61637e1f-2741-4bf4-9745-c6a2e521d16a",
   "metadata": {},
   "source": [
    "## Getting Meta data of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e230982-aa17-48ae-ac01-963766ac0309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (4375821, 8), (4375821,)\n",
      "CPU times: user 5.9 s, sys: 1.94 s, total: 7.83 s\n",
      "Wall time: 7.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This set of parameters has the date/lat lon encoded \n",
    "\n",
    "load_data_params = {'fpath':data_path,'colsToDrop':colsToDrop,'splitXY':True,\n",
    "                    'imbalance':False,'trainTestSplit':True}\n",
    "\n",
    "X_meta, X_meta_test, y_meta, y_meta_test = load_cpu_data(**load_data_params)\n",
    "\n",
    "print(f'data shape: {X_meta.shape}, {y_meta.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a4667a3-ada8-4ba2-a6eb-7135d0c01e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1533442,  417031, 1632745,  656705, 1515223, 1673801, 1514098,\n",
       "       1961484, 1478403, 1691816, 1012069, 1404775,  621396,   10827,\n",
       "        618075,  312738, 1443512, 1462006, 1649248, 1489556, 1350742,\n",
       "        294812, 1122866, 1457842, 1517321,  440037,   13845,   53087,\n",
       "       1375873,  293638, 1672416,  457320, 1358464, 1940804,  373528,\n",
       "        251290,  516364,  782300, 1815342,  731220,  201754,  769669,\n",
       "        576464, 1508382, 2204598,  121782, 1270516, 1816288,  612288,\n",
       "       1686870, 1998778,  865915,  441140, 2110624,  106202, 1352157,\n",
       "       1652666, 1433943,  774852, 2092935])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([random_ind_water,random_ind_land])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50fbcb51-f38b-4d00-9063-9f8d847d28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cluster_inds = np.concatenate([random_ind_water,random_ind_land])\n",
    "clulster_meta_data = X_meta.iloc[total_cluster_inds,4:]\n",
    "# print(clulster_meta_data['year'])\n",
    "after_viirs_launch_inds = clulster_meta_data.loc[clulster_meta_data['year'] > 2012.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f57ee8d-aa28-480c-be69-47698f664b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_offset</th>\n",
       "      <th>y_offset</th>\n",
       "      <th>year</th>\n",
       "      <th>julian_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4583036</th>\n",
       "      <td>1915.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354316</th>\n",
       "      <td>3936.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789874</th>\n",
       "      <td>1287.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072014</th>\n",
       "      <td>4362.0</td>\n",
       "      <td>3967.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890787</th>\n",
       "      <td>1224.0</td>\n",
       "      <td>1181.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788281</th>\n",
       "      <td>4149.0</td>\n",
       "      <td>3639.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4403826</th>\n",
       "      <td>1133.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774791</th>\n",
       "      <td>3279.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417527</th>\n",
       "      <td>4148.0</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513332</th>\n",
       "      <td>2869.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382512</th>\n",
       "      <td>3796.0</td>\n",
       "      <td>883.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276536</th>\n",
       "      <td>908.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180806</th>\n",
       "      <td>4103.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097351</th>\n",
       "      <td>1384.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095863</th>\n",
       "      <td>4116.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114439</th>\n",
       "      <td>4574.0</td>\n",
       "      <td>4697.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033897</th>\n",
       "      <td>1294.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>248.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x_offset  y_offset    year  julian_day\n",
       "4583036    1915.0     587.0  2020.0       171.0\n",
       "354316     3936.0     186.0  2020.0       167.0\n",
       "2789874    1287.0    1341.0  2020.0       209.0\n",
       "4072014    4362.0    3967.0  2020.0       172.0\n",
       "4890787    1224.0    1181.0  2020.0       230.0\n",
       "2788281    4149.0    3639.0  2020.0       187.0\n",
       "4403826    1133.0    3073.0  2020.0       116.0\n",
       "774791     3279.0      36.0  2020.0       124.0\n",
       "4417527    4148.0    3067.0  2020.0       145.0\n",
       "5513332    2869.0     609.0  2020.0       135.0\n",
       "4382512    3796.0     883.0  2020.0       189.0\n",
       "5276536     908.0     452.0  2020.0       185.0\n",
       "1180806    4103.0     247.0  2020.0        83.0\n",
       "5097351    1384.0     646.0  2020.0       273.0\n",
       "4095863    4116.0     518.0  2020.0       206.0\n",
       "5114439    4574.0    4697.0  2020.0       195.0\n",
       "2033897    1294.0    1350.0  2020.0       248.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_viirs_launch_inds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a4cca-556f-4e75-bc92-6361608f42c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Percentage Random pulled datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6a8c5-ad0e-4e6c-89b7-7e75526f654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the clusters: kmeans_output_land and kmeans_output_water\n",
    "# Data: X_water, X_land, y_water, y_land\n",
    "\n",
    "PERCENT_RANDOM_PULL = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa603ad-b373-4797-b1b2-cd966ef1c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "random_ind_land = np.array([])\n",
    "random_ind_water = []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    # cluster_ind_water = np.where(bgm_water == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_WATER = int(PERCENT_RANDOM_PULL*len(cluster_ind_water))\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT_RANDOM_PULL_WATER,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water = np.append(random_ind_water, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    # cluster_ind_land = np.where(bgm_land == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_LAND = int(PERCENT_RANDOM_PULL*len(cluster_ind_land))\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT_RANDOM_PULL_LAND,replace=False)\n",
    "    random_ind_land = np.append(random_ind_land, random_pts_land)\n",
    "    # print(f'Pulling {COUNT_RANDOM_PULL_WATER} Water pts and {COUNT_RANDOM_PULL_LAND} Land pts')\n",
    "    # print()\n",
    "random_ind_water = random_ind_water.astype('int')\n",
    "random_ind_land = random_ind_land.astype('int')\n",
    "\n",
    "print(len(random_ind_water),len(random_ind_land))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad8c21-d046-49b7-8bca-e4fb6cdf145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2,figsize=(20, 10))\n",
    "# var=0\n",
    "# for col in range(2):\n",
    "#     ax[col, 0].set_ylabel('Frequency') \n",
    "#     for row in range(2):\n",
    "#         variable=X_cpu.columns[var]\n",
    "#         if 'ndvi' in variable: \n",
    "#             continue\n",
    "#             var_bins = bin_boundaries\n",
    "#             log_values = False\n",
    "#         else: \n",
    "#             var_bins = None\n",
    "#             log_values = True\n",
    "#         ax[row, col].hist(\n",
    "#             [   \n",
    "#             X_cpu[variable][not_same_point.index].values\n",
    "#             ],\n",
    "#             label=[\n",
    "#             \"data\"\n",
    "#             ],\n",
    "#             bins=var_bins,\n",
    "#         color=['brown'], log=log_values) \n",
    "#         ax[row, col].set_xlabel(f'{variable}')\n",
    "#         var+=1\n",
    "#     ax[0,0].legend(loc='upper right',fontsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f855d30f-505c-45cb-b02b-f94e5d38da4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d307387-dc6d-49ce-be7d-af4346607953",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Total random dataset used for training random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccec67-bee6-4314-b013-ca09089b09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_land_random = X_land.iloc[random_ind_land]\n",
    "y_cluster_land_random = y_land.iloc[random_ind_land]\n",
    "X_cluster_water_random = X_water.iloc[random_ind_water]\n",
    "y_cluster_water_random = y_water.iloc[random_ind_water]\n",
    "\n",
    "X_cluster_random = pd.concat([X_cluster_land_random,X_cluster_water_random])\n",
    "y_cluster_random = pd.concat([y_cluster_land_random,y_cluster_water_random])\n",
    "\n",
    "#Combine the data so that we can shuffle the indices and keep the data together that should be\n",
    "All_data_random = pd.concat([X_cluster_random,y_cluster_random],axis=1).sample(frac=1)\n",
    "\n",
    "X_cluster_rfa_random = All_data_random[X_cluster_random.columns]\n",
    "y_cluster_rfa_random = All_data_random['water']\n",
    "\n",
    "print(X_cluster_rfa_random)\n",
    "print(y_cluster_rfa_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27677834-c156-4527-9f1d-1e53b33a7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ind_land = np.random.choice(\n",
    "    np.arange(len(X_land)),len(random_ind_land),replace=False)\n",
    "print(random_ind_land)\n",
    "print(match_ind_land)\n",
    "\n",
    "match_ind_water = np.random.choice(\n",
    "    np.arange(len(X_water)),len(random_ind_water),replace=False)\n",
    "print(len(random_ind_water))\n",
    "print(len(match_ind_water))\n",
    "\n",
    "# X_match_land_random = X_land.iloc[match_ind_land]\n",
    "# y_match_land_random = y_land.iloc[match_ind_land]\n",
    "# X_match_water_random = X_water.iloc[match_ind_water]\n",
    "# y_match_water_random = y_water.iloc[match_ind_water]\n",
    "\n",
    "X_match_land_random = X_land.iloc[random_ind_land]\n",
    "y_match_land_random = y_land.iloc[random_ind_land]\n",
    "X_match_water_random = X_water.iloc[random_ind_water]\n",
    "y_match_water_random = y_water.iloc[random_ind_water]\n",
    "\n",
    "X_match_random = pd.concat([X_match_land_random,X_match_water_random])\n",
    "y_match_random = pd.concat([y_match_land_random,y_match_water_random])\n",
    "\n",
    "#Combine the data so that we can shuffle the indices and keep the data together that should be\n",
    "All_data_match_random = pd.concat([X_match_random,y_match_random],axis=1).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_match_rfa_random = All_data_match_random[X_match_random.columns]\n",
    "y_match_rfa_random = All_data_match_random['water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba98450-3b2d-46b7-8445-94e67036f79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(All_data_random)\n",
    "print(X_match_rfa_random)\n",
    "print(y_match_rfa_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce60e95-e471-4c4a-a292-7d3e4152cca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8be6ccf-6e47-4297-bb0b-92277c4fc231",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plotting paramater space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4907add-7b1c-4060-90c6-f971c49cc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kme_land_random =  KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_land)\n",
    "kmeans_output_land_random = kme_land_random.predict(X_land)\n",
    "kme_water_random = KMeans(n_clusters=CLUSTER_NUM, **common_params).fit(X_water)\n",
    "kmeans_output_water_random = kme_water_random.predict(X_water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76286d-7e58-444e-97ef-27cd5fa83dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "random_ind_land_eb = np.array([])\n",
    "random_ind_water_eb = []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water_eb = np.append(random_ind_water_eb, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT,replace=False)\n",
    "    random_ind_land_eb = np.append(random_ind_land_eb, random_pts_land)\n",
    "    \n",
    "random_ind_water_eb = random_ind_water_eb.astype('int')\n",
    "random_ind_land_eb = random_ind_land_eb.astype('int')\n",
    "\n",
    "print(random_ind_water_eb,random_ind_land_eb)\n",
    "\n",
    "\n",
    "#############\n",
    "\n",
    "match_ind_land_eb = np.random.choice(np.arange(len(X_land)),len(random_ind_land_eb),replace=False)\n",
    "match_ind_water_eb = np.random.choice(np.arange(len(X_water)),len(random_ind_water_eb),replace=False)\n",
    "\n",
    "X_match_land_eb = X_land.iloc[match_ind_land_eb]\n",
    "X_match_water_eb = X_water.iloc[match_ind_water_eb]\n",
    "X_match_eb = pd.concat([X_match_land_eb,X_match_water_eb])\n",
    "\n",
    "X_cluster_land_eb = X_land.iloc[random_ind_land_eb]\n",
    "X_cluster_water_eb = X_water.iloc[random_ind_water_eb]\n",
    "X_cluster_eb = pd.concat([X_cluster_land_eb,X_cluster_water_eb])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ac0359-2a9c-44c9-b68b-dff80958e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "#############\n",
    "np.random.seed(42)\n",
    "random_ind_land_p = np.array([])\n",
    "random_ind_water_p= []\n",
    "\n",
    "for cluster in np.unique(kmeans_output_water_random):\n",
    "    print(f'cluster {cluster}')\n",
    "    cluster_ind_water = np.where(kmeans_output_water_random == cluster)[0]\n",
    "    # cluster_ind_water = np.where(bgm_water == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_WATER = int(PERCENT_RANDOM_PULL*len(cluster_ind_water))\n",
    "    random_pts_water = np.random.choice(cluster_ind_water,COUNT_RANDOM_PULL_WATER,replace=False)\n",
    "    max_X_random_water = np.nanmax(X_water['sur_refl_b01_1'].iloc[random_pts_water])\n",
    "    if max_X_random_water < 10000:\n",
    "        random_ind_water_p = np.append(random_ind_water_p, random_pts_water)\n",
    "    else: print(f'Cluster {cluster} contains outliers')\n",
    "    \n",
    "    cluster_ind_land = np.where(kmeans_output_land_random == cluster)[0]\n",
    "    # cluster_ind_land = np.where(bgm_land == cluster)[0]\n",
    "    COUNT_RANDOM_PULL_LAND = int(PERCENT_RANDOM_PULL*len(cluster_ind_land))\n",
    "    random_pts_land = np.random.choice(cluster_ind_land,COUNT_RANDOM_PULL_LAND,replace=False)\n",
    "    random_ind_land_p = np.append(random_ind_land_p, random_pts_land)\n",
    "    print(f'Pulling {COUNT_RANDOM_PULL_WATER} Water pts and {COUNT_RANDOM_PULL_LAND} Land pts')\n",
    "    print()\n",
    "random_ind_water_p = random_ind_water_p.astype('int')\n",
    "random_ind_land_p = random_ind_land_p.astype('int')\n",
    "\n",
    "print(random_ind_water_p,random_ind_land_p)\n",
    "\n",
    "#############\n",
    "\n",
    "match_ind_land_p = np.random.choice(np.arange(len(X_land)),len(random_ind_land_p),replace=False)\n",
    "match_ind_water_p = np.random.choice(np.arange(len(X_water)),len(random_ind_water_p),replace=False)\n",
    "\n",
    "X_match_land_p = X_land.iloc[match_ind_land_p]\n",
    "X_match_water_p = X_water.iloc[match_ind_water_p]\n",
    "X_match_p = pd.concat([X_match_land_p,X_match_water_p])\n",
    "\n",
    "X_cluster_land_p = X_land.iloc[random_ind_land_p]\n",
    "X_cluster_water_p = X_water.iloc[random_ind_water_p]\n",
    "X_cluster_p = pd.concat([X_cluster_land_p,X_cluster_water_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da7981-4061-4f85-8c3b-5aef1a65fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2,figsize=(20, 10))\n",
    "var=0\n",
    "for col in range(2):\n",
    "    ax[col, 0].set_ylabel('Frequency') \n",
    "    for row in range(2):\n",
    "        variable=X_land.columns[var]\n",
    "        if 'ndvi' in variable: \n",
    "            # var_bins = bin_boundaries\n",
    "            log_values = False\n",
    "        else: \n",
    "            # var_bins = None\n",
    "            log_values = True\n",
    "        ax[row, col].hist(\n",
    "            [  \n",
    "            # X_cluster_eb[variable].values,\n",
    "            # X_match_eb[variable].values,\n",
    "            X_cluster_p[variable].values,\n",
    "            X_match_p[variable].values,\n",
    "            ],\n",
    "            label=[\n",
    "            # f\"EB Cluster {len(X_cluster_eb)}\",\n",
    "            # \"EB Match\",\n",
    "            f\"P Cluster {len(X_match_p)}\",\n",
    "            f\"P Match\"\n",
    "            ],\n",
    "            #bins=var_bins,\n",
    "        #color=['darkgreen','lightgreen','darkblue','lightblue'], log=log_values) \n",
    "        color=['plum','darkorchid'], log=log_values) \n",
    "        ax[row, col].set_xlabel(f'{variable}')\n",
    "        var+=1\n",
    "    ax[0,0].legend(loc='upper right',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b82dde-f9a2-40c5-a21a-c76837a96d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =  plt.subplots(1, 1,figsize=(10, 5))\n",
    "variable = X_land.columns[0]\n",
    "\n",
    "plt.hist(\n",
    "    [X_cluster_p[variable].values,\n",
    "     X_match_p[variable].values,\n",
    "    ],\n",
    "    label=[\n",
    "        f\"P Cluster {len(X_match_p)}\",\n",
    "        f\"P Match\"\n",
    "        ],\n",
    "    color=['plum','darkorchid'], log=True) \n",
    "\n",
    "plt.ylabel('Frequency') \n",
    "plt.xlabel(f'{variable}')\n",
    "plt.legend(loc='upper right',fontsize=20)   \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3244e03-63f5-45f2-b28d-dfcd6b7bc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_rf_objective(trial):\n",
    "    list_trees = [75, 100, 125, 150, 175, 200, 250, 300, 400, 500]\n",
    "    max_depth = [5, 10, 30, 50, 80, 90, 100, 110]\n",
    "    min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "    min_samples_split = [2, 4, 8, 10]\n",
    "    bootstrap = [True, False]\n",
    "    max_features = ['auto', 'sqrt', 'log2']\n",
    "    \n",
    "    param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
    "       'max_depth':trial.suggest_categorical('max_depth', max_depth), \n",
    "       'min_samples_split':trial.suggest_categorical('min_samples_split', min_samples_split), \n",
    "       'min_samples_leaf':trial.suggest_categorical('min_samples_leaf', min_samples_leaf), \n",
    "       'bootstrap': trial.suggest_categorical('bootstrap', bootstrap),\n",
    "       'criterion':'gini', \n",
    "       #'min_weight_fraction_leaf': trial.suggest_float('min_weight_fraction_leaf', 1e-8, 1.0, log=True), \n",
    "       'max_features':trial.suggest_categorical('max_features', max_features), \n",
    "       'max_leaf_nodes':None, \n",
    "       'min_impurity_decrease':0.0, \n",
    "       'oob_score':False, \n",
    "       'n_jobs':-1, \n",
    "       # 'random_state':42, \n",
    "       'verbose':0, \n",
    "       'warm_start':False, \n",
    "       'class_weight':None, \n",
    "       'ccp_alpha':0.0, \n",
    "       'max_samples':None\n",
    "        }\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    #######################\n",
    "    # HERE IS WHERE TO CHANGE THE X,Y DATASET USED FOR TRAINING\n",
    "    #######################\n",
    "   \n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(X,y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    # for idx, (train_idx, val_idx) in enumerate(cv.split(X_cluster_rfa_random,  y_cluster_rfa_random)):    \n",
    "    #     X_train, X_val = X_cluster_rfa_random.iloc[train_idx], X_cluster_rfa_random.iloc[val_idx]\n",
    "    #     y_train, y_val = y_cluster_rfa_random.iloc[train_idx],  y_cluster_rfa_random.iloc[val_idx]\n",
    "\n",
    "    # for idx, (train_idx, val_idx) in enumerate(cv.split(X_match_rfa_random,  y_match_rfa_random)):    \n",
    "    #     X_train, X_val = X_match_rfa_random.iloc[train_idx], X_match_rfa_random.iloc[val_idx]\n",
    "    #     y_train, y_val = y_match_rfa_random.iloc[train_idx],  y_match_rfa_random.iloc[val_idx]     \n",
    "\n",
    "        model = skRF(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores[idx] = f1_score(y_val, preds)\n",
    "        if cv_scores[idx] == 0.0:\n",
    "            print('Pruning because of 0.0 score.')\n",
    "            return 0.0\n",
    "        print('Fold {}: {}'.format(idx, cv_scores[idx]))\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "search_space={\n",
    "    \"n_estimators\": [75, 100, 125, 150, 175, 200, 250, 300, 400, 500],\n",
    "    \"max_depth\" : [5,10, 30, 50, 80, 90, 100, 110],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5],\n",
    "    \"min_samples_split\" : [2, 4, 8, 10],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"max_features\" : ['auto', 'sqrt', 'log2'],\n",
    "    \n",
    "}\n",
    "TREES_AND_DEPTH_ONLY = False\n",
    "GRID_SEARCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b08f3e-44b5-48f8-acb8-33d538cae39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_rf_objective(trial):\n",
    "    list_trees = [75, 100, 125, 150, 175, 200, 250, 300, 400, 500]\n",
    "    max_depth = [5, 10, 30, 50, 80, 90, 100, 110]\n",
    "    min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "    min_samples_split = [2, 4, 8, 10]\n",
    "    bootstrap = [True, False]\n",
    "    max_features = ['auto', 'sqrt', 'log2']\n",
    "    \n",
    "    param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
    "        'max_depth':trial.suggest_categorical('max_depth', max_depth), \n",
    "        'min_samples_split':trial.suggest_categorical('min_samples_split', min_samples_split), \n",
    "        'min_samples_leaf':trial.suggest_categorical('min_samples_leaf', min_samples_leaf), \n",
    "        'max_features':trial.suggest_categorical('max_features', max_features), \n",
    "            }\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    #######################\n",
    "    # HERE IS WHERE TO CHANGE THE X,Y DATASET USED FOR TRAINING\n",
    "    #######################\n",
    "   \n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(X.to_pandas(),y.to_pandas())):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = cuRFC(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores[idx] = f1_score(y_val.to_numpy(), preds.to_numpy())\n",
    "        del model, preds\n",
    "        if cv_scores[idx] == 0.0:\n",
    "            print('Pruning because of 0.0 score.')\n",
    "            return 0.0\n",
    "        print('Fold {}: {}'.format(idx, cv_scores[idx]))\n",
    "    return np.mean(cv_scores)\n",
    "    \n",
    "search_space={\n",
    "    \"n_estimators\": [75, 100, 125, 150, 175, 200, 250, 300, 400, 500],\n",
    "    \"max_depth\" : [5,10, 30, 50, 80, 90, 100, 110],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5],\n",
    "    \"min_samples_split\" : [2, 4, 8, 10],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"max_features\" : ['auto', 'sqrt', 'log2'],\n",
    "    \n",
    "}\n",
    "TREES_AND_DEPTH_ONLY = False\n",
    "GRID_SEARCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca239ea1-6081-466a-9458-c158eb7f2393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "if GRID_SEARCH:\n",
    "    study = optuna.create_study(study_name='RF Tuning Grid Search', \n",
    "                                direction='maximize',\n",
    "                                sampler=optuna.samplers.GridSampler(search_space))\n",
    "    \n",
    "else:\n",
    "    study = optuna.create_study(study_name='RF Tuning',\n",
    "                                direction='maximize')\n",
    "#Objective is under the functions area\n",
    "\n",
    "#####################################################################\n",
    "#CHANGE HERE FOR DIFFERENT MODELING TYPE\n",
    "#rf_objective or xgb_objective\n",
    "#####################################################################\n",
    "if GPU is False:\n",
    "    study.optimize(cpu_rf_objective, n_trials=25, timeout=30*600)\n",
    "else: \n",
    "    study.optimize(gpu_rf_objective, n_trials=25, timeout=30*600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef706118-c253-40b8-b067-3adba3bdffd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Training and output best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602bb0b-7735-4127-a350-a554dcb8a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = study.best_trials            \n",
    "max_trial_score = max([trial.values[0] for trial in trials])\n",
    "max_trial_params = [trial.params for trial in trials \n",
    "                        if trial.values[0] == max_trial_score][0]\n",
    "max_trial_params['n_jobs'] = -1\n",
    "score_print = int(np.round(max_trial_score,4)*1000)\n",
    "print(max_trial_score)\n",
    "print(score_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb27e0f-3ab7-41f8-bda7-2c0e7564578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = max_trial_params\n",
    "hyperparameters['n_jobs'] = -1\n",
    "print('Using these params:')\n",
    "print(hyperparameters)\n",
    "tuned_classifier = skRF(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dea7c9-7927-4f2c-9b11-8bfa0dd082ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "tuned_classifier.fit(X,y) #_match_rfa_random , y_match_rfa_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29964f62-43bb-453c-9b65-a7526af71bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = f'rfa_models/MODIS_RFA_Targeted_v000_MaxScore{score_print}_sfcref127ndvi.pkl'\n",
    "print(filename)\n",
    "pickle.dump(tuned_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3220fba-351e-4bc5-9e24-f2af5dcf901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickled_model = pickle.load(open('rfa_models/MODIS_RFA_v201_EBCluster_sfcref127ndvi_4.pkl', 'rb'))\n",
    "# print(pickled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee12a19-8cf8-472d-ba4d-e269e7356272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (TensorFlow)",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
