{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b714c30-b71c-43c6-9fe3-9b012a7bfdfe",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  MODIS Water Cluster Training\n",
    "\n",
    "Version: 0.1.0\n",
    "\n",
    "Date modified: 05.01.2023\n",
    "\n",
    "Modified by: Amanda Burke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f43eed03-46c0-41a4-b716-4e543a00f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import joblib\n",
    "import optuna\n",
    "import pickle\n",
    "import time\n",
    "import glob\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# GPU-based frameworks\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from cuml.ensemble import RandomForestClassifier as cuRFC\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0c8f7-a553-43aa-a7a9-720557034e6f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3005c-5b10-48f6-9ebe-f221e488b92d",
   "metadata": {},
   "source": [
    "Changing these are the most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c697f3fe-a6a8-4783-aa06-d79baaaa2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VERSION 4.2.1 (targeted 500k points)\n",
    "# DATASET_VERSION = 'v421'\n",
    "## VERSION 2.0.1 (5 million points)\n",
    "DATASET_VERSION = 'v201'\n",
    "## VERSION 0.0.0 (2billion data points)\n",
    "# DATASET_VERSION = 'v000'\n",
    "\n",
    "## No clustering to rf\n",
    "CLUSTER_MODELS = ['Nocluster']\n",
    "## Proportional or even balance clustering to rf\n",
    "# CLUSTER_MODELS = ['EBmatch','EBcluster','Pmatch','Pcluster']\n",
    "\n",
    "## Variables input to the rf\n",
    "input_vars = ['sur_refl_b01_1','sur_refl_b02_1','sur_refl_b07_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef09a8be-17ed-40a8-958e-ed66b83929bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(CLUSTER_MODELS) < 2) and ('Noc' in CLUSTER_MODELS[0]):\n",
    "    PROCESSOR = 'gpu'\n",
    "else: \n",
    "    PROCESSOR = 'cpu'\n",
    "    \n",
    "TEST_RATIO = 0.2\n",
    "v_names = [\n",
    "    'sur_refl_b01_1','sur_refl_b02_1','sur_refl_b03_1',\n",
    "    'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
    "    'sur_refl_b07_1','ndvi','ndwi1','ndwi2'\n",
    "    ]\n",
    "common_params = {\n",
    "    \"n_init\": \"auto\"\n",
    "}\n",
    "droped_vars = [v for v in v_names if v not in input_vars]\n",
    "#RF Training\n",
    "search_space={\n",
    "    \"n_estimators\": [75, 100, 125, 150, 175, 200, 250, 300, 400, 500],\n",
    "    \"max_depth\" : [5, 10, 30, 50, 80, 90, 100, 110],\n",
    "    \"min_samples_leaf\" : [1, 2, 3, 4, 5],\n",
    "    \"min_samples_split\" : [2, 4, 8, 10],\n",
    "    \"bootstrap\" : [True, False],\n",
    "    \"max_features\" : ['auto', 'sqrt', 'log2'] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b186d-7086-4346-8f59-be1048f778d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62b27b38-d384-4fba-bdc6-f1970e7f6bd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729b926-4895-4835-9225-0d3863f8f40f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cd372-f48f-4cdf-90b7-f8a8fc9d66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_clusters(X_w,X_l,cluster_output_w,cluster_output_l, n_cluster,\n",
    "                      kme_w=None,kme_l=None):\n",
    "    fig = plt.figure(figsize = (25, 10))\n",
    "\n",
    "    plt.suptitle(f'Kmeans Clustering {DATA_VERSION} Data, {n_cluster} Clusters')\n",
    "\n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.set_title(f'Land and Water Datapoints')\n",
    "    ax1.scatter(X_w.values[:,0], X_w.values[:,1],label='Water')\n",
    "    ax1.scatter(X_l.values[:,0], X_l.values[:,1],label='Land')\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax1.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    ax1.set_xlabel(X_w.columns[0])\n",
    "    ax1.set_ylabel(X_w.columns[1])\n",
    "    ax1.legend(loc='lower right',fontsize=\"20\")\n",
    "\n",
    "    ax2 = plt.subplot(132)\n",
    "    ax2.set_title(f'Water Datapoints Clustered: {len(X_water)} Examples')\n",
    "    ax2.scatter(X_w.values[:,0], X_w.values[:,1],c=cluster_output_w,cmap='tab10')\n",
    "    if kme_w is not None:\n",
    "        ax2.scatter(kme_w.cluster_centers_[:,0],kme_w.cluster_centers_[:,1],\n",
    "            label='Center Point',c='k',s=150)\n",
    "        ax2.legend(loc='lower right',fontsize=\"20\")\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax2.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    ax2.set_xlabel(X_w.columns[0])\n",
    "    ax2.set_ylabel(X_w.columns[1])\n",
    "    \n",
    "\n",
    "    ax3 = plt.subplot(133)\n",
    " \n",
    "    ax3.set_title(f'Land Datapoints Clustered: {len(X_land)} Examples')\n",
    "    ax3.scatter(X_l.values[:,0], X_l.values[:,1],c=cluster_output_l,cmap='tab10')\n",
    "    if kme_l is not None:\n",
    "        ax3.scatter(kme_l.cluster_centers_[:,0],kme_l.cluster_centers_[:,1],\n",
    "                    label='Center Point',c='k',s=150)\n",
    "        ax3.legend(loc='lower right',fontsize=\"20\")\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax3.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    ax3.set_xlabel(X_l.columns[0])\n",
    "    ax3.set_ylabel(X_l.columns[1])\n",
    "   \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a675b-fb62-484d-8a3d-9b8fed870873",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading and extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fd27567-2a51-4e94-8d0a-43504a90bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_load_data(fpath, colsToDrop, \n",
    "    yCol='water', testSize=0.2, randomState=42,\n",
    "    dataType=np.int16, cpu=True, splitXY=True, trainTestSplit=True,\n",
    "    applyLog=False, imbalance=False, frac=0.1, land=False, multi=False, \n",
    "    multisample=1000000, ndvi_change=True):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by models\n",
    "    :param fpath: Path to the data to be ingested.\n",
    "    :param dataType: Data type to convert ingested data to.\n",
    "    :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "    :param testSize: Ration to\n",
    "    \"\"\"\n",
    "    if multi:\n",
    "        all_dfs = [pd.read_csv(path_) for\n",
    "                   path_ in fpath]\n",
    "        df = pd.concat(all_dfs).sample(n=multisample, random_state=randomState)\n",
    "        print('DF length: {}'.format(len(df.index)))\n",
    "    else:   \n",
    "        df = pd.read_parquet(fpath) if '.parquet' in fpath else pd.read_csv(fpath)\n",
    "    df = df[df['sur_refl_b01_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b07_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b06_1'] + df['sur_refl_b02_1'] != 0]\n",
    "\n",
    "    df = df.drop(columns=colsToDrop)\n",
    "    cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0).astype(dataType)\n",
    "    if applyLog:\n",
    "        for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "            print('Applying log1p func to {}'.format(col))\n",
    "            cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "        cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    df = None\n",
    "    if imbalance:\n",
    "        if land:\n",
    "            print('Imbalancing data, sampling {} from water'.format(frac))\n",
    "        else:\n",
    "            print(f'Imbalancing data, sampling {frac} from land, {1-frac} from water')\n",
    "        groupedDF = cleanedDF.groupby('water')\n",
    "        dfs = [groupedDF.get_group(y) for y in groupedDF.groups]\n",
    "        sampledDF = dfs[1].sample(frac=frac)if land else dfs[0].sample(frac=frac)\n",
    "        concatDF = sampledDF.append(dfs[0]) if land else sampledDF.append(dfs[1])\n",
    "        concatDF = concatDF.sample(frac=1)\n",
    "        concatDF = concatDF.reset_index()\n",
    "        cleanedDF = concatDF.drop(columns=['index'])\n",
    "    if not splitXY:\n",
    "        return cleanedDF\n",
    "    cleanedX = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    cleanedy = cleanedDF[yCol].astype(dataType)\n",
    "    \n",
    "    ############\n",
    "    #Added calculation of NDVI instead of the file point\n",
    "    ############\n",
    "    if ndvi_change is True:\n",
    "        top_math_ndvi = (cleanedX['sur_refl_b02_1'].values - cleanedX['sur_refl_b01_1'].values)\n",
    "        bot_math_ndvi = (cleanedX['sur_refl_b02_1'].values + cleanedX['sur_refl_b01_1'].values)\n",
    "        calculated_ndvi = top_math_ndvi/bot_math_ndvi\n",
    "        calculated_ndvi[calculated_ndvi > 1.0] = 1.0\n",
    "        calculated_ndvi[calculated_ndvi < -1.0] = -1.0\n",
    "        scaled_ndvi = (10000*calculated_ndvi).astype(int)\n",
    "        cleanedX['ndvi'] = scaled_ndvi\n",
    "        \n",
    "    if trainTestSplit:\n",
    "        return train_test_split(cleanedX, cleanedy, test_size=TEST_RATIO)\n",
    "    else:\n",
    "        return cleanedX, cleanedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5033fe-4542-46e5-9043-317ca2d7ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_load_data(fpath, colsToDrop, yCol='water', testSize=0.2, randomState=42, \n",
    "            dataType=cp.float32, cpu=False, splitXY=True, trainTestSplit=True,\n",
    "            applyLog=False, imbalance=False, frac=0.1, land=False, multi=False, \n",
    "            multisample=1000000, ndvi_change=True):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by models\n",
    "    :param fpath: Path to the data to be ingested.\n",
    "    :param dataType: Data type to convert ingested data to.\n",
    "    :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "    :param testSize: Ration to\n",
    "    \"\"\"\n",
    "    if multi:\n",
    "        all_dfs = [pd.read_csv(path_) for path_ in fpath]\n",
    "        df = pd.concat(all_dfs).sample(n=multisample, random_state=randomState)\n",
    "        print('DF length: {}'.format(len(df.index)))\n",
    "    else:   \n",
    "        df = pd.read_parquet(fpath) if '.parquet' in fpath else pd.read_csv(fpath)\n",
    "    df = df[df['sur_refl_b01_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b07_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b06_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df.drop(columns=colsToDrop)\n",
    "    cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0).astype(dataType)\n",
    "    cleanedDF = cudf.from_pandas(cleanedDF) if not cpu else cleanedDF\n",
    "    if applyLog:\n",
    "        for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "            print('Applying log1p func to {}'.format(col))\n",
    "            cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "        cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    df = None\n",
    "    if imbalance:\n",
    "        if land:\n",
    "            print('Imbalancing data, sampling {} from water'.format(frac))\n",
    "        else:\n",
    "            print('Imbalancing data, sampling {} from land'.format(frac))\n",
    "        groupedDF = cleanedDF.groupby('water')\n",
    "        dfs = [groupedDF.get_group(y) for y in groupedDF.groups]\n",
    "        sampledDF = dfs[1].sample(frac=frac)if land else dfs[0].sample(frac=frac)\n",
    "        concatDF = sampledDF.append(dfs[0]) if land else sampledDF.append(dfs[1])\n",
    "        concatDF = concatDF.sample(frac=1)\n",
    "        concatDF = concatDF.reset_index()\n",
    "        cleanedDF = concatDF.drop(columns=['index'])\n",
    "    if not splitXY:\n",
    "        return cleanedDF\n",
    "    X = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    y = cleanedDF[yCol].astype(dataType)\n",
    "    \n",
    "    cleanedX = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    cleanedy = cleanedDF[yCol].astype(dataType)\n",
    "    \n",
    "    ############\n",
    "    #Added calculation of NDVI instead of the file point\n",
    "    ############\n",
    "    if ndvi_change is True:\n",
    "        top_math_ndvi = (cleanedX['sur_refl_b02_1'].values - cleanedX['sur_refl_b01_1'].values)\n",
    "        bot_math_ndvi = (cleanedX['sur_refl_b02_1'].values + cleanedX['sur_refl_b01_1'].values)\n",
    "        calculated_ndvi = top_math_ndvi/bot_math_ndvi\n",
    "        calculated_ndvi[calculated_ndvi > 1.0] = 1.0\n",
    "        calculated_ndvi[calculated_ndvi < -1.0] = -1.0\n",
    "        scaled_ndvi = (10000*calculated_ndvi).astype(int)\n",
    "        cleanedX['ndvi'] = scaled_ndvi\n",
    "    if trainTestSplit:\n",
    "        return train_test_split(cleanedX, cleanedy, test_size=TEST_RATIO)\n",
    "    else:\n",
    "        return cleanedX, cleanedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24bef151-652f-4cad-b1ca-5c4e64344c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(tile, data_version, offsets_indexes, \n",
    "                    ndvi_calc=True, colsToDrop=droped_vars):\n",
    "    \n",
    "    training_data_basepath = f'/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/{data_version}'\n",
    "    glob_string = os.path.join(training_data_basepath,'MOD*{}*.parquet.gzip'.format(tile))\n",
    "    data_paths = sorted([fv for fv in glob.glob(glob_string)])\n",
    " \n",
    "    data_path = data_paths[0]\n",
    "    print(data_path)\n",
    "\n",
    "    colsToDropTraining = colsToDrop.copy()\n",
    "    colsToDropTraining.extend(offsets_indexes)\n",
    "    \n",
    "    if 'gpu' in PROCESSOR:\n",
    "        X_gpu, X_test, y_gpu, y_test = gpu_load_data(\n",
    "            fpath=data_path,\n",
    "            colsToDrop=colsToDropTraining\n",
    "            )\n",
    "        X_cpu, X_test, y_cpu, y_test = cpu_load_data(\n",
    "            fpath=data_path,\n",
    "            colsToDrop=colsToDropTraining\n",
    "            )\n",
    "        print('Input Variables', X_cpu.columns)\n",
    "        print(f'data shape: {X_cpu.shape}, {y_cpu.shape}')\n",
    "        return X_gpu, y_gpu, X_cpu, y_cpu\n",
    "    else: \n",
    "        X, X_test, y, y_test = cpu_load_data(\n",
    "            fpath=data_path,\n",
    "            colsToDrop=colsToDropTraining\n",
    "            )\n",
    "        print('Input Variables', X.columns)\n",
    "        print(f'data shape: {X.shape}, {y.shape}')\n",
    "        \n",
    "    #Getting the indices that are associated with land (0) and water (1)\n",
    "    water_indx = np.where(y>0.5)[0]\n",
    "    land_indx = np.where(y<0.5)[0]\n",
    "    # print(y.iloc[water_indx])\n",
    "    # print('Min water value:',np.nanmin(y.iloc[water_indx]),', Min land value:',np.nanmin(y.iloc[land_indx]))\n",
    "    print()\n",
    "\n",
    "    return X, y, water_indx, land_indx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e435e0-8089-4c0f-8ab0-ef140c5eb414",
   "metadata": {},
   "source": [
    "### Kmeans Clustering and Matching Size dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e0854-39fc-409d-82ce-9d340243778b",
   "metadata": {},
   "source": [
    "Based on the cluster analysis above on 5.03.23, 15 clusters appears to have the most data and exclude outliers so will use that number for selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d66a293-e0e7-419f-a6c2-e558102de4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(cluster_type, InX, InY, water_i, land_i, \n",
    "                      kwargs=common_params, plotting=False, CLUSTER_NUM=15, \n",
    "                      PERCENT_RANDOM_PULL=0.15, match=True):\n",
    "\n",
    "    InY_w = InY.iloc[water_i].reset_index(drop=True)\n",
    "    InY_l = InY.iloc[land_i].reset_index(drop=True)\n",
    "    InX_w = InX.iloc[water_i].reset_index(drop=True)\n",
    "    InX_l = InX.iloc[land_i].reset_index(drop=True)\n",
    "    \n",
    "    kme_land_model = MiniBatchKMeans(n_clusters=CLUSTER_NUM, **kwargs).fit(InX_l)\n",
    "    kme_land = kme_land_model.predict(InX_l)\n",
    "\n",
    "    kme_water_model = MiniBatchKMeans(n_clusters=CLUSTER_NUM, **kwargs).fit(InX_w)\n",
    "    kme_water = kme_water_model.predict(InX_w)\n",
    "    \n",
    "    if plotting:\n",
    "        plotting_clusters(\n",
    "                    InX_w, InX_l,\n",
    "                    kme_water,kme_land,\n",
    "                    CLUSTER_NUM,kme_water_model,kme_land_model)\n",
    "    if 'Even' in cluster_type: \n",
    "        eb_count_water  = np.inf\n",
    "        eb_count_land = np.inf\n",
    "        for c in np.arange(CLUSTER_NUM):\n",
    "            water_num = len(np.where(kme_water == c)[0])\n",
    "            if water_num < eb_count_water: eb_count_water = water_num\n",
    "            land_num = len(np.where(kme_land == c)[0])\n",
    "            if land_num < eb_count_land: eb_count_land = land_num\n",
    "        if eb_count_land < eb_count_water: COUNT = eb_count_land\n",
    "        else: COUNT = eb_count_water\n",
    "    \n",
    "    w_l_cluster_indx = []\n",
    "    for label in [kme_water,kme_land]:\n",
    "        cluster_indx = []\n",
    "        for c in np.arange(CLUSTER_NUM):\n",
    "            indx = np.where(label == c)[0]  \n",
    "            if 'Even' in cluster_type: selection_count = COUNT\n",
    "            else: selection_count = int(PERCENT_RANDOM_PULL*len(indx))\n",
    "            rand_indx = np.random.choice(indx,selection_count,replace=False)\n",
    "            cluster_indx.extend(list(rand_indx))\n",
    "        w_l_cluster_indx.append(cluster_indx)\n",
    "    \n",
    "    clusterY = pd.concat(\n",
    "        [InY_w.iloc[w_l_cluster_indx[0]],InY_l.iloc[w_l_cluster_indx[1]]]\n",
    "         ).reset_index(drop=True).sample(frac=1)\n",
    "    clusterX = pd.concat(\n",
    "        [InX_w.iloc[w_l_cluster_indx[0]],InX_l.iloc[w_l_cluster_indx[1]]]\n",
    "         ).reset_index(drop=True).iloc[clusterY.index]\n",
    "    if match is False:\n",
    "        print(\"Using clustered data\")\n",
    "        return clusterX, clusterY\n",
    "    else:\n",
    "        print(\"Using Randomly Matched Data\")\n",
    "        matchY_w = InY_w.sample(n=len(w_l_cluster_indx[0]),replace=False)\n",
    "        matchY_l = InY_l.sample(n=len(w_l_cluster_indx[1]),replace=False)\n",
    "    \n",
    "        matchY = pd.concat([matchY_w,matchY_l]).reset_index(drop=True).sample(frac=1)  \n",
    "        matchX = pd.concat(\n",
    "            [InX_w.iloc[matchY_w.index], InX_l.iloc[matchY_l.index]]\n",
    "            ).reset_index(drop=True).iloc[matchY.index]\n",
    "        return matchX, matchY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223ed7a-dd6a-4f04-ba2c-711551e1a4af",
   "metadata": {},
   "source": [
    "### Random Forest functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3244e03-63f5-45f2-b28d-dfcd6b7bc8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rf_objective(trial, rfaX, rfaY):\n",
    "    list_trees = [75, 100, 125, 150, 175, 200, 250, 300, 400, 500]\n",
    "    max_depth = [5, 10, 30, 50, 80, 90, 100, 110]\n",
    "    min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "    min_samples_split = [2, 4, 8, 10]\n",
    "    bootstrap = [True, False]\n",
    "    max_features = ['auto', 'sqrt', 'log2']\n",
    "    \n",
    "    param = {'n_estimators': trial.suggest_categorical('n_estimators', list_trees), \n",
    "        'max_depth':trial.suggest_categorical('max_depth', max_depth), \n",
    "        'min_samples_split':trial.suggest_categorical('min_samples_split', min_samples_split), \n",
    "        'min_samples_leaf':trial.suggest_categorical('min_samples_leaf', min_samples_leaf), \n",
    "        'max_features':trial.suggest_categorical('max_features', max_features), \n",
    "                      }\n",
    "    cpu_param = { \n",
    "        'max_leaf_nodes':None, \n",
    "        'min_impurity_decrease':0.0, \n",
    "        'oob_score':False, \n",
    "        'verbose':0, \n",
    "        'n_jobs': -1,\n",
    "        'warm_start':False, \n",
    "        'class_weight':None, \n",
    "        'ccp_alpha':0.0, \n",
    "        'max_samples':None\n",
    "                      }\n",
    "    if 'gpu' in PROCESSOR: \n",
    "        avg_cv_scores = gpu_rf_objective(rfaX, rfaY, param)\n",
    "    else: \n",
    "        avg_cv_scores = cpu_rf_objective(rfaX, rfaY, param.update(cpu_param))\n",
    "    \n",
    "    return avg_cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40bf6170-96a7-448f-a308-393612eb8df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cpu_rf_objective(rfaX, rfaY, param):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(rfaX,rfaY)):\n",
    "        X_train, X_val = rfaX.iloc[train_idx], rfaX.iloc[val_idx]\n",
    "        y_train, y_val = rfaY.iloc[train_idx],  rfaY.iloc[val_idx]\n",
    "        model = skRF(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores[idx] = f1_score(y_val, preds)\n",
    "        if cv_scores[idx] == 0.0:\n",
    "            print('Pruning because of 0.0 score.')\n",
    "            return 0.0\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48bb0f1d-85e8-4395-87f7-93c01685ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_rf_objective(rfaX, rfaY, param):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, val_idx) in enumerate(cv.split(rfaX.to_pandas(), rfaY.to_pandas())):\n",
    "        X_train, X_val = rfaX.iloc[train_idx], rfaX.iloc[val_idx]\n",
    "        y_train, y_val = rfaY.iloc[train_idx], rfaY.iloc[val_idx]\n",
    "        model = cuRFC(**param)\n",
    "        model.fit(X_train, \n",
    "                  y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        cv_scores[idx] = f1_score(y_val.to_numpy(), preds.to_numpy())\n",
    "        del model, preds\n",
    "        if cv_scores[idx] == 0.0:\n",
    "            print('Pruning because of 0.0 score.')\n",
    "            return 0.0\n",
    "        print('Fold {}: {}'.format(idx, cv_scores[idx]))\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca239ea1-6081-466a-9458-c158eb7f2393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def running_rfa(rfaX, rfaY,num_trials=1):\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    study = optuna.create_study(\n",
    "        study_name='RF Tuning Grid Search', direction='maximize',\n",
    "        sampler=optuna.samplers.GridSampler(search_space))\n",
    "    study.optimize(\n",
    "            lambda trial: rf_objective(trial, rfaX, rfaY), \n",
    "            n_trials=num_trials, timeout=30*600\n",
    "            )\n",
    "    trials = study.best_trials            \n",
    "    max_trial_score = max([trial.values[0] for trial in trials])\n",
    "    max_trial_params = [trial.params for trial in trials \n",
    "                        if trial.values[0] == max_trial_score][0]\n",
    "    max_trial_params['n_jobs'] = -1\n",
    "    return max_trial_score, max_trial_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4baa2cf-000f-4119-8f05-26a9384eb67a",
   "metadata": {},
   "source": [
    "### Running the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bb0fe47-657c-4bdd-b41d-cb8e70068281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/projects/ilab/data/MODIS/MODIS_WATER_ML/training_data/v2.0.1/MOD09_GLOBAL_5469777_2_0_1.parquet.gzip\n",
      "Input Variables Index(['sur_refl_b01_1', 'sur_refl_b02_1', 'sur_refl_b07_1', 'ndvi'], dtype='object')\n",
      "data shape: (4375821, 4), (4375821,)\n",
      "CPU times: user 6.94 s, sys: 1.46 s, total: 8.4 s\n",
      "Wall time: 7.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if '201' in DATASET_VERSION: \n",
    "    pre_process_params = {\n",
    "        'tile':'GLOBAL',\n",
    "        'data_version':'v2.0.1',\n",
    "        'offsets_indexes': ['x_offset','y_offset','year','julian_day']}\n",
    "if '421' in DATASET_VERSION:\n",
    "    pre_process_params = {\n",
    "        'tile':'Golden',\n",
    "        'data_version':'v4.2.1',\n",
    "        'offsets_indexes': ['x_offset','y_offset','year','julian_day','tileID']}\n",
    "if '000' in DATASET_VERSION:\n",
    "    pre_process_params = {\n",
    "        'tile':'cleaned',\n",
    "        'data_version':'AGU',\n",
    "        'offsets_indexes': []} \n",
    "if 'gpu' in PROCESSOR:\n",
    "    X_gpu, y_gpu, X_cpu, y_cpu = pre_process_data(**pre_process_params)\n",
    "else: \n",
    "    X_cpu, y_cpu, water_indx, land_indx = pre_process_data(**pre_process_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fccb8-3634-4481-9282-796c6c63ff1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7850ead-84e0-449f-8b3f-97bc45ec18a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:36:29,496]\u001b[0m A new study created in memory with name: RF Tuning Grid Search\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 0.9757121234709529\n",
      "Fold 1: 0.975898454919032\n",
      "Fold 2: 0.976194296384358\n",
      "Fold 3: 0.9759809768325718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:41:16,198]\u001b[0m Trial 0 finished with value: 0.9759159578448233 and parameters: {'n_estimators': 300, 'max_depth': 110, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 0 with value: 0.9759159578448233.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9757939376172016\n",
      "Fold 0: 0.9768916429324161\n",
      "Fold 1: 0.9770702117392633\n",
      "Fold 2: 0.977306556080352\n",
      "Fold 3: 0.977182395500932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:43:35,598]\u001b[0m Trial 1 finished with value: 0.9771024186514616 and parameters: {'n_estimators': 150, 'max_depth': 90, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9770612870043446\n",
      "Fold 0: 0.9751214075816014\n",
      "Fold 1: 0.9752317634513876\n",
      "Fold 2: 0.9754407271761201\n",
      "Fold 3: 0.9752497292701933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:45:48,058]\u001b[0m Trial 2 finished with value: 0.9752272340340781 and parameters: {'n_estimators': 250, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9750925426910882\n",
      "Fold 0: 0.976720559525389\n",
      "Fold 1: 0.9768319088031168\n",
      "Fold 2: 0.9771138772230393\n",
      "Fold 3: 0.9769703127705258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:48:51,699]\u001b[0m Trial 3 finished with value: 0.9768802716514733 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.976764699935296\n",
      "Fold 0: 0.9764545193803249\n",
      "Fold 1: 0.9765588681152096\n",
      "Fold 2: 0.9768556596181228\n",
      "Fold 3: 0.9766723616769615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:51:52,789]\u001b[0m Trial 4 finished with value: 0.9766031606169246 and parameters: {'n_estimators': 200, 'max_depth': 80, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'auto'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9764743942940043\n",
      "Fold 0: 0.9768181755005755\n",
      "Fold 1: 0.9769918211387248\n",
      "Fold 2: 0.9772163862095455\n",
      "Fold 3: 0.977071895821327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:54:13,685]\u001b[0m Trial 5 finished with value: 0.976989746454376 and parameters: {'n_estimators': 150, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9768504536017074\n",
      "Fold 0: 0.9768725431104742\n",
      "Fold 1: 0.977059468527511\n",
      "Fold 2: 0.9772950980206339\n",
      "Fold 3: 0.9772019572953737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:57:17,243]\u001b[0m Trial 6 finished with value: 0.9770912293840149 and parameters: {'n_estimators': 200, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9770270799660821\n",
      "Fold 0: 0.9768164686588323\n",
      "Fold 1: 0.9770071093280245\n",
      "Fold 2: 0.9771904819666828\n",
      "Fold 3: 0.9770986385057812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 16:58:53,678]\u001b[0m Trial 7 finished with value: 0.9769918546426432 and parameters: {'n_estimators': 100, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9768465747538955\n",
      "Fold 0: 0.9767008128622531\n",
      "Fold 1: 0.9768262658391748\n",
      "Fold 2: 0.9770984843507573\n",
      "Fold 3: 0.9769579662653405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 17:00:53,348]\u001b[0m Trial 8 finished with value: 0.9768618517810614 and parameters: {'n_estimators': 125, 'max_depth': 50, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9767257295877813\n",
      "Fold 0: 0.9766150665839447\n",
      "Fold 1: 0.9767340215353676\n",
      "Fold 2: 0.9769942273944184\n",
      "Fold 3: 0.9768318250577214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-11 17:02:25,514]\u001b[0m Trial 9 finished with value: 0.9767585086498547 and parameters: {'n_estimators': 100, 'max_depth': 100, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 1 with value: 0.9771024186514616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 0.9766174026778212\n",
      "\n",
      " 9771, 4375821 Samples\n",
      "Saving random forest to: rfa_models/MODIS_RFA_v201_Nocluster_MaxScore9771_SfcRef127ndvi.pkl\n",
      "Execution time: 00:27:36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "best_trial_data = {}\n",
    "start_time = time.time()\n",
    "\n",
    "if 'gpu' in PROCESSOR: \n",
    "    nocluster_score, nocluster_param = running_rfa(X_gpu, y_gpu,num_iterations)\n",
    "    noc_round_score = int(np.round(nocluster_score,5)*10000)\n",
    "    print(f'\\n {noc_round_score}, {len(X_gpu)} Samples')\n",
    "    nocluster_param['n_jobs'] = -1\n",
    "    #RFA fitting\n",
    "    nocluster_rfa = skRF(**nocluster_param)\n",
    "    nocluster_rfa.fit(X_cpu,y_cpu)\n",
    "    #Output rfa file\n",
    "    noc_rfa_filename = f'rfa_models/MODIS_RFA_{DATASET_VERSION}_Nocluster_MaxScore{noc_round_score}_SfcRef127ndvi.pkl'\n",
    "    print(f'Saving random forest to: {noc_rfa_filename}')\n",
    "    pickle.dump(nocluster_rfa, open(noc_rfa_filename, 'wb'))\n",
    "else: \n",
    "    kmeans_params = {'InX': X_cpu, 'InY': y_cpu, 'water_i': water_indx, 'land_i': land_indx}\n",
    "    for cluster_type in CLUSTER_MODELS:\n",
    "        print(f'\\n{cluster_type}')\n",
    "        best_score = 0\n",
    "        for i in np.arange(num_iterations):\n",
    "            print(f'Iteration: {i}')\n",
    "            if 'cluster' in cluster_type: kmeans_params['match'] = False\n",
    "            if 'EB' in cluster_type: kmeans_params['cluster_type'] = 'Even Balance'\n",
    "            if 'P' in cluster_type: kmeans_params['cluster_type'] = 'Percent'\n",
    "            print(kmeans_params)\n",
    "            rfa_pred, rfa_label = kmeans_clustering(**kmeans_params)\n",
    "            tuning_score, rfa_param = running_rfa(rfa_pred, rfa_label)\n",
    "            if tuning_score > best_score:\n",
    "                best_label = rfa_label\n",
    "                best_pred = rfa_pred\n",
    "                best_param = rfa_param\n",
    "                best_score = tuning_score\n",
    "            else: continue \n",
    "            del rfa_pred, rfa_label, rfa_param, tuning_score\n",
    "        #Save data for plotting\n",
    "        best_trial_data[cluster_type] = pd.concat([best_pred,best_label],axis=1)\n",
    "        #Print out best iteration info \n",
    "        round_score = int(np.round(best_score,5)*10000)\n",
    "        print(f'\\nMax score for {cluster_type}: {round_score}, {len(best_pred)} Samples')\n",
    "        #RFA fitting\n",
    "        best_rfa = skRF(**best_param)\n",
    "        best_rfa.fit(best_pred,best_label)\n",
    "        #Output rfa file\n",
    "        rfa_filename = f'rfa_models/MODIS_RFA_{DATASET_VERSION}_{cluster_type}_MaxScore{round_score}_SfcRef127ndvi.pkl'\n",
    "        print(f'Saving random forest to: {rfa_filename}')\n",
    "        pickle.dump(best_rfa, open(rfa_filename, 'wb'))\n",
    "        #Print out time length \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'Execution time: {time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d8541-74f4-4d5b-b279-38bb0a297a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14903308-fb43-460a-99b1-693b8cdf4fa4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e8879-a05e-4a1a-87e3-061ac0d5f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_trial_data)\n",
    "['EBmatch','EBcluster','Pmatch','Pcluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed094c0f-363c-46db-89e0-944575ecfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2,figsize=(20, 10))\n",
    "var=0\n",
    "for col in range(2):\n",
    "    ax[col, 0].set_ylabel('Frequency') \n",
    "    for row in range(2):\n",
    "        variable=v201_X.columns[var]\n",
    "        if 'ndvi' in variable: \n",
    "            var_bins = bin_boundaries\n",
    "            log_values = False\n",
    "        else: \n",
    "            var_bins = None\n",
    "            log_values = True\n",
    "        ax[row, col].hist(\n",
    "            [   \n",
    "                v201_X[variable].values,\n",
    "                best_trial_data['EBmatch'][variable].values,\n",
    "                best_trial_data['EBcluster'][variable].values,\n",
    "                best_trial_data['Pmatch'][variable].values,\n",
    "                best_trial_data['Pcluster'][variable].values\n",
    "            ],\n",
    "            label=[\n",
    "                #Change these\n",
    "                'v2.0.1',\n",
    "                'EB Match',\n",
    "                'EB Cluster',\n",
    "                'Percent Match',\n",
    "                'Percent Cluster',\n",
    "            ],\n",
    "            bins=var_bins,\n",
    "        color=['orange',\n",
    "               'brown',\n",
    "               'steelblue',\n",
    "               'lightgreen',\n",
    "               'pink'\n",
    "              ], log=log_values) \n",
    "        ax[row, col].set_xlabel(f'{variable}')\n",
    "        var+=1\n",
    "    ax[0,0].legend(loc='upper right',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75088f-e9a1-4f6a-b34e-96b60a4ba9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EB_cluster_X, EB_cluster_y, EB_match_X, EB_match_y = kmeans_clustering(\n",
    "#     'Even Balance', v201_X, v201_y, v201_water_i, v201_land_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb9fb1-e6c0-447d-9821-57e33e004038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_cluster_X, P_cluster_y, P_match_X, P_match_y = kmeans_clustering(\n",
    "#     'Percent', v201_X, v201_y, v201_water_i, v201_land_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76526a20-7aac-4466-94ea-2b3621e79511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin_boundaries =  [*range(-10000,0,1000)] + [*range(0,10001,1000)]\n",
    "# plt.figure(figsize=(10,5))\n",
    "# # plt.hist(v201_X['ndvi'].values, label='Total Values',rwidth=0.5,bins=bin_boundaries)\n",
    "# plt.hist(P_cluster_X['ndvi'].values, label='Percent Cluster',\n",
    "#          bins=bin_boundaries,color='red',histtype ='bar')\n",
    "# plt.hist(EB_cluster_X['ndvi'].values, label='Even Balanced Cluster',\n",
    "#          bins=bin_boundaries,color='black',histtype ='bar')\n",
    "\n",
    "# plt.ylabel('Frequency',fontsize=12)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae927b8-cd3b-4e20-9689-23dff97ad1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0276abf7-ae38-4e96-b250-3e25238de329",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Recalculating NDVI manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d231ff-be4f-4bf0-b9de-e0fbace04f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_ndvi = np.where(X['ndvi'].values < 0.0)[0]\n",
    "# percent_neg_ndvi = len(neg_ndvi)/len(X['ndvi'].values)\n",
    "# how_many_water = np.where(y.iloc[neg_ndvi] > 0.5)[0]\n",
    "# how_many_land = np.where(y.iloc[neg_ndvi] < 0.5)[0]\n",
    "# print(len(how_many_water))\n",
    "# print(len(how_many_land))\n",
    "# print(len(neg_ndvi))\n",
    "\n",
    "# print(percent_neg_ndvi)\n",
    "# print(X.iloc[neg_ndvi,:].head())\n",
    "# print(y.iloc[neg_ndvi].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ad173-8495-4809-91c9-7757636daba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# bin_boundaries =  [*range(-10000,0,1000)] + [*range(0,10001,1000)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219a2ca-012b-4fea-804d-2bdac8cec747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "# trials = study.best_trials\n",
    "# trial_score = max([trial.values[0]\n",
    "#                    for trial in trials])\n",
    "# best_trial_params = [trial.params for trial in trials if trial.values[0] == trial_score][0]\n",
    "# print(best_trial_params)\n",
    "# print(trial_score)\n",
    "# score_print = np.round(trial_score,4)\n",
    "# print(score_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb27e0f-3ab7-41f8-bda7-2c0e7564578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters = best_trial_params\n",
    "# hyperparameters['n_jobs'] = -1\n",
    "# print('Using these params:')\n",
    "# print(hyperparameters)\n",
    "# tuned_classifier = skRF(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3220fba-351e-4bc5-9e24-f2af5dcf901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickled_model = pickle.load(open('rfa_models/MODIS_RFA_v201_EBCluster_sfcref127ndvi_4.pkl', 'rb'))\n",
    "# print(pickled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e05495-91b9-4ca8-9a14-26e0fa8ac422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EB_rand_X_rfa: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'bootstrap': True, 'max_features': 'log2'} 0.9785175070775922\n",
    "#Per_rand_X_rfa: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3, 'bootstrap': True, 'max_features': 'auto', 'n_jobs': -1} 0.9773275135496542\n",
    "#EB_cluster_X_rfa: {'n_estimators': 200, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 5, 'bootstrap': True, 'max_features': 'sqrt'} 0.9668007117784662\n",
    "#Per_cluster_X_rfa: {'n_estimators': 300, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': True, 'max_features': 'auto', 'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee12a19-8cf8-472d-ba4d-e269e7356272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EB1: 0.9121361508267432\n",
    "# EB2: 0.9152120215067565\n",
    "# EB3: 0.9153888116216589\n",
    "# EB4: 0.9334065797136774\n",
    "# EB5: 0.9330483639924072\n",
    "# EB6: 0.9325007563612594\n",
    "# EB7: 13875 12950 0.9330562509477165\n",
    "# EB8: 14220 13272 0.9119937102685194 \n",
    "# EB9: 13875 12950 0.9318627771973583\n",
    "# EB10: 14220 13272 0.9128319097402475\n",
    "\n",
    "# %1: 359648 295422 0.9778067788170863\n",
    "# %2: 359649 295421 0.977828848863204\n",
    "# %3: 359649 295421 0.977814397217147\n",
    "# %4: 359648 295421 0.9777926266177195\n",
    "# %5: 359650 295422 0.9778923365411023\n",
    "# %6: 359843 295233 0.9779668774041262\n",
    "# %7: 359841 295230 0.977761799842581\n",
    "# %8: 359840 296518 0.977231470922011\n",
    "# %9: 359835 295223 0.977650365098458\n",
    "# %10: 359837 295222 0.9778535497660246\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (TensorFlow)",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
