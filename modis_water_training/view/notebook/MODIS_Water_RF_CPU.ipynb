{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIS Water Random Forest\n",
    "\n",
    "Version: 0.1.0\n",
    "\n",
    "Date modified: 02.08.2022\n",
    "\n",
    "Modified by: Caleb Spradlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "#GDAL Stuff\n",
    "from osgeo import gdalconst\n",
    "from osgeo import gdal\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_OUTPUT_DIR = '/att/nobackup/cssprad1/projects/modis_water/code/modis_water_random_forest/view/notebook/output'\n",
    "RASTER_OUTPUT_DIR = '/att/nobackup/cssprad1/projects/modis_water/code/modis_water_random_forest/view/notebook/output'\n",
    "MODEL_OUTPUT_DIR = '/att/nobackup/cssprad1/projects/modis_water/models/'\n",
    "\n",
    "TILE = 'global'\n",
    "MODEL = 'rf'\n",
    "TEST_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "LABEL_NAME = 'water'\n",
    "DATA_TYPE = np.int16\n",
    "colsToDrop = ['x_offset', 'y_offset']\n",
    "v_names = ['sur_refl_b01_1','sur_refl_b02_1','sur_refl_b03_1',\n",
    "           'sur_refl_b04_1','sur_refl_b05_1','sur_refl_b06_1',\n",
    "           'sur_refl_b07_1','ndvi','ndwi1','ndwi2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fpath, colsToDrop, yCol='water', testSize=0.2, randomState=42, \n",
    "              dataType=np.float32, cpu=True, splitXY=False, trainTestSplit=False,\n",
    "             applyLog=False, imbalance=False, frac=0.1, land=False, multi=False, \n",
    "              multisample=1000000):\n",
    "    \"\"\"\n",
    "    Simple helper function for loading data to be used by models\n",
    "    :param fpath: Path to the data to be ingested.\n",
    "    :param dataType: Data type to convert ingested data to.\n",
    "    :param colsToDrop: Columns which are not necessary, from which to drop.\n",
    "    :param testSize: Ration to\n",
    "    \"\"\"\n",
    "    if multi:\n",
    "        all_dfs = [pd.read_csv(path_) for path_ in fpath]\n",
    "        df = pd.concat(all_dfs).sample(n=multisample, random_state=randomState)\n",
    "        print('DF length: {}'.format(len(df.index)))\n",
    "    else:   \n",
    "        df = pd.read_parquet(fpath) if '.parquet' in fpath else pd.read_csv(fpath)\n",
    "    df = df[df['sur_refl_b01_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b07_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df[df['sur_refl_b06_1'] + df['sur_refl_b02_1'] != 0]\n",
    "    df = df.drop(columns=colsToDrop)\n",
    "    cleanedDF = df[~df.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0).astype(dataType)\n",
    "    if applyLog:\n",
    "        for col in cleanedDF.drop([yCol], axis=1).columns:\n",
    "            print('Applying log1p func to {}'.format(col))\n",
    "            cleanedDF[col] = np.log1p(cleanedDF[col])\n",
    "        cleanedDF = cleanedDF[~cleanedDF.isin([np.NaN, np.inf, -np.inf]).any(1)].dropna(axis=0)\n",
    "    df = None\n",
    "    if imbalance:\n",
    "        groupedDF = cleanedDF.groupby('water')\n",
    "        dfs = [groupedDF.get_group(y) for y in groupedDF.groups]\n",
    "        sampledDF = dfs[1].sample(frac=frac)if land else dfs[0].sample(frac=frac)\n",
    "        concatDF = sampledDF.append(dfs[0]) if land else sampledDF.append(dfs[1])\n",
    "        concatDF = concatDF.sample(frac=1)\n",
    "        concatDF = concatDF.reset_index()\n",
    "        cleanedDF = concatDF.drop(columns=['index'])\n",
    "    if not splitXY:\n",
    "        return cleanedDF\n",
    "    X = cleanedDF.drop([yCol], axis=1).astype(dataType)\n",
    "    y = cleanedDF[yCol].astype(dataType)\n",
    "    if trainTestSplit:\n",
    "        return train_test_split(X, y, test_size=TEST_RATIO)\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "- Read in to cuDF or pandas Dataframe\n",
    "- Drop unnecessary columns\n",
    "- Clean data\n",
    "- Split into Xs and Ys\n",
    "- Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_string = '/att/nobackup/cssprad1/projects/modis_water/data/training_data/v1.1.0/MOD09_{}_*.parquet.gzip'.format(TILE)\n",
    "data_paths = [fv for fv in glob.glob(glob_string)]\n",
    "data_path = data_paths[0]\n",
    "pprint(data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data(fpath=data_path,\n",
    "                                             colsToDrop=colsToDrop,\n",
    "                                             dataType=DATA_TYPE,\n",
    "                                             cpu=True,\n",
    "                                             splitXY=True,\n",
    "                                             imbalance=False,\n",
    "                                             trainTestSplit=True,\n",
    "                                             multi=False)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [print(column) for column in X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_interesting_idx(df, column, threshold, greaterThan=True):\n",
    "    dfToReturn = df[df[column] > threshold] if \\\n",
    "        greaterThan else df[df[column] < threshold]\n",
    "    return dfToReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_interesting_idx(X_train, 'ndvi', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_interesting_idx(X_train, 'ndwi1', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_interesting_idx(X_train, 'ndwi2', 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'n_estimators': 400, \n",
    "                   'criterion':'gini', \n",
    "                   'max_depth':None, \n",
    "                   'min_samples_split':2, \n",
    "                   'min_samples_leaf':1, \n",
    "                   'min_weight_fraction_leaf':0.0, \n",
    "                   'max_features':'auto', \n",
    "                   'max_leaf_nodes':None, \n",
    "                   'min_impurity_decrease':0.0, \n",
    "                   'bootstrap':True, \n",
    "                   'oob_score':False, \n",
    "                   'n_jobs':-1, \n",
    "                   'random_state':42, \n",
    "                   'verbose':0, \n",
    "                   'warm_start':True, \n",
    "                   'class_weight':None, \n",
    "                   'ccp_alpha':0.0, \n",
    "                   'max_samples':None\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = skRF(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = None\n",
    "bestModelScore = 0\n",
    "scores = []\n",
    "for trainIdx, testIdx in kf.split(X_train):\n",
    "    print(\"Train {}, Test {}\".format(trainIdx, testIdx))\n",
    "    X_train_valid, X_test_valid = X_train.iloc[trainIdx], X_train.iloc[testIdx]\n",
    "    y_train_valid, y_test_valid = y_train.iloc[trainIdx], y_train.iloc[testIdx]\n",
    "    print('Fitting model')\n",
    "    classifier.fit(X_train_valid, y_train_valid)\n",
    "    print('Getting score')\n",
    "    score = classifier.score(X_test_valid, y_test_valid)\n",
    "    if score>=bestModelScore:\n",
    "        bestModelScore = score\n",
    "        print('Training accuracy score: {}'.format(score))\n",
    "        bestModel = classifier\n",
    "    print('Predicting for test set')\n",
    "    test_predictions = classifier.predict(X_test_valid)\n",
    "    print(classification_report(y_test_valid, test_predictions))\n",
    "    print('Score: {}'.format(score))\n",
    "    scores.append(score)\n",
    "    del test_predictions, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreAvg = np.asarray(scores).mean()\n",
    "print('Average accuracy score: {}'.format(scoreAvg))\n",
    "print('Best accuracy score: {}'.format(bestModelScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing and training/testing data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = classifier.score(X_test, y_test)\n",
    "score = round(score, 3)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = classifier.predict(X_train)\n",
    "test_predictions = classifier.predict(X_test)\n",
    "prediction_probs = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionProbabilityList = list()\n",
    "for i, subarr in enumerate(prediction_probs):\n",
    "    predictionProbabilityList.append(subarr[1])\n",
    "predictionProbabilityArray = np.asarray(predictionProbabilityList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the distribution of the probability of the predicted values.\n",
    "\n",
    "These are the probability that each test data point is water p=1 vs land p=0. Usually a relatively flatter distribution on one of the sides shows us that the model is not as confident on predicting that side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(predictionProbabilityArray, bins=30)\n",
    "plt.title('Distribution of the probability of predicted values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = test_predictions.astype(np.int32)\n",
    "y_test_int = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Performance')\n",
    "print('-------------------------------------------------------')\n",
    "print(classification_report(y_test, test_predictions))\n",
    "cm = confusion_matrix(y_test_int, test_predictions)\n",
    "recall = (cm[0][0] / (cm[0][0] + cm[0][1]))\n",
    "print('Test Recall')\n",
    "print('-------------------------------------------------------')\n",
    "print(recall)\n",
    "print('Confusion Matrix')\n",
    "print('-------------------------------------------------------')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = classifier\n",
    "\n",
    "probs = clf.predict_proba(X_test)\n",
    "preds = probs[:, 1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'red', label = 'ROC AUC score = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutaion importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_importance_results = permutation_importance(classifier,\n",
    "                                                        X=X_test,\n",
    "                                                        y=y_test,\n",
    "                                                        n_repeats=10,\n",
    "                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_save_path = 'mw_{}_{}_{}_{}_{}_permutation_importance.png'.format(\n",
    "    TILE,\n",
    "    score,\n",
    "    hyperparameters['n_estimators'],\n",
    "    MODEL,\n",
    "    datetime.datetime.now().strftime('%Y_%m_%d_%H_%M'))\n",
    "\n",
    "png_save_path = os.path.join(FIGURE_OUTPUT_DIR, png_save_path)\n",
    "\n",
    "sorted_idx = permutation_importance_results.importances_mean.argsort()\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.barh(X_test.columns[sorted_idx], permutation_importance_results.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.savefig(png_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test, test_predictions, train_predictions, y_test_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'mw_{}_{}_{}_{}_{}_tuned_{}.sav'.format(TILE,\n",
    "                                                              score,\n",
    "                                                              hyperparameters['n_estimators'],\n",
    "                                                              MODEL,\n",
    "                                                              'cpu',\n",
    "                                                              datetime.datetime.now().strftime('%Y_%m_%d_%H_%M'))\n",
    "model_save_path = os.path.join(MODEL_OUTPUT_DIR, model_save_path)\n",
    "print('Saving model to: {}'.format(model_save_path))\n",
    "print(classifier)\n",
    "joblib.dump(classifier, model_save_path, compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: raster testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE = 'h12v09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = 218\n",
    "YEAR = 2006\n",
    "PATH = '/att/nobackup/cssprad1/projects/modis_water/data/test_data/{}/'.format(TILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_list = [fn for fn in glob.glob(os.path.join(PATH, '*A{}{:03}*.tif'.format(YEAR, DAY)))\n",
    "            if 'sur_refl' in fn and 'GQ' not in fn]\n",
    "vars_list.sort()\n",
    "vars_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dimensions of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrt_opts = gdal.BuildVRTOptions(separate=True)\n",
    "dd = gdal.BuildVRT('tmp.vrt', vars_list, options=vrt_opts)\n",
    "nrows, ncols = dd.RasterYSize, dd.RasterXSize\n",
    "dd = None\n",
    "if os.path.exists('tmp.vrt'):\n",
    "    os.remove('tmp.vrt') \n",
    "nrows, ncols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data \n",
    "We don't need to slice because we have more than enough GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readRasterToArray(vars_list):\n",
    "    vrt_options = gdal.BuildVRTOptions(separate=True)\n",
    "    dd = gdal.BuildVRT('tmp.vrt', vars_list, options=vrt_options)\n",
    "    nrows, ncols = dd.RasterYSize, dd.RasterXSize\n",
    "    newshp = (ncols*nrows, dd.RasterCount+3)\n",
    "    img = np.empty(newshp, dtype=np.int16)\n",
    "    for b in range(len(vars_list)):\n",
    "        img[:, b] = dd.GetRasterBand(b+1).ReadAsArray().astype(np.int16).ravel()\n",
    "    dd = None\n",
    "    img[:, len(vars_list)] = ((img[:, 1] - img[:, 0]) / (img[:, 1] + img[:, 0])) * 10000\n",
    "    img[:, len(vars_list)+1] = ((img[:, 1] - img[:, 5]) / (img[:, 1] + img[:, 5])) * 10000\n",
    "    img[:, len(vars_list)+2] = ((img[:, 1] - img[:, 6]) / (img[:, 1] + img[:, 6])) * 10000\n",
    "    if os.path.exists('tmp.vrt'):\n",
    "        os.remove('tmp.vrt')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = readRasterToArray(vars_list)\n",
    "print('Raster as ndarray')\n",
    "print(im)\n",
    "print('{} MB size'.format((im.size * im.itemsize) / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictRaster(img_chunk):\n",
    "    \"\"\"\n",
    "    Function given a raster in the form of a nxn matrix, will\n",
    "    convert the matrix to a GPU/CPU-bound data frame then perform \n",
    "    predictions given the loaded model.\n",
    "    \n",
    "    Return the prediction matrix, the prediction probabilities\n",
    "    for each and the dataframe converted to host.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(img_chunk, dtype=np.int16)\n",
    "    print('Making predictions from raster')\n",
    "    predictions = classifier.predict(df).astype(np.int16)\n",
    "    predictionsProbs = classifier.predict_proba(df).astype(np.float32)\n",
    "    return predictions, predictionsProbs, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedRaster, predictedProbaRaster, df = predictRaster(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = (4800, 4800)\n",
    "left = list()\n",
    "right = list()\n",
    "for i, subarr in enumerate(predictedProbaRaster):\n",
    "    left.append(subarr[0])\n",
    "    right.append(subarr[1])\n",
    "leftArr = np.asarray(left)\n",
    "rightArr = np.asarray(right)\n",
    "probaLand = leftArr.reshape(shp)\n",
    "probaWater = rightArr.reshape(shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputreshapet raster: description and histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(16, 20), bins=50)\n",
    "plt.title('Distribution of each band and calculated idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape the unravelled matrix back to the 4800x4800 raster shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.asarray(predictedRaster)\n",
    "reshp = matrix.reshape(shp)\n",
    "reshp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the QA Mask and the Water Mask for the h09v05 TILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qaMask = '/att/nobackup/cssprad1/projects/modis_water/data/qa_masks'\n",
    "waterMask = '/att/nobackup/cssprad1/projects/modis_water/data/water_masks/Min2000_2019'\n",
    "qa_list = [fn for fn in glob.glob(os.path.join(qaMask, '*A{}{:03}.{}*bad_good_mask.tif'.format(YEAR, DAY, TILE)))]\n",
    "water_list = [fn for fn in glob.glob(os.path.join(waterMask, '*{}*.tif'.format(TILE)))]\n",
    "qa_mask = qa_list[0]\n",
    "water_mask = water_list[0]\n",
    "print(water_mask)\n",
    "print(qa_mask)\n",
    "ds = gdal.Open(qa_mask, gdal.GA_ReadOnly)\n",
    "waterMask = gdal.Open(water_mask, gdal.GA_ReadOnly)\n",
    "qaMaskMatrix = ds.GetRasterBand(1).ReadAsArray().astype(np.int16)\n",
    "waterMaskMatrix = waterMask.GetRasterBand(1).ReadAsArray().astype(np.int16)\n",
    "ds = None\n",
    "waterMask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterMaskMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask out results if QA Mask says pixel is \"bad\"\n",
    "Mask out water mask if QA Mask says pixel is \"bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedResult = np.where(qaMaskMatrix == 0, reshp, -9999)\n",
    "maskedResultProba = np.where(qaMaskMatrix == 0, probaWater, -9999)\n",
    "waterMasked = np.where(qaMaskMatrix == 0, waterMaskMatrix, -9999)\n",
    "waterMaskRavel = waterMasked.ravel()\n",
    "imWater = (waterMaskRavel == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating stats for predicted and truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TILE = 'global_{}_{}'.format(MODEL, TILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "outputPlt = plt.matshow(np.where(maskedResult == -9999, np.NaN, maskedResult), fignum=1)\n",
    "plt.colorbar()\n",
    "plt.title('Predicted water mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "outputPlt = plt.matshow(np.where(maskedResult == -9999, np.NaN, maskedResultProba), fignum=1)\n",
    "plt.colorbar()\n",
    "plt.title('Predicted probabilities of water')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum extent water mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "truth = np.where(waterMasked==-9999, np.NaN, waterMasked)\n",
    "truth = np.where(waterMasked==250, np.NaN, truth)\n",
    "truthPlt = plt.matshow(truth, fignum=1)\n",
    "plt.colorbar()\n",
    "plt.title('Minimum extent water mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics on test raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = np.where((waterMasked == 1) & (maskedResult == 1), 1, 0)\n",
    "tn = np.where((waterMasked == 0) & (maskedResult == 0), 1, 0)\n",
    "fp = np.where((waterMasked == 0) & (maskedResult == 1), 1, 0)\n",
    "fn = np.where((waterMasked == 1) & (maskedResult == 0), 1, 0)\n",
    "total = np.count_nonzero(waterMasked == 1) + np.count_nonzero(waterMasked == 0)\n",
    "truePositives = np.count_nonzero(tp == 1)\n",
    "trueNegatives = np.count_nonzero(tn == 1)\n",
    "falsePositives = np.count_nonzero(fp == 1)\n",
    "falseNegatives = np.count_nonzero(fn == 1)\n",
    "accuracy = (truePositives + trueNegatives) / (truePositives + trueNegatives + falsePositives + falseNegatives)\n",
    "jians = truePositives / (truePositives + trueNegatives)\n",
    "pc = truePositives / (truePositives + falsePositives)\n",
    "rc = truePositives / (truePositives + falseNegatives)\n",
    "f1 = truePositives / (truePositives + (0.5*(falsePositives + falseNegatives)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count num of occurences for each class with the masked predicted result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countNoData = np.count_nonzero(maskedResult == -9999)\n",
    "countLand = np.count_nonzero(maskedResult == 0)\n",
    "countWater = np.count_nonzero(maskedResult == 1)\n",
    "print('Predicted\\n Nodata occurences: {}\\n Land occurance: {}\\n Water occurances: {}'.format(countNoData, countLand, countWater))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count num of occurences for each class with the water mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countNoDataT = np.count_nonzero(waterMasked == -9999)\n",
    "countLandT = np.count_nonzero(waterMasked == 0)\n",
    "countWaterT = np.count_nonzero(waterMasked == 1)\n",
    "print('Min. extent water mask vals\\n Nodata occurences: {}\\n Land occurance: {}\\n Water occurances: {}'.format(countNoDataT, countLandT, countWaterT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model metrics on raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Metrics of Accuracy for Raster Test Data')\n",
    "print('True Positives:  {}'.format(truePositives))\n",
    "print('True Negatives:  {}'.format(trueNegatives))\n",
    "print('False Positives: {}'.format(falsePositives))\n",
    "print('False Negatives: {}'.format(falseNegatives))\n",
    "print('Total \"good\" data: {}'.format(total))\n",
    "print('Accuracy*: {}'.format(accuracy))\n",
    "print(\"Jian's metric : {}\".format(jians))\n",
    "print('Precision: {}'.format(pc))\n",
    "print('Recall: {}'.format(rc))\n",
    "print('f1: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output predicted raster to GeoTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outPath = os.path.join(RASTER_OUTPUT_DIR, '{}_{}_{}_predicted_{}.tif'.format(YEAR, DAY, TILE, MODEL))\n",
    "waterMaskForDay = os.path.join(RASTER_OUTPUT_DIR, 'waterMask_{}_qa_{}.tif'.format(YEAR, DAY, TILE, MODEL))\n",
    "outPathProba = os.path.join(RASTER_OUTPUT_DIR, '{}_{}_{}_predicted_probabilities_{}.tif'.format(YEAR, DAY, TILE, MODEL))\n",
    "print(outPath)\n",
    "print(waterMaskForDay)\n",
    "print(outPathProba)\n",
    "\n",
    "ds = gdal.Open(vars_list[0], gdal.GA_ReadOnly)\n",
    "geo = ds.GetGeoTransform()\n",
    "proj = ds.GetProjection()\n",
    "ncols = ds.RasterXSize\n",
    "nrows = ds.RasterYSize\n",
    "print('Transform')\n",
    "print(geo)\n",
    "print('Projection')\n",
    "print(proj)\n",
    "print('Width')\n",
    "print(ncols)\n",
    "print('Height')\n",
    "print(nrows)\n",
    "ds = None\n",
    "\n",
    "# Output predicted binary raster masked with good-bad mask.\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "outDs = driver.Create(outPath, ncols, nrows, 1, gdal.GDT_Int16, options=['COMPRESS=LZW'])\n",
    "outDs.SetGeoTransform(geo)\n",
    "outDs.SetProjection(proj)\n",
    "outBand = outDs.GetRasterBand(1)\n",
    "outBand.WriteArray(maskedResult)\n",
    "outBand.SetNoDataValue(-9999)\n",
    "outDs.FlushCache()\n",
    "outDs = None\n",
    "outBand = None\n",
    "driver = None\n",
    "\n",
    "# Output water mask with good-bad masked.\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "outDs = driver.Create(waterMaskForDay, ncols, nrows, 1, gdal.GDT_Int16, options=['COMPRESS=LZW'])\n",
    "outDs.SetGeoTransform(geo)\n",
    "outDs.SetProjection(proj)\n",
    "outBand = outDs.GetRasterBand(1)\n",
    "outBand.WriteArray(waterMasked)\n",
    "outBand.SetNoDataValue(-9999)\n",
    "outDs.FlushCache()\n",
    "outDs = None\n",
    "outBand = None\n",
    "driver = None\n",
    "\n",
    "# Output probabilies raster masked by good-bad mask.\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "outDs = driver.Create(outPathProba, ncols, nrows, 1, gdal.GDT_Float32, options=['COMPRESS=LZW'])\n",
    "outDs.SetGeoTransform(geo)\n",
    "outDs.SetProjection(proj)\n",
    "outBand = outDs.GetRasterBand(1)\n",
    "outBand.WriteArray(maskedResultProba)\n",
    "outBand.SetNoDataValue(-9999)\n",
    "outDs.FlushCache()\n",
    "outDs = None\n",
    "outBand = None\n",
    "driver = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ilab]",
   "language": "python",
   "name": "conda-env-ilab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
